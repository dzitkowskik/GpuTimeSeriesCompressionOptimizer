\documentclass[12pt, twoside, openany]{report}
\usepackage[dvips]{graphicx,color,rotating}
\usepackage[cp1250]{inputenc}
\usepackage{t1enc}
\usepackage{a4wide}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage[MeX]{polski}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{left=25mm,right=25mm,%
bindingoffset=10mm, top=25mm, bottom=25mm}
\usepackage{amssymb, latexsym}
\usepackage{amsthm}
\usepackage{palatino}
\usepackage{array}
\usepackage{pstricks}
\usepackage{textcomp}
\theoremstyle{definition}
\newtheorem{theorem}{Twierdzenie}[section]
\newtheorem{remark}{Uwaga}[section]
\newtheorem{definition}{Definicja}[section]
\newtheorem{alg}{Algorytm}[chapter]
\newtheorem{prz}{Przypadek}[section]
\newtheorem{np}{Przyk³ad}[section]
\newtheorem{lemma}[theorem]{Lemat}
\linespread{1.5}
\newcommand*{\norm}[1]{\left\Vert{#1}\right\Vert}
\newcommand*{\abs}[1]{\left\vert{#1}\right\vert}
\newcommand*{\om}{\omega}

\usepackage[ruled,vlined]{algorithm2e}
\usepackage{listings}

\author{Karol Dzitkowski}
\title{Optymalizator kompresji szeregów czasowych na GPU}
\begin{document}
\begin{titlepage}
\pagestyle{empty}

\noindent
\begin{Large}
\begin{table}[t]
\centering
\begin{tabular}[t]{lcr}
 \includegraphics[width=70pt,height=70pt]{PW} & POLITECHNIKA WARSZAWSKA & \includegraphics[width=70pt,height=70pt]{MiNI}\\
& WYDZIA£ MATEMATYKI & \\
& I NAUK INFORMACYJNYCH &
\end{tabular}
\end{table}

% \vfill
\begin{center}PRACA DYPLOMOWA MAGISTERSKA\end{center}
\begin{center}INFORMATYKA\end{center}\end{Large}
% \vfill
\begin{center}
\Huge
\textbf{Optymalizator kompresji szeregów czasowych na GPU}
\end{center}
% \vfill\vfill
\vfill
\begin{center}
\Large
Autor:\\
\LARGE
Karol Dzitkowski
\end{center}
\vfill
\begin{center}
\Large
Promotor: dr in¿. Krzysztof Kaczmarski
\end{center}
\vfill
\begin{center}
\large
Warszawa, luty 2016
\end{center}
\newpage
\hfill
\begin{table}[b]
\centering
\begin{tabular}[t]{ccc}
............................................. & \hspace*{100pt} & .............................................\\
podpis promotora & \hspace*{100pt} & podpis autora
\end{tabular}
\end{table}


% \maketitle
\end{titlepage}
\thispagestyle{empty}
\newpage
\pagestyle{headings}
\setcounter{page}{1}
\hyphenation{Syl-ves-tra}
\hyphenation{Syl-ves-ter-a}

\renewcommand{\abstractname}{Abstrakt}

\begin{abstract}
Wiele urz¹dzeñ takich jak czujniki, stacje pomiarowe, czy nawet serwery, produkuj¹ ogromne iloœci danych w postaci szeregów czasowych, które nastêpnie s¹ przetwarzane i sk³adowane do póŸniejszej analizy. Ogromn¹ rolê w tym procesie stanowi przetwarzanie danych na kartach graficznych w celu przyspieszenia obliczeñ. Aby wydajnie korzystaæ z GPGPU przedstawiono szereg rozwi¹zañ, korzystaj¹cych z kart graficznych jako koprocesory w bazach danych lub nawet bazy danych po stronie GPU. We wszystkich rozwi¹zaniach bardzo istotn¹ rolê stanowi kompresja danych. Szeregi czasowe s¹ bardzo szczególnym rodzajem danych, dla których kluczowy jest dobór odpowiedniej kompresji wedle charakterystyki danych szeregu. W tej pracy przedstawiê nowe podejœcie do kompresji szeregów czasowych po stronie GPU, przy u¿yciu planera buduj¹cego na bie¿¹co drzewa kompresji na podstawie statystyk nap³ywaj¹cych danych. Przedstawione rozwi¹zanie kompresuje dane za pomoc¹ lekkich i bezstratnych kompresji w technologii CUDA.
\end{abstract}

\renewcommand{\abstractname}{Abstract}

\begin{abstract}
Many devices such as sensors, measuring stations or even servers produce enormous amounts of data in the form of time series, which are then processed and stored for later analysis. A huge role in this process takes data processing on graphics cards in order to accelerate calculations. To efficiently use the GPGPU a number of solutions has been presented, that use the GPU as a coprocessor in a databases. There were also attempts to create a GPU-side databases. It has been known that data compression plays here the crucial role. Time series are special kind of data, for which choosing the right compression according to the characteristics of the data series is essencial. In this paper I present a new approach to compression of time series on the side of the GPU, using a planner to keep building the compression tree based on statistics of incoming data. The solution compresses data using lightweight and lossless compression in CUDA technology.
\end{abstract}

%-----------Pocz¹tek czêœci zasadniczej-----------

\chapter{Wstêp}
Poni¿sza praca zawiera opis implementacji optymalizatora kompresji szeregów czasowych, bazuj¹cego na dynamicznie generowanych statystykach danych. Pomys³ opiera siê na tworzeniu drzew kompresji (kompresja kaskadowa) oraz zbieraniu statystyk o krawêdziach takich drzew - jak dobrze dana para kompresji sprawdza siê dla nap³ywaj¹cych danych. System bêdzie równie¿ dynamicznie zmienia³ - korygowa³, takie drzewa w zale¿noœci od charakterystyki kolejnych paczek danych.
W za³o¿eniu program ma umo¿liwiæ kompresjê du¿ych iloœci danych przy wykorzystaniu potencja³u obliczeniowego wspó³czesnych kart graficznych.

\section{Procesory graficzne}
Procesory graficzne sta³y siê znacz¹cymi i potê¿nymi koprocesorami obliczeñ dla wielu aplikacji i systemów takich jak bazy danych, badania naukowe czy wyszukiwarki www. Nowoczesne GPU posiadaj¹ moc obliczeniow¹ o rz¹d wiêksz¹ ni¿ zwykle, wielordzeniowe procesory CPU, takie jak AMD FX 8XXX czy Intel Core i7. Dla przyk³adu flagowa konstrukcja firmy NVIDIA - GeForce GTX Titan X osi¹ga moc 6600 GFLOPS (miliardów operacji zmiennoprzecinkowych na sekundê), przy $336 GB/s$ przepustowoœci pamiêci, podczas gdy najszybsze procesory takie jak Intel Core i7-5960x osi¹gaj¹ nieca³e 180 GFLOPS, przy przepustowoœci $68 GB/s$. Kartom graficznym dorównuj¹ tylko inne jednostki typu SIMD, na przyk³ad karty obliczeniowe Xeon Phi. Pomimo tak osza³amiaj¹cych wyników, programowanie na jednostkach SIMD jest o wiele trudniejsze,
jak równie¿ ograniczone przepustowoœci¹ szyny PCI-E, która wynosi w porywach $8 GB/s$, co dodatkowo przemawia za u¿yciem kompresji przy przetwarzaniu szeregów czasowych, choæby w celu przyspieszenia kopiowania danych z i na kartê graficzn¹.

\section{Szeregi czasowe}

	\begin{figure}[h!]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/TS}
		\caption{Szereg czasowy}
		\label{ref:ts}
	\end{figure}

Terabajty danych w postaci szeregów czasowych s¹ przetwarzane i analizowane ka¿dego dnia na ca³ym œwiecie. Zapytania i agregacje na tak wielkich porcjach danych jest czasoch³onne i wymaga du¿ej iloœci zasobów. Aby zmierzyæ siê z tym problemem, powsta³y wyspecjalizowane bazy danych, wspieraj¹ce analizê szeregów czasowych. Wa¿nym czynnikiem w tych rozwi¹zaniach jest kompresja oraz u¿ycie procesorów graficznych w celu przyspieszenia obliczeñ. Aby przetwarzaæ dane na GPU bez koniecznoœci ich ci¹g³ego kopiowania poprzez szynê PCI-E, powstaj¹ bazy danych po stronie GPU (najczêœciej rozproszone), takie jak MapD\footnote{Baza danych GPU - http://www.mapd.com/}\cite{MOSTAK} lub DDJ\footnote{https://github.com/d-d-j -  zaproponowana we wczeœniejszej pracy in¿ynierskiej}.
Innymi rozwi¹zaniami s¹ koprocesory obliczeniowe GPU, wspomagaj¹ce dzia³anie baz takich jak Cassandra, HBase, TepoDB, OpenTSDB czy PostgreSQL. Charakterystyka danych wielu szeregów wskazuje, ¿e przy odpowiedniej obróbce mog¹ byæ kompresowane z bardzo du¿ym wspó³czynnikiem, szczególnie jeœli by³oby mo¿liwe kompresowanie za pomoc¹ dynamicznie zmieniaj¹cych siê ci¹gów (ró¿nych) algorytmów kompresji i transformacji danych. Dla przyk³adu, jeœli jakiœ fragment szeregu jest sta³y, z nielicznymi wyj¹tkami, warto by³oby usun¹æ wyj¹tki, a resztê skompresowaæ jako jedn¹ liczbê - uzyskuj¹c wspó³czynnik kompresji rzêdu d³ugoœci danych.

\section{SIMD i lekka kompresja}
Bazy danych przechowuj¹ce szeregi czasowe s¹ najczêœciej zorientowane kolumnowo oraz stosuj¹ metody lekkiej kompresji w celu oszczêdnoœci pamiêci. W tych przypadkach stosuje siê metody lekkiej kompresji, takie jak kodowanie s³ownikowe, delta lub sta³ej liczby bitów, zamiast bardziej skomplikowanych i wolniejszych metod, które czêsto zapewni³yby lepszy poziom kompresji. Systemy te ³aduj¹ swoje dane do pamiêci trwa³ej paczkami, które mog¹ byæ kompresowane osobno, przy u¿yciu ró¿nych algorytmów, zmieniaj¹cych siê dynamicznie w czasie. Takie kolumny wartoœci numerycznych tego samego typu wspaniale przetwarza siê przy u¿yciu procesorów typu SIMD, co daje wielokrotne przyspieszenie w stosunku do tradycyjnych architektur. Okazuje siê ¿e wiêkszoœæ algorytmów lekkiej kompresji mo¿e z du¿ym powodzeniem byæ w ten sposób zrównoleglona. Równie¿ dynamiczne generowanie statystyk nap³ywaj¹cych danych mo¿e byæ przyspieszone z u¿yciem SIMD, co otwiera mo¿liwoœæ implementacji wydajnych systemów, dynamicznie optymalizuj¹cych u¿yte kompresje w celu zwiêkszenia wspó³czynnika kompresji danych. Dodatkowo u¿ycie kaskadowej kompresji mo¿e wielokrotnie wzmocniæ poziom kompresji, pod warunkiem stworzenia dobrego planu kompresji, w³aœnie na podstawie wygenerowanych statystyk. Ogromna moc obliczeniowa procesorów graficznych mo¿e pozwoliæ wygenerowaæ odpowiedni plan w rozs¹dnym czasie. Takie u¿ycie jest mo¿liwe np. w bazach danych po stronie GPU, gdzie jest to niezmiernie wa¿ne z powodu œcis³ego limitu pamiêci na kartach i ich wysokiego kosztu.

\section{Zawartoœæ pracy}
W tej pracy przedstawiê planer kompresji (optymalizator) kompresuj¹cy nap³ywaj¹ce paczki danych. Zaprezentujê nowe podejœcie do planera buduj¹cego drzewa kompresji i ucz¹cego siê ich konstrukcji na podstawie statystyk wêz³ów takich drzew generowanych w czasie rzeczywistym\footnote{jak równie¿ statystyk nap³ywaj¹cych danych}. Przedstawiê równie¿ zaimplementowane œrodowisko oraz u¿yte algorytmy lekkiej kompresji. W ramach tej pracy stworzone zosta³y 4 biblioteki, wykorzystuj¹ce technologiê \emph{NVIDIA CUDA}, tworz¹ce framework optymalizatora kompresji oraz program kompresuj¹cy kolumny podanego szeregu czasowego w sposób równoleg³y.
Nastêpny podrozdzia³ zawiera opis wczeœniejszych prac prowadzonych w tych tematach, a tak¿e krótki opis architektury CUDA. W rozdziale 2 omówiê stworzony framework oraz metody lekkiej kompresji, ze szczególnym uwzglêdnieniem kompresji FL oraz GFC. Rozdzia³ 3 jest w ca³oœci poœwiêcony optymalizatorowi kompresji oraz generowaniu drzew i statystyk. Nastêpnie przedstawiê wyniki prac i eksperymentów. Ostatni rozdzia³ to podsumowanie oraz zakres przysz³ych prac i optymalizacji.

\section{Powi¹zane prace}

\subsection{Szeregi czasowe}
Szeregi czasowe s¹ typem danych dla których istnieje wiele efektywnych sposobów kompresji, zale¿nych od ich charakterystyki. W wielu pracach przedstawiono podejœcia do tego problemu od strony lekkiej kompresji. Najczêstszymi z nich s¹ kodowanie ekstremami \cite{FINK}, sta³ej d³ugoœci bitów \cite{PRZYMUS1}, czyli tzw. NULL Suppression (NS) oraz proste kodowania s³ownikowe np. wszystkich unikalnych wartoœci, które mo¿na zakodowaæ pewn¹ za³o¿on¹ z góry liczb¹ bitów \cite{ABADI}. \\
Dodatkowo do kompresji szeregów stosuje siê metody regresji \cite{MENSMANN}. Autor stosuje Piecewise Regression - regresjê odcinkow¹, polegaj¹c¹ na przybli¿aniu kawa³ków szeregu funkcj¹, np. wielomianem. Ma to swoj¹ wersjê stratn¹ jak i bezstratn¹, gdzie mo¿emy zapisaæ ró¿nicê od zadanej funkcji i wynik zapisaæ na mniejszej liczbie bitów. \\ Szeregi czasowe to nie tylko liczby ca³kowite. Analizuje siê tak¿e wiele sposobów kompresji liczb zmiennoprzecinkowych pojedynczej i podwójnej precyzji. Najczêœciej próbuje siê zamieniæ liczbê u³amkow¹ na ca³kowit¹ stosuj¹c skalowanie \cite{PRZYMUS2}. Istniej¹ te¿ bardziej skomplikowane metody na przyk³ad kompresji liczb double algorytmem FPC \cite{BURTSCHER}, który kompresuje liniow¹ sekwencjê liczb o podwójnej precyzji (IEEE 754), sekwencyjnie przewiduj¹c ka¿d¹ wartoœæ, a nastêpnie wykonuj¹c operacjê XOR z prawdziw¹ wartoœci¹ szeregu, po czym usuwane s¹ wiod¹ce zera.

\subsection{SIMD SSE}
Bior¹c pod uwagê algorytmy lekkiej kompresji dla szeregów, warto zwróciæ uwagê na udane próby optymalizacji z u¿yciem prostego SIMD jakim s¹ operacje wektorowe SSE na procesorach Intel \cite{ZHAO, LEMIRE}. W tych pracach pokazano przek³ad algorytmów kodowania z wyrównaniem do bajtów (Byte-Aligned Coding) oraz do s³ów (Word-Aligned Coding) i zmierzono wydajnoœæ implementacji wektorowej wersji tych kodowañ z u¿yciem SSE. Autorzy zastosowali równie¿ binarne pakowanie (Binary Packing) w formie algorytmu FOR (Frame of Reference) \cite{GOLDSTEIN} dziel¹c dane na bloki o d³ugoœci 128 elementów (zmiennych ca³kowitych o d³ugoœci 32 bitów) i stosuj¹c patchowanie. Taki algorytm okaza³ siê najwydajniejszy. Pokazano, ¿e bez spadku jakoœci kompresji mo¿na uzyskaæ w ten sposób wzrost szybkoœci kompresji od 2 do 4 razy w stosunku to tradycyjnej implementacji.

\subsection{Obliczenia GPU}
Dziêki ogromnej mocy obliczeniowej kart graficznych uzyskano znacz¹cy wzrost wydajnoœci wielu algorytmów daj¹cych siê w mniejszym lub wiêkszym stopniu zrównolegliæ. Przyk³adowymi algorytmami o tej w³aœciwoœci s¹ choæby radix sort\cite{SORT}, hashowanie kuku³cze\cite{PHASH,CHASH}, sumy prefixowe\cite{PPS} i inne zaimplementowane w podstawowych bibliotekach takich jak
CUDPP\footnote{CUDA Data Parallel Primitives - http://cudpp.github.io/}
czy Thrust\footnote{Parallel algorithms library - https://developer.nvidia.com/thrust}. \\
Najwa¿niejsze s¹ jednak bardzo zadowalaj¹ce rezultaty zrównoleglania algorytmów u¿ywanych w bazach danych takich jak index search\cite{ANH}, wszelkiego rodzaju agregacje i operacje join, scatter i gather\cite{RUSSEK} oraz obliczanie statystyk danych\cite{KACZMAR1}, jak równie¿ dopasowywanie wyra¿eñ regularnych\cite{MORISHIMA}. Dla przyk³adu, wzrost wydajnoœci oferowany przez algorytmy z biblioteki Thrust, która jest niejako odpowiednikiem Std, jest œrednio 10-krotny\cite{CUDA_PERF} w stosunku do najszybszych wersji CPU. Wiêkszoœæ przytoczonych wy¿ej przyk³adów równie¿ reprezentuje wzrost wydajnoœci o rz¹d wielkoœci. W pracach odnoœnie akceleracji baz danych za pomoc¹ technologii CUDA, autorzy otrzymuj¹ przyspieszenie $20-60$ krotne\cite{BAKKUM}, w przypadku operacji \emph{SELECT WHERE} i \emph{SELECT JOIN} z agregacjami\cite{RUSSEK}. Powy¿sze wyniki zwykle s¹ osi¹gane bez uwzglêdniania czasu kopiowania danych na GPU, co jak obliczono zajmuje to œrednio ok $90\%$ czasu dzia³ania algorytmów\cite{KACZMAR2}.

\subsection{Kompresje}
Opisane wy¿ej algorytmy lekkiej kompresji szeregów czasowych, w wiêkszoœci zosta³y zaimplementowane przez Fang et al.\cite{FANG} oraz Przymus et al.\cite{KACZMAR2} w ich pracach, gdzie autorzy zaznaczaj¹ ogromny wzrost przepustowoœci takich algorytmów oraz ich wysok¹ skutecznoœæ w kompresji szeregów. W przypadku pierwszego jest to nawet to 56 GB/s dekodowania, a dla drugiego od 2 do 40 GB/s kodowania w zale¿noœci od stopnia skomplikowania algorytmu. Wiêkszoœæ przewidzianych metod ma swoje odpowiedniki z patchowaniem, w którym elementy niepasuj¹ce odk³adane s¹ do osobnej tablicy wyj¹tków. Prace te odnosz¹ siê jednak tylko do liczb ca³kowitych, a najczêœciej ca³kowitych bez znaku (naturalnych).\\
Lekk¹ kompresjê liczb zmiennopozycyjnych o podwójnej precyzji przestawi³ w swojej pracy O'Neil et al.\cite{ONEIL}, w której stosuj¹c technologiê CUDA i dziel¹c dane na odpowiednie bloki, zastosowano wariacjê algorytmu FOR i osi¹gniêto bardzo dobre wyniki rzêdu 75 Gb/s kodowania oraz a¿ 90 Gb/s dekodowania (daje to podobne rezultaty jak implementacja algorytmu FL dla liczb naturanlych\cite{PRZYMUS1}). Algorytm nazwano GFC, a jego uogólnienie dla liczb o pojedynczej precyzji przedstawiê dok³adnie w kolejnym rozdziale. \\
Wzrost wydajnoœci osi¹gniêto równie¿ na tle bardziej skomplikowanych metod (daj¹cych czêsto lepsze wspó³czynniki kompresji) jak kodowanie Huffmana\cite{CURRY}, gdzie równoleg³a implementacja na GPU uzyska³a \emph{2-5} krotne przyspieszenie, natomiast przepustowoœæ takiej kompresji to dla porównania 300 do 500 MB/s. Próby zoptymalizowania algorytmów takich jak LZSS w pracach Ozsoy et al.\cite{OZSOY}, skoñczy³y siê lekkim (max 2.2x) wzrostem wydajnoœci (w stosunku do wielordzeniowych implementacji CPU), przy uzyskanej przepustowoœci 1700 Mb/s w konfiguracji z dwoma kartami GPU\cite{OZSOY3}. Równie¿ inni autorzy maj¹ nadziejê na optymalizacjê z u¿yciem kodowañ s³ownikowych, takich jak LZW, pobijaj¹c wyniki CPU po przepisaniu ich do architektury SIMD\cite{SHYNI}. Mo¿na dodatkowo spotkaæ wariacje algorytmu LZSS przepisanego na CUDA, takie jak CANLZSS\cite{DTU}, która wed³ug autora przewy¿sza wydajnoœci¹ ponad 60 razy seryjn¹ implementacjê zwyk³ego LZSS. Kolejna optymalizacja GLZSS, w której zreorganizowano s³ownik to postaci tablicy haszy, oraz przyspieszono porównywanie podci¹gów\footnote{równie¿ zrównoleglaj¹c je na GPU}, osi¹gaj¹c dwukrotne przyspieszenie wzglêdem poprzednich prac\cite{ZU}. \\
Porównuj¹c szybkoœæ dzia³ania oraz wspó³czynniki kompresji uzyskane przez autorów, mo¿na dojœæ do wniosku, ¿e zastosowanie metod lekkich kompresji dla szeregów czasowych, w miejscach gdzie szczególne znaczenie ma szybka dekompresja, jest uzasadnione.

\subsection{Planery kompresji}
Okazuje siê, ¿e aby wielokrotnie zwiêkszyæ wspó³czynnik kompresji szeregu czasowego, warto go przetransformowaæ przed kompresj¹ b¹dŸ nawet skompresowaæ wielokrotnie ró¿nymi algorytmami. W tym celu powsta³y planery kompresji, które dzia³aj¹ na zasadzie kodowania kaskadowego, czyli ci¹gu nastêpuj¹cych po sobie kodowañ tworz¹cych drzewo. Dziêki zastosowaniu procesorów graficznych osi¹gniêto bardzo dobre wyniki zarówno pod wzglêdem wspó³czynnika kompresji, jak i szybkoœci dzia³ania. Dla przyk³adu przepustowoœæ kodowania 45 GB/s oraz dekodowania 56 GB/s zosta³a osi¹gniêta przez Fang et al.\cite{FANG}. W tym przypadku pos³uguj¹c siê heurystykami wykorzystuj¹cymi statystyki danych wejœciowych, spoœród ogromnej iloœci dostêpnych schematów kodowania, wyznaczano najlepiej pasuj¹ce\footnote{np. dla danych posortowanych powinny zaczynaæ siê od RLE itd.}. Nastêpnie wybierano spoœród nich plan spe³niaj¹cy zdefiniowane normy, np. plan o najwiêkszym wspó³czynniku kompresji. Statystyki na których oparty by³ algorytm pozyskiwano z informacji o kolumnie w bazie danych. Zanotowano du¿o lepsz¹ kompresjê ni¿ w przypadku tradycyjnego kodowania pojedyncz¹ metod¹ dla realistycznych danych. \\
Kolejnym, podobnym podejœciem do planera jest praca Przymusa et al.\cite{PRZYMUS2}, w której plan z³o¿ony jest z trzech warstw metod nastêpuj¹cych po sobie: transformacji, kodowania bazowego i pomocniczego. Cech¹ charakterystyczn¹ tego rozwi¹zania jest dynamiczny generator statystyk, który uaktualnia statystyki w momencie tworzenia planu, wykorzystuj¹c w³aœciwoœci poszczególnych metod takiej kompresji\footnote{szczególnie w przypadku minimalnej iloœci bitów potrzebnych do zapisania ka¿dej liczby}. Dodatkowo praca ta implementuje znajdowanie optimum ze wzglêdu na dwie sprzeczne zmienne (bi-objective optimizer): szybkoœæ dzia³ania i jakoœæ kompresji, stosuj¹c optymalnoœæ Pareto\cite{PARETO}. Generowanie statystyk dla takiego planera na GPU zapewnia do 70 razy lepsz¹ wydajnoœæ w stosunku do analogicznej implementacji na CPU\cite{KACZMAR2}.
\section{CUDA}
Jedn¹ z wielu zalet architektury kart graficznych jest to, ¿e sk³adaj¹ siê z kilku multiprocesorów (SMs - Streaming Multiprocessors) architektury SIMD. Jest to w³aœciwie architektura typu SIMT, gdzie multiprocesor wykonuje w¹tki w grupach o licznoœci 32 zwanymi \emph{warps}. Architektura ta jest zbli¿ona do SIMD z t¹ ró¿nic¹, ¿e to nie organizacja wektora danych kontroluje jednostki obliczeniowe, a organizacja instrukcji pojedyñczego w¹tku. Umo¿liwia on zatem pisanie równolegle wykonywanego kodu dla niezale¿nych i skalowalnych w¹tków, jak i dla tych koordynowanych danymi.
	\begin{figure}[h!]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.50]{img/CUDA_arch}
		\vspace*{-3mm}
		\caption{Architektura NVIDIA CUDA}
		\label{ref:cuda_arch}
	\end{figure}
\noindent
Wszystkie w¹tki wykonuj¹ ten sam kod funkcji kernela. Ponadto CUDA tworzy abstrakcjê bloków w¹tków, które zorganizowane s¹ w siatkê (GRID) i wspó³dziel¹ zasoby multiprocesora. Wa¿na jest równie¿ hierarchia pamiêci, w której czêœæ przydzielana jest w¹tkom w postaci pamiêci lokalnej i rejestrów, oraz pamiêci wspó³dzielonej przez w¹tki z tego samego bloku (Shared Memory) - te pamiêci musz¹ byæ znane w trakcie kompilacji kernela. Najwolniejsza jest pamiêæ globalna (Device Memory), wspólna dla wszystkich w¹tków, wszystkich bloków, na wszystkich multiprocesorach. Dok³adny opis tej architektury mo¿na znaleŸæ bezpoœrednio na stronie producenta.
	\begin{figure}[h!]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.50]{img/CUDA_grid}
		\vspace*{-6mm}
		\caption{Abstrakcja bloków i siatki w CUDA}
		\label{ref:cuda_grid}
	\end{figure}

\chapter{Opis systemu}

\section{Kodowania}

Przedstawiê krótko kodowania u¿yte w implementacji planera kompresji oraz ich modyfikacje, a nastêpnie opiszê szczegó³owo dwa najwa¿niejsze, które zwykle koñcz¹ œcie¿ki kompresji w generowanych planach. S¹ to kodowania bazuj¹ce na pomyœle usuwania zbêdnych zer wiod¹cych, dla liczb naturalnych - AFL oraz u³amkowych - GFC. Trzeba zauwa¿yæ, ¿e operacja patchowania jest tutaj zaimplementowana odmiennie ni¿ w innych publikacjach, jako osobny rodzaj kodowania, mog¹cy przybieraæ wiele form, natomiast algorytmy nie maj¹ swoich wersji z patchowaniem.\\

\subsection{Podstawowe algorytmy transformacji szeregów}
\begin{description}
\item[Delta] -- Zapisuje zmiany pomiêdzy kolejnymi danymi w szeregu, rejestruj¹c pierwsz¹ wartoœæ w metadanych. Bardzo dobrze sprawdza siê na danych posortowanych b¹dŸ o zmianach liniowych o sta³ej wartoœci. Algorytm ten zosta³ zaimplementowany czêœciowo z u¿yciem biblioteki Thrust i funkcji \emph{inclusive\_scan} - do dekodowania.
\item[Scale] -- Bardzo prosta transformacja, odmienna od wielu implementacji o tej samej nazwie, polegaj¹ca na odjêciu lub dodaniu (dla liczb ujemnych) najmniejszej dodatniej wartoœci szeregu. Bardzo dobrze sprawdza siê dla du¿ych wartoœci szeregu o ma³ej wariancji. Dla przyk³adu, maj¹c wartoœci: $${1234000, ..., 1234500, ..., 1234999}$$ dane zostan¹ zapisane jako ${0, 1, ..., 999}$ i bêd¹ mog³y byæ zredukowane do du¿o mniejszej liczby bitów.
\item[FloatToInt] -- Wersja algorytmu, któr¹ czêsto w literaturze nazywa siê mianem \emph{Scale}. Znaj¹c maksymaln¹ precyzjê danych zmiennopozycyjnych, mo¿liwe jest ich zapisanie w postaci liczb ca³kowitych, mno¿¹c przez odpowiedni¹ potêgê liczby 10. Oznacza to, ¿e maj¹c wektor cen w z³otówkach, mo¿na przemno¿yæ cenê 99.99 przez 100 otrzymuj¹c 9999 i zmieniæ reprezentacjê liczb na ca³kowite.
W wyniku takiego dzia³ania reprezentacja liczb ca³kowitych mo¿e ulec lepszej kompresji.
\item[Patch] -- Bardzo wa¿nym zadaniem w kompresji szeregów czasowych jest usuwanie wartoœci odstaj¹cych tzw. \emph{outliers}. Kodowanie to dzieli wektor danych na dwa wektory wzglêdem zdefiniowanego operatora, mówi¹cego np. ¿e jako wartoœci odstaj¹ce nale¿y uznaæ wszystkie wartoœci przekraczaj¹ce $90\%$ wartoœci maksymalnej. W ten sposób mo¿e byæ zdefiniowanych wiele ró¿nych wersji ,,patchowania'', dla przyk³adu, dziel¹c wartoœci na ujemne i dodatnie.

	\begin{figure}[h!]
		\centering
		\includegraphics{img/Patch}
		\caption{Przyk³ad u¿ycia patchowania z operatorem - "wiêkszy od zera"}
		\label{ref:patch}
	\end{figure}

W przeciwieñstwie do innych prac algorytm ten nie zapisuje wyj¹tków wraz z ich pozycjami, umo¿liwiaj¹c lepsze ich skompresowanie w dalszych krokach. Zamiast tego przechowuje w metadanych zapisany bitowo stempel przynale¿noœci poszczególnych elementów wektora do pierwszej lub drugiej tablicy wynikowej. Rozmiar takich metadanych wynosi $(N+32)$ bitów, gdzie $N$ to liczba kompresowanych elementów.
\end{description}

\subsection{Global memory coalescing}


Tablice zaalokowane w pamiêci urz¹dzenia GPU Nvidia s¹ wyrównane do bloków o wielkoœci 256 bajtów przez sterownik urz¹dzenia. Urz¹dzenie mo¿e dostaæ siê do pamiêci przez 32, 64 lub 128 bajtowe transakcje ,które s¹ wyrównane do ich wielkoœci. Odczytuj¹c lub zapisuj¹c do pamiêci globalnej, wa¿ne jest zatem aby w¹tki wymaga³y dostêpu zawsze do kolejnych rekordów tablicy, najlepiej wszystkie nale¿¹ce do tego samego \emph{warp}. Dla osi¹gniêcia takiego rezultatu mo¿na zastosowaæ poni¿szy algorytm obliczania indeksów wejœciowych dla danego w¹tku CUDA. \\
Oznaczmy jako:
\begin{itemize}
	\item $\Sigma$ -- iloœæ przetwarzanych elementów
	\item $\omega$ -- iloœæ w¹tków w grupie
	\item $\kappa$ -- iloœæ elementów w bloku danych
	\item $\lambda$ -- iloœæ elementów przetwarzanych przez pojedynczy w¹tek
	\item $B_{size}$ -- wielkoœæ bloków w¹tków -- (CUDA block size)
	\item $B_{count}$ -- iloœæ bloków -- (CUDA block count)
	\item $w_{g}$ -- iloœæ grup w bloku
	\item $W_{lane}(t) = t_{idx} (mod\ \omega)$ -- indeks w¹tku t w grupie -- (warp lane)
\end{itemize}
\noindent
Za³ó¿my ¿e chcemy przetworzyæ 1MB danych tj. $1024*1024$ elementy, u¿ywaj¹c bloków z 4 grupami po 32 w¹tki ka¿dy, czyli 4 warpy. Ponadto chcemy aby bloki danych mia³y 32 rekordy, a ka¿dy w¹tek przetwarza³ 16 elementów: $\Sigma = 1024*1024$, $\omega = 32$,  $\kappa = 32$, $\lambda = 16$, $w_{g}$ = 4. \\
Bardzo ³atwo mo¿na obliczyæ ile wynosi rozmiar pojedynczego bloku $B_{size}$, oraz iloœæ wszystkich bloków, potrzebnych do przetworzenia wszystkich elementów wektora wejœciowego $B_{count}$:
$$B_{size} = \omega * w_{g} $$,
$$ B_{count} = \frac{\Sigma + B_{size}*\lambda - 1}{B_{size}*\lambda} $$

Przyjmuj¹c pocz¹tkowy indeks bloków danych dla w¹tku $t$ o indeksie $t_{idx}(t)$ z bloku $b_{idx}(t)$ za $\Psi(t) = (t_{idx}(t) - W_{lane}(t)) * \lambda / 32$, indeks bloku danych dla danego w¹tku mo¿na obliczyæ za pomoc¹ wzoru:
$$ d_{b}(t) = b_{idx}(t) * w_{g} * \lambda + \Psi(t) $$
co dla naszego przyk³adu obrazuje rysunek \ref{ref:cuda_data_blocks}.
\begin{figure}[h!]
	\centering
	\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/cuda_data_blocks}
	\caption{Przejœcie z u³o¿enia w¹tków w bloku na bloki danych}
	\label{ref:cuda_data_blocks}
\end{figure}

Ka¿dej grupie w bloku CUDA odpowiada tyle samo bloków danych, przy czym bloki danych s¹ wielkoœci $\kappa$ elementów i ich numery s¹ potrzebne do obliczenia pocz¹tkowego indeksu wejœciowego dla w¹tku, który definiujemy jako $$ \mu_{0}(t) = d_{b}(t)*\kappa + W_{lane}(t) $$
Kolejne indeksy wyliczane s¹ jako przesuniêcia o $\omega$, czyli
$ \mu_{k}(t) = \mu_{0}(t) + k * \omega $, dla $ k \in [1,\kappa-1] $.
Tworzy to podzia³ danych wejœciowych, który zgodnie z przyk³adem obrazuje rysunek \ref{ref:cuda_data_blocks2}.

\begin{figure}[h!]
	\centering
	\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/cuda_data_blocks2}
	\caption{Indeksy danych wejœciowych}
	\label{ref:cuda_data_blocks2}
\end{figure}

Dziêki takiemu u³o¿eniu kolejne w¹tki z tego samego warp, wykonuj¹ odczyt kolejnych rekordów z tablicy Ÿród³owej, poniewa¿ w¹tek 0 odczytuje rekord 0, w¹tek 1 rekord 1, a¿ wreszcie w¹tek $\omega$ rekord $\omega$. Nastêpnie po przesuniêciu o $\omega$ w¹tki ponownie odczytuj¹ dane, które s¹ ze sob¹ s¹siaduj¹ce. Dziêki temu odczyt mo¿e byæ po³¹czony (Global Memory Coalescing\cite{UENG}). £¹czny odczyt mo¿e byæ wielokrotnie szybszy ni¿ odczyty z nie kolejnych indeksów, co jest kluczowe przy budowie bardzo wydajnych algorytmów przetwarzaj¹cych dane na GPU.
W przypadku CUDA grupa powinna mieæ licznoœæ 32, co odpowiada iloœci w¹tków w jednym \emph{warp}.

\newpage

\subsection{Algorytmy kompresji szeregów}
\begin{description}
\item[RLE] -- kodowanie d³ugoœci serii (Run-Length-Encoding) to sposób kompresji polegaj¹cy na zapisie ci¹gów takich samych wartoœci, jako wartoœæ i d³ugoœæ tego ci¹gu. W tym przypadku obie te wartoœci trafiaj¹ do 2 ró¿nych tablic, które nastêpnie mog¹ byæ kompresowane osobno. Szczególnie dobrze sprawdza siê w przypadku posortowanych danych, lub czêsto siê powtarzaj¹cych. Dla przyk³adu wektor ${5,5,5,5,1,1,1,1,17,17,17,17}$ zostanie skompresowany do ${5,1,17}$ oraz ${4,4,4}$. Data technika kompresji jest op³acalna jeœli œrednia d³ugoœæ ci¹gów przekracza 2 ($D_{sr} > 2$). \\ Dana metoda zosta³a zaimplementowana z u¿yciem biblioteki Thrust, stosuj¹c miêdzy innymi metodê \emph{reduce\_by\_key}.
\item[Dict] -- Kolejn¹ grup¹ kompresji s¹ kodowania bazuj¹ce na pomyœle s³ownikowym ($Dict_{K}$). Wykorzystuj¹ one informacjê o licznoœci poszczególnych wartoœci w wektorze. Kompresja s³ownikowa wykorzystuje $K$ najczêœciej wystêpuj¹cych wartoœci i zapisuje ich tablicê w metadanych. Nastêpnie wartoœci z wektora danych s¹ kodowane indeksami w tej tablicy, przy u¿yciu jak najmniejszej liczby bitów $bit_{cnt} = log_{2}(K)$. Reszta niepasuj¹cych wartoœci zapisywana jest do osobnej tablicy, co dzia³a podobnie jak w kodowaniu \emph{Patch}.
\item[Unique, Const] -- Zaimplementowane s¹ tak¿e lekko zoptymalizowane wersje kodowania $Dict_{K}$ dla $K=1$ - \emph{Const}, oraz $K=N_{u}$ - \emph{Unique}, gdzie $N_{u}$ jest liczb¹ unikalnych wartoœci w ca³ym kompresowanym wektorze. Dla przyk³adu, jeœli wszystkie wartoœci s¹ równe, z nielicznymi wyj¹tkami, zostanie wybrane kodowanie \emph{Const}, które zapisze najczêstsz¹ wartoœæ w metadanych i stworzy tablicê wyj¹tków, uzyskuj¹c bardzo wysoki stopieñ kompresji.
\end{description}

\subsubsection{AFL}
Ten rodzaj kodowania nazywany jest kodowaniem o sta³ej d³ugoœci z wyrównaniem. Ogólny pomys³ algorytmu jest bardzo prosty i bazuje na algorytmie NS (null suppression), czyli usuwaniu wiod¹cych zer z liczb i zapisywanie ich na mniejszej iloœci bitów. W tym przypadku iloœæ bitów na których zapisujemy liczby jest znana z góry przed rozpoczêciem kodowania i nie ulega zmianie. Dla uproszczenia przyjmijmy, ¿e kompresujemy liczby naturalne o d³ugoœci 32 bitów, np. \emph{unsigned int}. Wyrównanie polega na grupowaniu wykonawczych w¹tków w grupy o pewnej licznoœci. W naszym przypadku bêdzie to liczba 32, czyli liczba w¹tków nale¿¹cych do jednego \emph{warpa}, z uwagi na wykorzystanie tzw. \emph{³¹cznego dostêpu do pamiêci globalnej CUDA}. Wtedy liczba kompresowanych elementów musi byæ wielokrotnoœci¹ d³ugoœci kodowanego s³owa pomno¿onej przez 32, czyli 1024. Kodowanie przebiega nastêpuj¹co:
\begin{enumerate}
\item Obliczana jest najmniejsza liczba bitów potrzebna do zakodowania wszystkich s³ów w wektorze, nazwijmy go $W$ i oznaczmy liczbê bitów jako $\sigma$:
$$ \sigma = log_{2}(max(W)) + 1 $$
\item Nastêpnie wektor elementów jest dope³niany, aby jego d³ugoœæ by³a wielokrotnoœci¹ 1024, a liczba dope³nionych elementów wraz z potrzebn¹ do zakodowania ka¿dej wartoœci liczb¹ bitów $\sigma$ zapisywana jest do metadanych.
\item Dla ka¿dego w¹tku $t$ CUDA ozn. \emph{$t=thread(b_{idx},t_{idx})$}, co oznacza w¹tek o indeksie $t_{idx}$ z bloku $b_{idx}$, wyznaczany jest pocz¹tkowy indeks danych wejœciowych i wyjœciowych dla tego w¹tku, zgodnie z algorytmem przedstawionym w poprzedniej sekcji.
Wielkoœæ bloków w¹tków ustalmy na $ B_{size} = 32 * 8 $ co sprawi, ¿e ka¿dy blok bêdzie siê sk³ada³ z 8 warpów, a grupy bêd¹ mia³y licznoœæ 32 ($\omega = 32$, $w_{g} = 8$). Ponadto, chcemy aby bloki danych by³y wielkoœci 32 elementów ($\kappa = 32$).
Maj¹c dane wejœciowe o indeksach $ {\mu_{0}, \mu_{1}, ..., \mu_{\kappa-1}} $ w¹tek zapisuje $\sigma$ dolnych bitów ka¿dej z liczb spod tych indeksów, do rekordów tablicy wynikowej. Wielkoœci bloków s¹ tak dobrane, aby ka¿dy w¹tek kodowa³ $\kappa$ liczb u¿ywaj¹c $\sigma$ bitów i otrzymuj¹c w ten sposób $\sigma$ liczb o wielkoœci $\kappa$. Za³ó¿my, ¿e $\kappa = 8$ oraz $\sigma = 3$, wtedy \ref{ref:afl4} obrazuje u³o¿enie danych wejœciowych o wielkoœci 8 bitów, skompresowanych do wielkoœci 3 bitów w wektorze wynikowym, przyjmuj¹c 16 iloœæ w¹tków w grupie ($\omega = 16$). Jak widaæ skompresowane dane idealnie mieszcz¹ siê w 3 rekordach tablicy wynikowej.

\begin{figure}[h!]
	\centering
	\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/AFL4}
	\caption{AFL - zapis w tablicy wyjœciowej}
	\label{ref:afl4}
\end{figure}

Pocz¹tkowy indeks tablicy wynikowej pod który w¹tek ma zapisaæ skompresowane dane, wyliczany jest jako $ \nu_{0}(t) = d_{b}(t) * \sigma + W_{lane}(t) $. Do rekordu zapisywanych jest mo¿liwie najwiêcej bitów (tak jak pokazuje \ref{ref:afl4}), po czym jeœli brak³o miejsca dalsze bity przenoszone s¹ do nastêpnego rekordu, którego indeks wyliczany jest jako $ \nu_{k}(t) = \nu_{0}(t) + k * \omega $, gdzie $ k \in [1,\sigma-1] $. Tutaj równie¿ w¹tki pos³uguj¹ siê ³¹cznym dostêpem do pamiêci.
\item Po skompresowaniu, dane powinny mieæ dok³adnie $\sigma * \Sigma$ bitów d³ugoœci, nie licz¹c metadanych, które mo¿na zapisaæ w dwóch bajtach.

\end{enumerate}

Tak zaimplementowany algorytm okazuje siê byæ oko³o dziesiêciokrotnie szybszy od tradycyjnej implementacji Fixed-Length encoding na CUDA, który jest równowa¿ny tej kompresji z $\omega = 1$.

\subsubsection{GFC}
\emph{GFC} to zaproponowana przez Burtscher et al.\cite{ONEIL} modyfikacja algorytmu \emph{pFPC} kompresji liczb zmiennoprzecinkowych o podwójnej precyzji, który jest równoleg³¹ wersj¹ algorytmu \emph{FPC} zaimplementowan¹ na procesory graficzne. Zamiast operacji XOR na prawdziwej i przewidzianej wartoœci kompresowanej liczby, metoda ta u¿ywa zwyk³ego odejmowania i dodatkowo zapamiêtuje znak, a kompresuje wartoœæ absolutn¹ tej ró¿nicy. Algorytm ten równie¿ stosuje wyrównanie, u¿ywaj¹c ³¹czny dostêp do pamiêci, za to w przeciwieñstwie do algorytmu \emph{AFL} nie wymaga aby iloœæ kompresowanych liczb przez pojedynczy w¹tek by³a podzielna przez 32. Mo¿e byæ to na przyk³ad 15. Blok danych bêdzie mia³ ponownie 32 wartoœci, poniewa¿ ka¿dy \emph{warp} musi przetworzyæ 32 wartoœci, aby uzyskaæ $\sigma$ liczb wynikowych. W tym algorytmie liczba $\sigma$ jest wyznaczana na bie¿¹co dla ka¿dej liczby osobno i wyra¿ona jest w bajtach. Opiszê tutaj wersjê algorytmu dla liczb o pojedynczej precyzji (32-bit) typu np. float. Zatem $\sigma$ mo¿e przybieraæ wartoœci 1, 2, 3 lub 4 i mo¿na zapisaæ j¹ na 2 bajtach. Iloœæ bajtów na których zostanie zapisana liczba x mo¿e byæ przedstawiona w uproszczeniu jako: $ \sigma(x) = log_{2}(x)/8 + 1 $. Poni¿ej zamieszczam prosty pseudokod algorytmu wykonywanego przez ka¿dy w¹tek w kernelu CUDA:
\begin{algorithm}[H]
 \caption{Pseudokod algorytmu kompresji GFC dla w¹tku t}
 \tcc{WEJŒCIE: $data$ - wektor do skompresowania}
 \tcc{WYJŒCIE: $compr$ - skompr. dane, $offsets$ - rozm. paczek}
 \nl $last$ = 0, $i$ = 0\;
 \While{$i < \lambda$}{
    \nl $diff$ = $data[\mu_{i}(t)]$ - $last$\;
    \nl $sign$ = bit znaku liczby $diff$\;
    \nl $diff = abs(diff)$\;
    \nl $minByte = \sigma(diff)$\;
    \nl $size$ = wykonaj sumê prefixow¹ na minByte w warpie\;
    \nl $save(compr, diff, minByte)$ \tcp*{zapisz $minByte$ bajtów liczby $diff$ do tablicy wynikowej}
    \nl $saveMeta(compr, minByte, sign)$ \tcp*{zapisz minByte oraz sign do tablicy wynikowej}
    \nl $off = off + size + 16$\;
    \nl $beg = beg + 32$\;
    \nl $last = data[beg-1]$\;
 }
 \If{$warp_{idx} == 31$}{
    \nl $offsets[warp] = off$\;
 }
 \label{ref:alg_gfc}
\end{algorithm}
\newpage
\noindent
Poszczególne \emph{warp-y} pracuj¹ oddzielnie, kompresuj¹c dane do osobnych paczek. Dane z ca³ego \emph{warp} pakowane s¹ w jedno miejsce, pocz¹wszy od wyliczonego wczeœniej przesuniêcia. W ka¿dej iteracji, \emph{warp} pakuje 32 liczby tworz¹c z nich podpaczkê, poprzedzon¹ ma³ym nag³ówkiem zawieraj¹cym informacje o znakach i liczbie bitów na których jest zapisana ka¿da liczba. Rozmiar tych informacji to 4 bity, wiêc dane w pesymistycznym wypadku mog¹ rozrosn¹æ siê o $l_{w}/2$ bajtów. Podpaczki zapisywane s¹ jedna za drug¹. Poniewa¿ rozmiar skompresowanej paczki nie jest znany w momencie uruchomienia algorytmu, potrzebna jest osobna tablica wynikowa, w której przechowywane s¹ wynikowe wielkoœci paczek. Ponadto trzeba zaalokowaæ tablicê wynikow¹ o wielkoœci
$ c_{s} = (l_{W} + 1)*\frac{9}{2} $ bajtów miejsca.

\begin{figure}[h!]
	\centering
	\hspace*{-0.5cm}\includegraphics[scale=0.75]{img/gfc}
	\caption{wynik dzia³ania algorytmu \emph{GFC} - tablica wyjœciowa}
	\label{ref:gfc}
\end{figure}

Pomimo podobnego podzia³u na bloki danych, powy¿szy rodzaj kompresji znacz¹co ró¿ni siê od metody \emph{AFL}. Iloœæ stworzonych paczek danych przez ten algorytm wynosi $ p_{n} = w_{g} * B_{n} $. Paczki skompresowane przez poszczególne \emph{warp-y} nie przylegaj¹ do siebie, co widaæ na rysunku \ref{ref:gfc}, przez to minusem tej metody jest to, ¿e po kompresji nale¿y przekopiowaæ wszystkie $p_{n}$ paczek, o ró¿nych rozmiarach do tablicy wynikowej. Kopiowanie to jest odpowiednio szybkie dla ma³ej iloœci paczek o wiêkszych rozmiarach. Wtedy zachodzi zale¿noœæ, ¿e kiedy $p_{n}$ roœnie, wydajnoœæ kopiowania maleje, natomiast wydajnoœæ samego algorytmu wzrasta. Jeœli zmniejszymy $p_{n}$ automatycznie musimy zwiêkszyæ $\lambda$, bo $B_{n}$ zale¿y odwrotnie proporcjonalnie od $\lambda$, a im wiêksze $\lambda$, tym wolniejszy jest sam algorytm (pojedyncze w¹tki wykonuj¹ wiêcej pracy).
Warto sprawdziæ zatem, czy napisanie dedykowanego algorytmu kopiowania (jako kernel CUDA), mo¿e przyspieszyæ takie kopiowania danych na GPU, wzglêdem tradycyjnych wywo³añ \emph{cudaMemcpy} w pêtli. Próby zrównoleglenia tych kopiowañ na ró¿nych \emph{stream-ach} na mojej karcie graficznej (GeForce GT 640) skoñczy³y siê gorsz¹ wydajnoœci¹ ni¿ seria kopiowañ na \emph{stream 0}.


\section{Biblioteki}

Projekt sk³ada siê z 4 bibliotek, których zale¿noœci wewnêtrzne pokazane s¹ na rysunku \ref{ref:libs}. Dwie z nich, \emph{CORE} oraz \emph{ENC}, wykorzystuj¹ technologiê CUDA i musz¹ byæ kompilowane za pomoc¹ \emph{nvcc}. Wszystkie korzystaj¹ z biblioteki \emph{Boost} oraz bibliotek do testowania i benchmarków (\emph{GTEST}, \emph{Google Benchmark}).
Poni¿ej znajduje siê tak¿e opis poszczególnych czêœci projektu.

	\begin{figure}[h!]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/Libs}
		\caption{Biblioteki}
		\label{ref:libs}
	\end{figure}

\subsection{TS - TIME SERIES}
Biblioteka definiuj¹ca strukturê szeregu czasowego, udostêpniaj¹ca metody do odczytu i zapisu szeregów z plików binarnych oraz tekstowych o kolumnach rozdzielonych separatorem, na przyk³ad \emph{CSV}. Ponadto umo¿liwia definicjê szeregu czasowego poprzez plik nag³ówkowy o strukturze wierszy: ([nazwa kolumny],[typ kolumny],[precyzja]), w której ka¿dy wiersz definiuje osobn¹ kolumnê. Przyk³adowa treœæ pliku nag³ówkowego zosta³a umieszczona na listingu~\ref{lst:tsheader}.
\begin{lstlisting}[caption=Przyk³adowy plik opisu szeregu czasowego,label={lst:tsheader}]
		timestamp,time,0
		CORE VOLTAGE,float,6
		CPU TEMP,float,6
		GPU TEMP,float,6
\end{lstlisting}
\subsection{CORE}
Tutaj zaimplementowane s¹ wszystkie podstawowe elementy takie jak logowanie, konfiguracja, inteligentny wskaŸnik na pamiêæ CUDA (zaimplementowany w oparciu o \emph{Shared Pointer} z biblioteki \emph{Boost}), operacje na wektorach danych po stronie GPU takie jak histogramy, wyliczanie statystyk itp., a tak¿e bazowe klasy testów i benchmarków wraz z generatorem danych. Zawiera tak¿e ,,scheduler'' równoleg³ych zadañ kompresji.
\subsection{ENC - ENCODINGS}
Encodings to biblioteka mieszcz¹ce wszystkie zaimplementowane w ramach tego projektu algorytmy kodowania i transformacji zaimplementowane na CUDA, potrafi¹ce kodowaæ i dekodowaæ dane wszystkich typów obs³ugiwanych przez ten system (\emph{char, short, int, unsigned int, long, float, double}).
\subsection{OPT - OPTIMIZER}
W³aœciwa biblioteka dla tego projektu mieszcz¹ca optymalizator kompresji, a tak¿e definicjê i implementacjê drzewa kompresji, jak równie¿ drzewa optymalnego (drzewa aktualnie u¿ywanego przez kompresor, które umo¿liwia pewne mutowanie tego drzewa, co zostanie opisane w nastêpnym rozdziale).
\section{Program}
Przyk³adowy program wynikowy, który u¿ywaj¹c optymalizatora kompresji, wielow¹tkowo i równolegle kompresuje wiele kolumn szeregu czasowego, podanego jako plik wejœciowy. Plik wejœciowy jest zaczytywany paczkami i w tym samym czasie czêœci ju¿ skompresowane mog¹ byæ zapisywane do podanego pliku wyjœciowego. Dok³adny opis tego algorytmu znajduje siê na koñcu rozdzia³u 3. Argumenty programu:
\begin{itemize}
\item \emph{--compress} lub \emph{-c}: opcja kompresji (nast¹pi kompresja pliku wejœciowego)
\item \emph{--decompress} lub \emph{-d}: opcja dekompresji (nast¹pi dekompresja pliku wejœciowego)
\item \emph{--header} lub \emph{-h} \emph{[<œcie¿ka>]}: podanie œcie¿ki do pliku zawieraj¹cego opis szeregu jak wy¿ej \ref{lst:tsheader}.
\item \emph{--input} lub \emph{-i} \emph{[<œcie¿ka>]}: podanie œcie¿ki do pliku wejœciowego
\item \emph{--output} lub \emph{-o} \emph{[<œcie¿ka>]}: podanie œcie¿ki do pliku wyjœciowego
\item \emph{--generate} lub \emph{-g}: -- wygeneruj przyk³adowe pliki danych
\item \emph{--padding} lub \emph{-p} \emph{[<ró¿nica>]}: w przypadku gdy wiersze szeregu w pliku binarnym s¹ wyrównane do jakieœ wielkoœci, podajemy w ten sposób ró¿nicê wzglêdem ich rzeczywistej wielkoœci, np. jeœli dane zajmuj¹ 12 bajtów, a s¹ wyrównane do 16, powinniœmy uruchomiæ program z opcj¹ \emph{-p 4}.
\end{itemize}

\chapter{Optymalizator kompresji}

W tym rodziale opiszê algorytm nazwany roboczo \emph{Online Stat compression Planner}, który bêdzie uczy³ siê budowaæ jak najlepsze drzewo kompresji na podstawie nap³ywaj¹cych danych, jednoczeœnie je kompresuj¹c. Zatem wydajnoœæ - compression ratio, powinno z czasem rosn¹æ, a¿ znajdzie siê na optymalnym poziomie. Ponadto algorytm ten przeszukuj¹c przestrzeñ ciekawych drzew kompresji i testuj¹c je na ma³ym fragmencie danych, bêdzie mia³ szansê znaleŸæ optymalne drzewo ju¿ na pocz¹tku swojego dzia³ania. Jednak w momencie zmiany charakterystyki danych, algorytm powinien zareagowaæ mutuj¹c drzewo, zmieniaj¹c jego wêz³y, aby dostosowaæ go do nowych danych. Na uwagê zas³uguje fakt, ¿e wszystkie dane na których operuj¹ optymalizator oraz drzewo, zawsze znajduj¹ siê na GPU, w celu minimalizacji liczby kopiowañ przez szynê PCI-E. Dodatkowo w oparciu o \emph{Shared Pointer} z biblioteki \emph{Boost} zaimplementowano inteligentne wskaŸniki na wektory danych w globalnej pamiêci GPU. Takie wskaŸniki przechowuj¹ce tablicê bajtów bêdê dalej nazywa³ SCBP\footnote{SCBP - inteligentny wskaŸnik na tablicê bajtów w globalnej pamiêci GPU (Shared Cuda Byte Pointer)}.

\section{Kodowanie}
Wszystkie algorytmy kompresji zosta³y zaimplementowane jako klasy dziedzicz¹ce po
abstrakcyjnej klasie kodowania (\emph{Encoding}), implementuj¹c metody kompresji i
dekompresji dla wszystkich typów wspieranych przez system (optymalizator).
Dla nas najwa¿niejsze s¹ dwie metody:
\begin{description}[noitemsep,nolistsep]
\item[Encode] -- przyjmuje dane do kompresji jako SCBP oraz typ danych do kompresji.
Metoda ta kompresuje dane i zwraca wektor wskaŸników SCBP d³ugoœci 2 lub 3, z których pierwszy jest zawsze metadanymi.
\item[Decode] -- przyjmuje w zasadzie to co zwraca \emph{Encode} oraz typ danych,
a zwraca zdekodowane dane w postaci SCBP.
\end{description}
Obiekt ka¿dego kodowania mo¿e byæ stworzony za pomoc¹ fabryki, podaj¹c jego typ oraz typ danych jakie ma kompresowaæ.
Aby kodowania, a raczej ich wynik by³ mo¿liwy do zserializowania i w nastêpstwie pozwala³ odtworzyæ schemat u¿yty do kompresji, przed metadanymi wyniku dodawany jest header w postaci: \emph{[Typ Kodowania (16 bit), Typ danych (16 bit),
D³ugoœæ metadanych (32 bit)]}, nazwijmy go EH\footnote{EH - header metadanych wyniku kodowania}.
Ponadto kodowanie umo¿liwia sprawdzenie jaki jest jego typ wynikowy oraz ile skompresowanych czêœci zwraca, np. metody \emph{PATCH} lub \emph{DICT} zwracaj¹ po 2 wyniki.

\section{Drzewo kompresji}
    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.55]{img/tree}
        \caption{Schemat drzewa kompresji}
        \label{ref:tree}
    \end{figure}
Drzewo kompresji jest implementacj¹ idei kompresji kaskadowej. Wêz³owi drzewa odpowiada kompresja
danego typu. Wêze³ ma tyle dzieci ile wyników zwraca kodowanie które reprezentuje.
Dodatkowy typ kodowania zosta³ dodany aby oznaczyæ liœcie takiego drzewa. Przyk³adowe drzewo
zosta³o przedstawione na rysunku \ref{ref:tree}. Drzewo mo¿e byæ tak¿e zapisane jako ci¹g typów kodowañ
(który dalej bêdê nazywa³ \emph{TreePath}, na przyk³ad pokazane drzewo mo¿na przedstawiæ jako:
\newline
\small{\textit{PATCH, RLE, AFL, NONE, SCALE, GFC, NONE, FLOAT\_TO\_INT, CONST, AFL, NONE}}
\newline
Schemat ten jest o tyle wa¿ny, ¿e w ten sposób bêd¹ u³o¿one fragmenty skompresowanych danych przez algorytm kompresji drzewem.

\subsection{Algorytm kompresji drzewem}
    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.55]{img/tree_compress}
        \caption{Schemat przebiegu algorytmu kompresji drzewem}
        \label{ref:tree_compress}
    \end{figure}
Algorytm kompresji drzewem jest rekurencyjny pocz¹wszy od korzenia drzewa i za wejœcie
dostaje tylko dane do skompresowania w postaci SCBP. Ogólna idea polega na kompresowaniu
danych odpowiednim koderem reprezentowanym przez wierzcho³ek drzewa i przekazywaniu wyników
dzieciom tego wêz³a. Dzia³anie kompresji opisuje algorytm \ref{alg:tree_compress}.

\begin{algorithm}[H]
 \caption{Pseudokod algorytmu kompresji drzewem}
 \SetKwFunction{algoN}{$Node \mapsto Compress$}
 \SetKwFunction{algoT}{$Tree \mapsto Compress$}
 \SetKwProg{myalg}{Metoda}{}{}
 \KwIn{DATA -- dane do skompresowania (GPU)}
 \KwOut{RES -- skompresowane dane (GPU), wynik w postaci wektora SCBP}
 \myalg{\algoN{}}{
    \nl $X \gets$ wêze³ na którym wywo³ano metodê\;
    \nl $K \gets$ pobierz koder typu reprezentowanego przez wêze³ $X$ z fabryki\;
    \nl $COMPR \gets$ zakoduj $DATA$ u¿ywaj¹c kodera $K$\;
    \nl $EH \gets$ stwórz odpowiedni nag³ówek kodowania\;
    \nl do³¹cz $EH$ na pocz¹tku wektora $COMPR$\;
    \uIf{$X$ jest liœciem}{
        \nl dopisz $COMPR$ do $RES$\;
    }
    \Else{
        \ForEach{$D$ dziecka $X$}{
            \nl $CHILD\_RES \gets$ wywo³aj metodê Compress na $D$\;
            \nl dopisz $CHILD\_RES$ na koñcu wektora $RES$\;
        }
    }
    \nl uaktualnij compression ratio uzyskane przez aktualne poddrzewo\;
    \nl \Return{$RES$}\;
 }
 \setcounter{AlgoLine}{0}
 \myalg{\algoT{}}{
    \nl $ROOT \gets$ pobierz korzeñ drzewa\;
    \nl $VEC \gets$ wykonaj metodê $Compress(DATA)$ na $ROOT$\;
    \If{ustawiony wskaŸnik na statystyki}{
        \nl zaktualizuj statystyki; \tcp*{opisane w 2 fazie optymalizatora}
    }
    \nl $RES \gets$ po³¹cz wektor wyników $VEC$ w jeden ci¹g pamiêci\;
    \nl \Return{$RES$}\;
 }
 \label{alg:tree_compress}
\end{algorithm}

Po skompresowaniu danych za pomoc¹ korzenia drzewa uzyskujemy wektor kawa³ków skompresowanych danych
oraz nag³ówków. Ostatni¹ czynnoœci¹ w algorytmie jest po³¹czenie tych danych w jeden ci¹g wynikowy
(pojedyncza tablica zaalokowana na GPU). Na rysunku \ref{ref:tree_compress} widaæ prosty przebieg dzia³ania
algorytmu. Jako \emph{E\#} oznaczono nag³ówki doczepiane z ró¿nych kodowañ.
Jak widaæ, nag³ówki odzwierciedlaj¹ strukturê drzewa i s¹ to¿same z \emph{TreePath},
pomijaj¹c kawa³ki skompresowanych danych (\emph{A, B, C}). Dziêki temu mo¿na odtworzyæ drzewo do dekompresji.

\subsection{Algorytm dekompresji drzewem}
Algorytm dekompresji drzewem jest bardziej skomplikowany ni¿ kompresja i sk³ada siê z
dwóch faz: rekonstrukcji struktury drzewa i w³aœciwej dekompresji drzewem. Ogólny schemat
ca³oœci algorytmu pokazany jest na rysunku \ref{ref:tree_decompress}.

\subsubsection{Rekonstrukcja drzewa}
Kolejny algorytm rekurencyjny (patrz algorytm \ref{alg:rec_tree}), który na wejœciu dostaje SCBP ze skompresowanymi danymi oraz
offset - referencja do parametru okreœlaj¹cego po³o¿enie ju¿ odczytanego fragmentu danych, tj.
od jakiego bajtu nale¿y czytaæ dalsze dane wejœciowe. Idea algorytmu polega na odczytywaniu
kolejnych nag³ówków \emph{EH} i budowaniu na ich podstawie drzewa, odpowiadaj¹cego drzewu u¿ytemu
do kompresji.

\begin{algorithm}[H]
 \scriptsize
 \caption{Pseudokod algorytmu rekonstrukcji drzewa}
 \SetKwFunction{algo}{$Tree \mapsto DecompressNodes$}
 \SetKwProg{myalg}{Metoda}{}{}
 \KwIn{DATA -- skompresowane dane (GPU), OFFSET -- przesuniêcie (REF)}
 \KwOut{NODE -- zrekonstruowany wêze³ drzewa}
 \myalg{\algo{}}{
    \nl $EH \gets$ odczytaj nag³ówek z wejœcia\;
    \nl $OFFSET += SIZEOF(EH)$\;
    \nl $NODE \gets$ stwórz wêze³ typu wskazywanego przez $EH$\;
    \nl $MET\_SIZE \gets$ pobierz rozmiar metadanych z $EH$\;
    \nl $MET \gets$ odczytaj metadane o rozmiarze $MET\_SIZE$\;
    \nl $OFFSET += MET\_SIZE$\;
    \nl ustaw metadane w $NODE$ na $MET$\;
    \uIf{$NODE$ ma typ \emph{NONE}, czyli jest liœciem}{
        \nl $SIZE \gets$ odczytaj z $MET$ rozmiar skompresowanych danych\;
        \nl $DATA \gets$ odczytaj z wejœcia $SIZE$ bajtów\;
        \nl ustaw dane w wêŸle $NODE$ na $DATA$\;
        \nl $OFFSET += SIZE$\;
    }
    \Else{
        \nl $K \gets$ pobierz koder o typie wskazywanym przez $EH$\;
        \nl $N \gets$ pobierz iloœæ wyników zwracanych przez koder $K$\;
        \For{i=0 to N}{
            \nl $CHILD\_NODE \gets DecompressNodes(DATA, OFFSET)$\;
            \nl dodaj $CHILD\_NODE$ jako dziecko $NODE$\;
        }
    }
    \nl \Return{$NODE$}\;
 }
 \label{alg:rec_tree}
\end{algorithm}
\normalsize

\newpage
\subsubsection{Dekompresja}
Po odtworzeniu drzewa na korzeniu wywo³ywana jest metoda \emph{Decompress}, która nie
przyjmuje ¿adnych parametrów, za to zwraca zdekodowane dane w postaci SCBP. Pokazuje
to algorytm \ref{alg:tree_decompress}.

\begin{algorithm}[H]
 \scriptsize
 \caption{Pseudokod algorytmu dekompresji drzewem}
 \SetKwFunction{algo}{$Node \mapsto Decompress$}
 \SetKwProg{myalg}{Metoda}{}{}
 \KwIn{}
 \KwOut{RES -- zdekodowane dane (GPU)}
 \myalg{\algo{}}{
    \nl $X \gets$ wêze³ na którym wywo³ano metodê\;
    \nl $K \gets$ pobierz koder typu reprezentowanego przez wêze³ $X$ z fabryki\;
    \nl $MET \gets$ pobierz metadane zapisane w wêŸle $X$\;
    \nl $W \gets$ stwórz wektor wskaŸników SCBP i dodaj do niego $MET$\;
    \uIf{$X$ jest liœciem}{
        \nl $DATA \gets$ pobierz dane zapisane w wêŸle $X$\;
        \nl dodaj $DATA$ na koñcu wektora $W$\;
    }
    \Else{
        \ForEach{$D$ dziecko $X$}{
            \nl $CHILD\_RES \gets$ wykonaj metodê $Decompress()$ na $X$\;
            \nl dodaj $CHILD\_RES$ na koñcu wektora $W$\;
        }
    }
    \nl $RES \gets$ u¿yj kodera $K$ do zdekodowania wektora $W$\;
    \nl \Return{$RES$}\;
 }
 \label{alg:tree_decompress}
\end{algorithm}
\normalsize

Podsumowuj¹c, jest to implementacja kaskadowej kompresji (rekurencyjnej z u¿yciem drzew jako reprezentacji).
Dodatkowo drzewa te posiadaj¹ wskaŸnik na statystyki drzewa i mog¹ je uaktualniaæ, co bêdzie szerzej
opisane w czêœci poœwiêconej 2 fazie algorytmu optymalizatora.
    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.55]{img/tree_decompress}
        \caption{Schemat przebiegu algorytmu dekompresji drzewem}
        \label{ref:tree_decompress}
    \end{figure}

\section{Statystyki}

Warunkiem podejmowania dobrych decyzji przez optymalizator jest znajomoœæ charakterystyki danych na których operuje. G³ówne zastosowanie statystyk w tym systemie, opiera siê na przesiewaniu wszystkich mo¿liwych drzew do tych najistotniejszych, które mog¹ uzyskaæ dobry wspó³czynnik kompresji. Ponadto, niektóre statystyki wykorzystywane s¹ przez same kodowania, aby odpowiednio dzia³aæ. W tym systemie zaimplementowano statystyki takie jak:
\begin{enumerate}
\item \emph{IsFloatingPoint} -- czy dane maj¹ typ zmiennoprzecinkowy czy ca³kowity
\item \emph{Sorted} -- czy dane s¹ posortowane (obojêtnie czy rosn¹co czy malej¹co)
\item \emph{Min} i \emph{Max} -- wartoœæ minimalna i maksymalna w zbiorze danych
\item \emph{Precision} -- maksymalna dok³adnoœæ (precyzja) danych, czyli iloœæ miejsc po przecinku
\item \emph{MinBitLength} -- minimalna liczba bitów na których mo¿na zakodowaæ ka¿d¹ liczbê ze zbioru
\item \emph{Size} -- rozmiar danych
\item \emph{RleMetric(N)} -- statystyka dla kodowania RLE opisana dok³adnie w nastêpnej podsekcji
\item \emph{Dictionary Counter} -- histogram wszystkich unikalnych wartoœci ze zbioru
\item \emph{Mean} -- œrednia arytmetyczna liczb w zbiorze
\end{enumerate}

\subsection{Metryka RLE}
\begin{definition}
Metryk¹ RLE bêdziemy nazywaæ d³ugoœæ maksymalnych ci¹gów równych liczb, nie d³u¿szych ni¿ N w danych D, ozn. $RLE_{M}(D, N)$.
\end{definition}
Wskazuje na zasadnoœæ u¿ycia kodowania RLE do jakiœ danych. Mo¿na uznaæ, ¿e jeœli $RLE_{M}(D, N) > N/2$ to warto u¿yæ RLE do kodowania danych $D$. Dla przyk³adu, jeœli weŸmiemy $N=2$ oraz dane D: $1112234444555555$, wtedy odczytane ci¹gi równych liczb nie d³u¿sze ni¿ 2 wynosz¹: $22121122212222$, z czego œrednia jest równa $\frac{26}{15} \approx 1,7$. Natomiast podstawiaj¹c $N=4$: $3212114321444$, œrednia wyniesie $\frac{32}{13} \approx 2,5$. W obu wypadkach wychodzi zatem, ¿e powinniœmy u¿yæ RLE do kompresji takich danych. Daje to wyobra¿enie o œredniej d³ugoœci ci¹gów równych liczb w danych, a ponadto jest bardzo wydajne obliczeniowo. Wyliczanie takiej statystyki jest trywialnie równoleg³e, poniewa¿ mo¿na w ka¿dym w¹tku wyliczaæ ci¹g pocz¹wszy od innego indeksu, niezale¿nie. Pseudokod wyliczania ci¹gu dla pojedynczego w¹tku CUDA pokazuje algorytm \ref{alg:rle_metric}. PóŸniej wystarczy obliczyæ sumê, korzystaj¹c na przyk³ad z gotowej funkcji z biblioteki \emph{Thrust}.

\begin{algorithm}[H]
 \small
 \caption{Obliczanie metryki RLE}
 \KwIn{DATA -- wektor danych wejœciowych\;
 N -- wspó³czynnik metryki RLE (maks. d³ugoœæ sprawdzanego ci¹gu)\;
 IDX -- globalny indeks w¹tku (unikalny)
 }
 \KwOut{LENGTHS -- d³ugoœci ci¹gów równych liczb}
 \SetKwFunction{algo}{GetRunLenN}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
 	\nl \If{$IDX >= length(DATA)-N$}{ \nl \Return{} }
 	\nl $num \gets 1, out \gets 1, last \gets 1$\;
 	\nl \For{$i=1$ to $N$}{
 		\nl $out \gets DATA[IDX] == DATA[IDX+i]$\;
 		\nl $num += out \& last$\;
 		\nl $last \gets out$\;
 	}
 	\nl $LENGTHS[IDX] \gets num$\;
 }
 \label{alg:rle_metric}
\end{algorithm}
\normalsize

\subsection{Precyzja}
Kolejn¹ wa¿n¹ statystyk¹ dla liczb zmiennoprzecinkowych jest precyzja, która odnosi siê do tego, czy warto zastosowaæ zmianê wartoœci na typ ca³kowitoliczbowy, stosuj¹c przemno¿enie\footnote{patrz kodowanie \emph{FLOAT\_TO\_INT}} przez odpowiedni¹ potêgê liczby 10. Analogicznie do metryki RLE, algorytm wyliczania precyzji jest trywialnie równoleg³y, a obliczanie precyzji pokazuje algorytm \ref{alg:precision}.

\begin{algorithm}[H]
 \small
 \caption{Obliczanie precyzji}
 \KwIn{VALUE -- wartoœæ u³amkowa\;
 MAX\_PREC -- maksymalna precyzja
 }
 \KwOut{PREC -- precyzja}
 \SetKwFunction{algo}{GetPrecision}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
	\nl $E \gets 1$\;
	\nl $MP \gets 10^{MAX\_PREC}$\;
	\nl \While{$(\frac{round(VALUE*E)}{E} \neq VALUE)\ \&\&\ (E < MP)$}{
		\nl $E \gets E*10$\;
	}
	\nl \Return{$\frac{log_{f}(E)}{log{f}(10)}$}\;
 }
 \label{alg:precision}
\end{algorithm}
\normalsize
\noindent
W systemie w bardzo ³atwy sposób mo¿na implementowaæ dodatkowe statystyki i udostêpniaæ je do optymalizatora w celu implementacji dodatkowych regu³.

\section{Optymalizator}
Algorytm optymalizatora kompresji maksymalizuje wspó³czynnik kompresji, jednoczeœnie staraj¹c siê wybraæ jak najmniejsze i najni¿sze drzewo kompresji. G³ównym pomys³em jest tworzenie statystyk krawêdzi drzewa kompresji o kszta³cie pe³nego drzewa binarnego (z tego wzglêdu kodowania mog¹ zwracaæ co najwy¿ej 2 wyniki). Nic nie stoi jednak na przeszkodzie, aby algorytm ten uogólniæ na kodowania zwracaj¹ce dowolnie du¿¹ iloœæ wyników.
Algorytm sk³ada siê z 3 faz, a jego zarys wygl¹da nastêpuj¹co:
\begin{enumerate}
\item Dla ma³ego fragmentu danych generujemy najciekawsze drzewa kompresji, zapisuj¹c statystyki krawêdzi w drzewie binarnym, po czym wybieramy drzewo o najlepszym wspó³czynniku kompresji z niewielk¹ poprawk¹ od wysokoœci drzewa.
\item Kompresujemy odpowiednio du¿¹ paczkê danych u¿ywaj¹c drzewa ustawionego jako optymalne i odpowiednio aktualizujemy statystyki krawêdzi podczas kompresji.
\item Jeœli kompresja siê pogorszy³a, zmieniamy drzewo, wymieniaj¹c odpowiednie poddrzewo na lepsze wed³ug statystyk krawêdzi.
\end{enumerate}

\subsection{Faza 1 - generowanie}
Ten fragment opisuje rekurencyjny algorytm generowania interesuj¹cych drzew na postawie statystyk.
Wyjaœniê najpierw co to znaczy, ¿e drzewo jest interesuj¹ce.
\begin{definition}[Interesuj¹ce drzewo]
Drzewo, którego ka¿dy wêze³ zosta³ wybrany jako dobra kontynuacja wêz³a poprzedniego, wedle okreœlonych regu³.
\end{definition}
\noindent
Regu³y tworzone s¹ na podstawie statystyk danych, które dany wêze³ ma dostaæ do kompresji, typu poprzedzaj¹cej go kompresji oraz typu danych. Dany jest tak¿e aktualny poziom drzewa na którym ma siê znaleŸæ nowy wêze³. Metodê zwracaj¹c¹ dobre kontynuacje nazwana roboczo \emph{GetContinuations}, zwraca  listê typów kodowañ, które spe³niaj¹ regu³y. Kilka przyk³adów:
\begin{itemize}
\item Jeœli poprzednikiem kodowania nie by³o \emph{FLOAT\_TO\_INT}, dane maj¹ nisk¹ precyzjê i niewielk¹ wartoœæ maksymaln¹, a ponadto typ danych to \emph{double}, to dodaj do listy kontynuacji typ kodowania \emph{FLOAT\_TO\_INT}, poniewa¿ jest zasadne.
\item Jeœli poprzednim kodowaniem by³o \emph{GFC} albo \emph{AFL}, to nie kompresuj ju¿ wiêcej i jako jedyn¹ mo¿liw¹ kontynuacjê zwróæ NONE. Jeœli nie, a typ danych to \emph{float} lub \emph{double} to dodaj \emph{GFC} do listy mo¿liwych kontynuacji, w p.p. dodaj \emph{AFL}.
\end{itemize}

Algorytm kompresuje dane w trakcie generowania drzew oraz jednoczeœnie oblicza i uaktualnia statystyki krawêdzi w drzewie binarnym (o tym w fazie 2). Tê fazê optymalizatora implementuje metoda \emph{FullStatisticsUpdate}, której pseudokod pokazany jest jako algorytm \ref{alg:faza1}.

\begin{algorithm}[H]
 \scriptsize
 \caption{Faza 1 algorytmu optymalizatora}
 \KwIn{DATA -- ma³a paczka danych\;
 ET -- typ kompresji, DT -- typ danych\;
 LEVEL -- aktualny poziom drzewa
 }
 \KwOut{RES -- lista interesuj¹cych drzew z ich wynikami}
 \SetKwFunction{algo}{FullStatisticsUpdate}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
	\nl $STAT \gets$ policz statystyki dla $DATA$\;
	\nl $RES \gets$ pusty wektor drzew\;
	\nl $CONT \gets$ wywo³aj $GetContinuations(ET, DT, STAT, LEVEL)$ \tcp{pobierz mo¿liwe kontynuacje}
	\ForEach{$C$ from $CONT$}{
		\nl $T \gets$ stwórz drzewo o jednym wêŸle reprezentuj¹cym kodowanie $C$ z typem danych $DT$\;
		\nl $COMPR \gets$ zakoduj dane $DATA$ u¿ywaj¹c $T$\;
		\nl $DT \gets$ typ danych zwracany przez kodowanie $C$\;
		\nl zaktualizuj w $T$ uzyskany wspó³czynnik kompresji\;
		\eIf{liczba wyników zwracana przez $C$ jest równa 1}{
			\nl $PART1 \gets$ wywo³aj $FullStatisticsUpdate(COMPR[1], C, DT, LEVEL+1)$\;
			\nl $PART1 \gets$ wywo³aj $CrossTrees(T, PART1, length(DATA), length(COMPR[0])$\;
		}(\tcp*[f]{jest równa 2}){
			\nl $PART1 \gets$ wywo³aj $FullStatisticsUpdate(COMPR[1], C, DT, LEVEL+1)$\;
			\nl $PART2 \gets$ wywo³aj $FullStatisticsUpdate(COMPR[2], C, DT, LEVEL+1)$\;
			\nl $PART1 \gets$ wywo³aj $CrossTrees(T, PART1, PART2, length(DATA), length(COMPR[0])$\;
		}
		\If{$PART1$ jest pusty}{
			\nl dodaj $T$ do $PART1$\;
		}
		\Else{
			\nl dopisz $PART1$ na koñcu wektora $RES$\;
		}
	}
	\nl \Return{$RES$}\;
 }
 \label{alg:faza1}
\end{algorithm}
\normalsize
\noindent
Metody \emph{CrossTrees} tworz¹ wszystkie mo¿liwe kombinacje, w których $T$ jest wierzcho³kiem, a drzewa z kolejnych dwóch argumentów (wektory drzew), jego poddrzewami. Przyk³adem dzia³ania tej metody jest rysunek \ref{ref:phase1}. Dodatkowo uaktualniany jest wspó³czynnik kompresji po³¹czonych drzew.

    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.75]{img/phase1}
        \caption{Przyk³ad dzia³ania metody CrossTrees}
        \label{ref:phase1}
    \end{figure}
\noindent
Zatem w skrócie wyliczamy statystyki i na ich podstawie przewidujemy mo¿liwe wêz³y potomne, aby drzewo
by³o interesuj¹ce, a nastêpnie kompresujemy danym kodowaniem dane i dla nich rekurencyjnie wyznaczamy interesuj¹ce drzewa. Nastêpnie ³¹czymy wyniki we wszystkie mo¿liwe kombinacje ale zachowuj¹c hierarchiê i do³¹czamy do mo¿liwych rozwi¹zañ. Przy okazji, wiemy jak dobrze ka¿de skonstruowane drzewo zachowuje siê dla danych wejœciowych. Finalnie drzewo o najlepszej statystyce wybierane jest jako optymalne.

\subsection{Faza 2 - kompresja}
W tej fazie w³aœciwe dane (du¿a paczka danych) s¹ kompresowane przez drzewo wybrane jako optymalne, ale
co wa¿niejsze uaktualniane s¹ statystyki krawêdzi drzewa binarnego. Opiszê jak wygl¹daj¹ te
statystyki i jak s¹ uaktualniane. Wa¿ne jest równie¿, ¿e drzewo optymalne pamiêta ostatni¹ kopiê statystyk, która jest tworzona w momencie ustawienia nowego drzewa jako optymalne.
    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.75]{img/bin_tree}
        \caption{Przyk³ad numerowania krawêdzi w drzewie binarnym i kompresji}
        \label{ref:bintree}
    \end{figure}
\noindent
Krawêdzie w drzewie kompresji odpowiadaj¹ parom kompresji na pewnym miejscu w odpowiadaj¹cym mu pe³nym drzewie binarnym, co pokazuje rysunek \ref{ref:bintree}. Z za³o¿enia, chcemy analizowaæ pary kompresji, poniewa¿ ka¿da wczeœniejsza kompresja wp³ywa na nastêpn¹ i niejako przygotowuje dla niej dane.
Dla przyk³adu, czêsto okazuje siê, ¿e kompresja \emph{AFL} dzia³a dla jakiœ danych bardzo s³abo, ale poprzedzona
kodowaniem \emph{DELTA} lub \emph{PATCH} osi¹ga bardzo dobre wyniki, zaœ poprzedzona kodowaniem \emph{DICT} ma
wynik jeszcze s³abszy. Wtedy dwie wczeœniejsze konfiguracje bêd¹ mia³y na tym miejscu wysokie statystyki, a trzecia niskie.

Ka¿dej parze nastêpuj¹cych po sobie kompresji da siê przypisaæ krawêdŸ w pe³nym drzewie binarnym o tej, lub
wiêkszej wysokoœci. Wynika to z tego, ¿e ka¿da kompresja mo¿e mieæ co najwy¿ej dwójkê nastêpców (dzieci).
Ponadto jeœli krawêdŸ ma indeks $i$, to ³atwo policzyæ indeksy krawêdzi odchodz¹cych od niej jako $2*(i+1)$ oraz $2*(i+1)+1$. Program konstruuje tabelê statystyk, w której pod indeksem $\lambda$ bêd¹ przechowywane statystyki
par kompresji na miejscu $\lambda$ w drzewie binarnym.

Dla danej pary kompresji na wybranym miejscu w drzewie, statystyka jest liczona jako œrednia arytmetyczna, ze
starej wartoœci statystyki (na pocz¹tku ma wartoœæ 1.0) oraz uzyskanego przez poddrzewo odpowiadaj¹ce danej
krawêdzi wspó³czynnika kompresji:
$$ \alpha_{new} = \frac{\alpha_{old} + CR_{e}}{2} $$
Dla przyk³adu, jeœli krawêdŸ $1$ z par¹ kompresji $(A,B)$ uzyska³a $CR_{e} = 2$ a potem $3$, to statystyka dla tej pary na tej krawêdzi bêdzie wynosi³a $\alpha_ = \frac{\frac{1+2}{2}+3}{2} = 2,25$. Taka statystyka sprawia, ¿e nigdy nie bêdzie wiêksza ni¿ najlepszy wspó³czynnik kompresji uzyskany przez t¹ parê oraz, ¿e statystyka ta d¹¿y do tego wspó³czynnika (w granicy), jeœli jest sta³y. W ca³ym programie wspó³czynnik kompresji krawêdzi $(A,B)$ ozn. $CR_{e}$ liczony jest jako œrednia arytmetyczna wspó³czynników kompresji osi¹gniêtych przez poddrzewo definiowane
przez wêze³ $A$ i poddrzewo definiowane przez $B$: $CR_{e} = \frac{CR(A) + CR(B)}{2}$. Natomiast wspó³czynnik kompresji dla wêz³a jest stosunkiem wielkoœci danych wejœciowych do danych wyjœciowych po kompresji. Dziêki temu
wspó³czynnik kompresji krawêdzi w lepszy sposób definiuje jakoœæ takiej pary kompresji w drzewie, zmniejszaj¹c
wp³yw jak¹ ma jakoœæ kompresji drugiego poddrzewa odchodz¹cego od $A$ na statystykê krawêdzi do której to poddrzewo nie nale¿y.

    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=1]{img/stats}
        \caption{Tablica statystyk krawêdzi}
        \label{ref:bintree}
    \end{figure}

Statystyki krawêdzi uaktualniane s¹ w ten sposób podczas trwania ka¿dej kompresji, o ile wskaŸnik na statystyki ustawiony jest w drzewie. W momencie ukoñczenia kompresji statystyki powinny ju¿ byæ aktualne.

\subsection{Faza 3 - poprawa}
Po dokonaniu kompresji na du¿ym kawa³ku danych lub nawet kilku paczkach, jesteœmy w stanie du¿o lepiej stwierdziæ, jak dobrze dane drzewo kompresji siê sprawuje. Jeœli jakoœæ ta wzros³a lub pozosta³a bez zmian, znaczy to ¿e nic nie trzeba zmieniaæ i wybrane drzewo kompresji jest optymalne. W przeciwnym przypadku nale¿y drzewo poprawiæ, stosuj¹c now¹ wiedzê, uzyskan¹ w formie statystyk krawêdzi z nowych danych.
Aby to osi¹gn¹æ algorytm sprawdza statystyki krawêdzi i wybiera krawêdŸ o najmniejszym indeksie dla której statystyka siê pogorszy³a (drzewo wybrane jako optymalne trzyma kopiê statystyk oraz wspó³czynnika kompresji z momentu wybrania go na optymalne). Mo¿na te¿ w tym momencie wybieraæ krawêdŸ dla której statystyka pogorszy³a siê
najbardziej np. procentowo. Wybran¹ krawêdŸ kasujemy (usuwamy j¹ z drzewa razem z poddrzewem). Na miejscu usuniêtej krawêdzi, zach³annie, wstawiamy parê kompresji o najwiêkszej statystyce dla tej krawêdzi. Podobnie
wstawiamy jej dzieci, a¿ do limitu wysokoœci drzewa. Proces ten dok³adniej opisuj¹ algorytmy \ref{alg:faza2_correct} i \ref{alg:faza2_replace}, z prostym przyk³adem w formie rysunku \ref{ref:mutate}.

    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.5]{img/mutate}
        \caption{Przyk³ad numerowania krawêdzi w drzewie binarnym i kompresji}
        \label{ref:mutate}
    \end{figure}

Wymieniaj¹c krawêdŸ, algorytm w zasadzie wymienia poddrzewo w grafie, zaczynaj¹c od pocz¹tku lub koñca krawêdzi (oszczêdzaj¹c pocz¹tek). Na rysunku \ref{ref:mutate} widzimy oba przypadki. Na przyk³ad, w pierwszej \emph{mutacji} tylko
jedna odnoga \emph{DICT} zosta³a zmieniona, podczas gdy w przejœciu drugim wymianie podlega ca³a krawêdŸ \emph{AFL-NONE}.

\begin{algorithm}[H]
 \tiny
 \caption{Faza 2 - poprawianie drzewa (TryCorrectTree)}
 \KwIn{OPT -- drzewo wybrane jako optymalne, $STAT_{new}$ -- aktualne statystyki\;}
 \SetKwFunction{algo}{TryCorrectTree}
 \SetKwProg{myalg}{Funkcja}{}{}
 \tcc{X.TO i X.FROM, X.NO to wêze³ koñcowy, pocz¹tkowy oraz numer krawêdzi X}
 \myalg{\algo{}}{
	\nl $CR_{new} \gets$ pobierz aktualny wspó³czynnik kompresji drzewa $OPT$\;
	\nl $CR_{old} \gets$ pobierz historyczny wspó³czynnik kompresji $OPT$\;
	\If{$CR_{new} \geq CR_{old}$}{
		\nl \Return{false}\;
	}
	\nl $STAT_{OLD} \gets$ pobierz historyczne statystyki z $OPT$\;
	\nl $EDGES \gets$ pobierz krawêdzie drzewa $OPT$\;
	\ForEach{$E$ from $EDGES$}{
		\nl $VAL_{OLD} \gets$ wartoœæ statystyki krawêdzi $E$ z $STAT_{OLD}$\;
		\nl $BEST \gets$ pobierz wartoœæ najlepszej statystyki na miejscu $E$ z $STAT_{NEW}$\;
		\If{$BEST > VAL_{OLD}$}{
			\nl $NEW, VAL_{NEW} \gets$ pobierz ze statystyk $STAT_{NEW}$ parê na miejscu $E$ zaczynaj¹c¹ siê t¹ sam¹ kompresj¹, o najwiêkszej statystyce oraz jej wartoœæ\;
			\If{$VAL_{NEW} > VAL_{OLD}$}{
				\nl wymieñ E.TO na NEW.TO, kasuj¹c ca³e poddrzewo od E.TO\;
				\nl wykonaj $Replace(NEW.TO, STAT_{NEW}, 2*(E.NO + 1))$\;
			}
			\Else{
				\nl $NEW \gets$ pobierz ze statystyk $STAT_{NEW}$ parê na miejscu $E$ o najwiêkszej statystyce\;
				\nl wymieñ E.FROM na NEW.FROM, kasuj¹c ca³e poddrzewo od E.FROM\;
				\eIf{E.NO jest parzyste}{
					\nl $NO \gets E.NO-1$\;
				}{
					\nl $NO \gets E.NO$\;
				}
				\nl wykonaj $Replace(NEW.FROM, STAT_{NEW}, NO)$\;
			}
			\nl wyjdŸ z pêtli\;
		}
	}
	\nl \Return{true}\;
 }
 \label{alg:faza2_correct}
\end{algorithm}

Podsumowuj¹c, program mutuje drzewo kompresji dopóki wspó³czynnik kompresji nie zacznie siê poprawiaæ. Pojedyncza
mutacja mo¿e zmieniæ jeden wêze³, ale mo¿e tak¿e wymieniæ ca³e drzewo, co dzieje siê bardzo czêsto. Wymiany s¹
dokonywane tylko wtedy, gdy wed³ug statystyk nast¹pi poprawa kompresji. W ten sposób nawet jeœli charakterystyka
danych siê zmieni, algorytm powinien dostosowaæ drzewo do nowych warunków.

\begin{algorithm}[H]
 \scriptsize
 \caption{Faza 2 - poprawianie drzewa (Replace)}
 \KwIn{NODE -- wymieniany wêze³ drzewa, STATS -- statystyki krawêdzi\;
 $EDGE_{NO}$ -- numer wymienionej krawêdzi, $MAX_{H}$ -- maksymalna wysokoœæ drzewa\;
 }
 \SetKwFunction{algo}{Replace}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
	\nl \lIf{$EDGE_{NO} > 2^{MAX_{H}}-3$}{\Return}
	\nl $K \gets$ kodowanie wêz³a $NODE$
	\nl $RES_{CNT} \gets$ pobierz iloœæ wyników zwracanych przez $K$\;
	\For{$i=0$ to $RES_{CNT}$}{
		\nl $BEST, BEST_{VAL} \gets$ pobierz ze $STATS$ parê zaczynaj¹c¹ siê na $K$ o najwiêkszej statystyce na pozycji $EDGE_{NO}+i$ w drzewie binarnym oraz jej wartoœæ\;
		\If{$BEST_{VAL} > 1.0$}{
			\nl $CHLD \gets$ wêze³ reprezentuj¹cy kodowanie BEST.TO\;
			\nl dodaj $CHLD$ jako dziecko $NODE$\;
			\nl wywo³aj $Replace(CHLD, STATS, 2*(EDGE_{NO}+i)+2$\;
		}
		\Else{
			\nl dodaj do $NODE$ dziecko z kodowaniem \emph{NONE}\;
		}
	}
	\Return
 }
 \label{alg:faza2_replace}
\end{algorithm}
\normalsize

\subsection{Ca³oœæ}

\begin{algorithm}[H]
 \scriptsize
 \caption{Ca³oœæ kompresji optymalizatorem}
 \KwIn{DATA -- dane do skompresowania, DT -- typ danych\;}
 \KwOut{RES -- skompresowane dane}
 \SetKwFunction{algo}{CompressData}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
	\If(\tcc*[f]{heurystyka}){warto przejrzeæ ponownie interesuj¹ce drzewa}{
		\nl $SAMPLE \gets$ pobierz kawa³ek danych z $DATA$\;
		\nl $TREES \gets$ wywo³aj $FullStatisticsUpdate(SAMPLE, NONE, DT, 0)$\;
		\nl $BEST \gets$ pobierz drzewo z najlepszym wynikiem\;
		\nl ustaw $BEST$ jako optymalne drzewo
	}
	\nl $RES \gets$ wykonaj kompresjê optymalnym drzewem\;
	\nl $UPDATE \gets$ wywo³aj $TryCorrectTree$ na optymalnym drzewie\;
	\If{$UPDATE$ is $true$}{
		\nl ustaw ponownie optymalne drzewo\;
	}
	\nl \Return{RES}
 }
 \label{alg:compress}
\end{algorithm}
\normalsize

Przebieg dzia³ania kompresji z u¿yciem optymalizatora pokazuje algorytm \ref{alg:compress}.
Co pewien czas próbujemy przejrzeæ wszystkie interesuj¹ce drzewa uaktualniaj¹c statystyki i wybieraj¹c
inne optymalne drzewo. Staramy siê je poprawiaæ i jeœli siê uda³o, to ponownie zapisujemy je jako
optymalne, tworz¹c now¹ kopiê statystyk (historycznych).

\subsection{Usprawnienie}
Iloœæ drzew do sprawdzenia w fazie 1 mo¿e lawinowo rosn¹c wzglêdem iloœci ró¿nych kompresji zaimplementowanych w systemie, w zale¿noœci od zastosowanych regu³. Warto zaimplementowaæ zbiory regu³ produkuj¹cych mniej i wiêcej
takich drzew, aby lepiej przeszukiwaæ przestrzeñ rozwi¹zañ. Jednak przeszukiwanie du¿ej iloœci drzew jest pomimo
zastosowania GPU, zbyt czasoch³onne jak na planowane zastosowania. Mo¿liwym rozwi¹zaniem (jeszcze nie zaimplementowanym ale planowanym), jest niezale¿ne i równoleg³e wykonywanie fazy 1 dla ró¿nych zbiorów regu³, równolegle do faz 2 i 3, w sposób pokazany na rysunku \ref{ref:threads}. Na tym rysunku numery 1,2,3 stanowi¹ numer fazy, a
A,B,C zbiory regu³ w których A s¹ najbardziej restrykcyjne i produkuj¹ ma³o drzew, zaœ C bardzo du¿o.

    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.5]{img/threads}
        \caption{Zrównoleglenie fazy 1 w optymalizatorze}
        \label{ref:threads}
    \end{figure}
\noindent
W ten sposób oba w¹tki mog¹ pracowaæ nawet na 2 oddzielnych urz¹dzeniach, wielokrotnie zwiêkszaj¹c nie tylko
wydajnoœæ ale i wspó³czynnik kompresji z racji przeszukania wiêkszej iloœci opcji. Algorytm powinien
tak¿e lepiej dostosowywaæ siê do zmian danych. Taka równoleg³oœæ jest mo¿liwa, poniewa¿ statystyki
zosta³y zaimplementowane w taki sposób, aby umo¿liwiæ do nich równoleg³y dostêp bez obaw o niespójnoœæ danych.

\section{Równoleg³y kompresor}
Szeregi czasowe zwykle sk³adaj¹ siê z wielu kolumn, które maj¹ ró¿ne charakterystyki, wiêc mog¹ byæ
kompresowane niezale¿nie i równolegle. Oprócz mo¿liwoœci wykorzystania do tego celu wielu urz¹dzeñ GPU
jednoczeœnie, mo¿na wykorzystaæ \emph{CUDA STREAMS} aby wykonywaæ jednoczeœnie wiele \emph{kerneli} oraz kopiowañ danych na tej samej karcie. Samymi \emph{stream'ami} w nowych wersjach CUDA ($>7.0$) nie
trzeba siê przejmowaæ, gdy¿ ka¿dy w¹tek automatycznie dostaje osobny i niezale¿ny (domyœlny) stream 0,
który dodatkowo nie powoduje niejawnej synchronizacji. Wszystko pod warunkiem kompilacji programu z flag¹ --default-stream per-thread lub zdefiniowaniu CUDA\_API\_PER\_THREAD\_DEFAULT\_STREAM.
Po zastosowaniu tej opcji wszystkie kernele oraz kopiowania pochodz¹ce z ró¿nych w¹tków, bêd¹ mog³y
byæ zrównoleglone, pomimo ich u¿ycia na domyœlnym streamie 0.

\subsection{Opis algorytmu}
W programie równoleg³a kompresja opiera siê na puli w¹tków zaimplementowanej jako \emph{Task Scheduler}
w bibliotece \emph{CORE}, w oparciu o bibliotekê \emph{BOOST}. Sama kompresja i dekompresja polega na
uruchamianiu zadañ kompresji lub dekompresji kawa³ków danych z u¿yciem instancji jakiegoœ optymalizatora, unikalnego dla danej kolumny. Oczywiœcie zadania te musz¹ byæ odpowiednio synchronizowane.

\subsubsection{Kompresja}
Równoleg³a kompresja kolumn jest opisana przez pseudokod w algorytmie \ref{alg:parallel}.

\begin{algorithm}[H]
 \scriptsize
 \caption{Ca³oœæ kompresji optymalizatorem}
 \KwIn{$FILE_{IN}$ -- plik wejœciowy, $FILE_{OUT}$ -- plik wyjœciowy\;}
 \SetKwFunction{algo}{$ParallelCompressor \rightarrow Compress$}
 \SetKwProg{myalg}{Metoda}{}{}
 \myalg{\algo{}}{
 	\nl $ID \gets 1$\;
	\Repeat{koniec pliku $FILE_{IN}$}{
		\nl $TS \gets$ odczytaj paczkê danych z pliku $FILE_{IN}$\;
		\If{niezainizjalizowany}{
			\tcc{inicjalizuje kompresor tworzy optymalizator dla ka¿dej kolumny wejœciowych danych oraz tworzy pulê w¹tków}
			\nl wywo³aj $init()$
		}
		\nl $COL_{N} \gets$ pobierz iloœæ kolumn z $TS$\;
		\For{$i=0$ to $N$}{
			\nl $TASK \gets$ stwórz zadanie kompresji z optymalizatorem dla kolumny $i$ oraz danymi $TS[i]$ (i-ta kolumna szeregu TS) o numerze $ID$\;
			\nl dodaj $TASK$ do schedulera oraz powiêksz $ID$ o 1\;
		}
		\nl zaczekaj na wykonanie wszystkich zadañ\;
	}
 }
 \label{alg:parallel}
\end{algorithm}
\normalsize
\noindent

W tym przypadku wa¿ne jest jak dzia³a samo zadanie kompresji, przy czym kluczowym elementem
jest synchronizacja zapisu do pliku wynikowego, który to przedstawia rysunek \ref{ref:parallel}.
Zadanie to przebiega nastêpuj¹co:
\begin{enumerate}
\item Otrzymane dane kopiowane s¹ na GPU
\item Dane s¹ kompresowane przy u¿yciu podanego optymalizatora
\item Dane s¹ zapisywane z powrotem do pamiêci RAM
\item Nastêpnie przy u¿yciu metod synchronizacji w¹tki zapisuj¹ dane do pliku wyjœciowego.
	\begin{itemize}
	\item w¹tek czeka a¿ wszystkie w¹tki o mniejszych numerach zakoñcz¹ pracê
	\item w¹tek zapisuje dane poprzedzaj¹c je ich rozmiarem
	\end{itemize}
\item Oznacz zadanie jako ukoñczone
\item Jeœli jakikolwiek z powy¿szych pkt. siê nie powiedzie oznacz zadanie jako zakoñczone pora¿k¹
\end{enumerate}

    \begin{figure}[h!]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.5]{img/parallel}
        \caption{Wykonanie zadañ kompresji przez w¹tki}
        \label{ref:parallel}
    \end{figure}

\subsubsection{Dekompresja}
Dekompresja przebiega na tyle prosto, ¿e ograniczê siê do krótkiego opisu bez pseudokodu i obrazków.
\begin{enumerate}
\item Kawa³ek po kawa³ku, zgodnie z zapisanymi rozmiarami czytamy skompresowane dane kolumn.
\item Dla ka¿dego kawa³ka tworzone jest zadanie dekompresuj¹ce (posiadaj¹ce wskaŸnik na wspóln¹ instancjê szeregu czasowego), które:
	\begin{enumerate}
	\item Zaczytuje dane na GPU
	\item Dekompresuje je
	\item Dopisuje na koñcu kolumny, któr¹ obs³uguje w szeregu czasowym
	\end{enumerate}
\item Po zdekodowaniu liczby kawa³ków równej liczbie kolumn czekamy a¿ w¹tki zakoñcz¹ pracê i zapisujemy szereg na wyjœciem.
\item Czyœcimy szereg czasowy aby nie zapisywaæ kolejny raz tych samych danych
\item Jeœli to nie koniec danych do dekompresji, wracamy do punktu pierwszego
\end{enumerate}

\chapter{Wyniki}
W tym rozdziale opiszê uzyskane wyniki pod wzglêdem wspó³czynników kompresji dla ró¿nych danych, jak równie¿ wygenerowane schematy kompresji. PóŸniej porównam wydajnoœæ ca³oœci jak i poszczególnych elementów systemu, z istniej¹cymi rozwi¹zaniami.

\section{Platforma testowa}
Wszystkie testy wykonano na komputerze stacjonarnym pod systemem \emph{Ubuntu 14.04.3 LTS},
z zainstalowanymi sterownikami \emph{NVIDIA 352.68} oraz \emph{CUDA 7.5}. Parametry komputera:
\begin{itemize}
\item Procesor: AMD FX(tm)-8350 Eight-Core Processor
\item Karta graficzna: 2 x GeForce GT 640
\item Pamiêæ RAM: 16 GB (1600 Mhz)
\item Dysk: SSD 40 GB
\item P³yta g³ówna: 970A-UD3 - Gigabyte
\end{itemize}

\section{Dane}
\subsection{Rzeczywiste}
Dane rzeczywiste pochodz¹ z dwóch Ÿróde³. Pierwsze pochodz¹ z pomiarów dzia³aj¹cego komputera MAC,
wykonane za pomoc¹ prostego programu OsxSystemDataLogger\footnote{https://github.com/dzitkowskik/osx-system-data-logger}, które zawieraj¹ pola takie jak czas, napiêcie na procesorze oraz temperaturê procesora i GPU. Dane te dalej bêdê nazywa³ \emph{INFO}. Drugie pochodz¹ z \emph{New York Stock Exchange} i s¹ danymi historycznymi wszystkich zdarzeñ w czasie rzeczywistym w formie \emph{NYSE OpenBook}\footnote{http://www.nyxdata.com/Data-Products/NYSE-OpenBook} zawieraj¹cymi ponad 20 kolumn, a w tym czas, wolumen, cenê, stronê, symbol i inne. Dane te dalej bêdê nazywa³ \emph{NYSE}.
\subsection{Wygenerowane}
\subsubsection{Czas}
Dane maj¹ s¹ liczbami ca³kowitymi o d³ugoœci $64bit$ monotonicznie rosn¹cymi od zadanej wartoœci startowej. Dane rosn¹ o losow¹ wielkoœæ z zadanego przedzia³u, z pewnym prawdopodobieñstwem. Dla prawdopodobieñstwa 0 czas siê nie zmienia, natomiast dla prawdopodobieñstwa 1, nie bêdzie dwóch tych samych liczb w wygenerowanym ci¹gu.
\begin{lstlisting}[caption=Time pattern,label={lst:time},basicstyle=\small]
	//                              ------------
	//                        ------
	//          --------------
	//       ---
	// ------                                   min
\end{lstlisting}

\subsubsection{Pattern A}
Dane te s¹ liczbami dowolnego typu i wielkoœci, z przedzia³u od zadanego minimum($v_{min}$) do maksimum($v_{max}$).
Wartoœæ generowanych punktów zmienia siê co $len$ kroków, oraz przed ka¿d¹ zmian¹ generowany jest
pojedynczy punkt o wartoœci $v_{max}$.

\begin{lstlisting}[caption=Pattern A,label={lst:patternA},basicstyle=\small]
	// *       *       *       *      *      * max
	//                  -------
	//          -------         ------
	//  -------                        ------  min
	//  <-len->
\end{lstlisting}

\subsubsection{Pattern B}
Dane B sk³adaj¹ siê z dwóch czêœci po³o¿onych na przemian co $len$ kroków, z których pierwsza
sk³ada siê z naprzemian po³o¿onych wartoœci bliskich $v_{max}$ i $v_{min}$. Druga czêœæ sk³ada
siê z wartoœci malej¹cych z wartoœci maksymalnej do minimalnej co ustalon¹ wartoœæ a nastêpnie
rosn¹ca z powrotem.
\begin{lstlisting}[caption=Pattern B,label={lst:patternB},basicstyle=\small]
//   pattern 1     |       pattern 2       |     pattern 1
// * * * * * * * *  *                       * * * * * * * * max-rand(0,5)
//  # # # # # # #     *                   *  # # # # # # #  max-rand(0,5)
//                      *               *
//                        *           *
//                          *       *
//  * * * * * * * *           *   *          * * * * * * * min+rand(0,5)
//   # # # # # # #              *             # # # # # #  min+rand(0,5)
//  <------len-----> <---------len---------> <-----len---->
\end{lstlisting}


\section{Badanie wspó³czynnika kompresji}
Wyniki tego pomiaru otrzymano kompresuj¹c pliki \emph{CSV} z danymi rzeczywistymi
omówionymi wczeœniej, za pomoc¹ zaimplementowanego równoleg³ego kompresora oraz
kompresorów \emph{7z, zip, tar.gz} dostêpnych w systemie \emph{Linux Ubuntu}.
\begin{table}[h!]
\centering
\caption{Wspó³czynnik kompresji dla plików CSV z danymi w porównaniu ze standardowymi kompresorami}
\label{my-label}
\begin{tabular}{|l|l|l|l|l|}
\hline
&	optymalizator &	tar.gz&	zip& 	7z \\ \hline
INFO			&27.26			&17.89  &22.60	&30.31 \\
NYSE			&8.12			&4.89	&5.64	&7.42  \\
GEN1			&17.40			&6.66	&7.95	&10.91 \\
browsermarket	&4.75			&3.72	&4.15	&5.40 \\
\hline
\end{tabular}
\end{table}
Z danych tych wynika ¿e dla wiêkszoœci danych optymalizator zachowuje siê lepiej ni¿
dostêpne w systemie kompresje, które poza tym s¹ o wiele wolniejsze, co poka¿ê w
dalszej czêœci. W dwóch przypadkach jednak \emph{7z} okaza³ siê lepszy, natomiast
obie kompresje maj¹ porównywalne wyniki.

\section{Wygenerowane schematy}
Kolejny test polega³ na przeœledzeniu dzia³ania optymalizatora dla du¿ej iloœci
danych w wariancie \emph{Pattern B}. Dla pierwszej czêœci spodziewamy siê, ¿e
algorytm bêdzie stara³ siê podzieliæ dane na górne i dolne, a nastêpnie pakowaæ je
za pomoc¹ kompresji s³ownikowej lub \emph{AFL}. Nastêpnie struktura danych siê zmieni,
wiêc algorytm powinien zareagowaæ stosuj¹c kodowanie delta a nastêpnie const lub rle,
uzyskuj¹c bardzo wysok¹ kompresjê.
\begin{table}[]
\centering
\caption{Dzia³anie optymalizatora dla danych ca³kowitych Pattern B}
\label{my-label}
\begin{tabular}{|l|l|l|l|l|}
\hline
It. & Scheme									&		Ratio	&	Pattern	\\ \hline
1	& patch,scale,dict,none,none,scale,afl,none &	3.599712	&	1\\
2	& patch,scale,dict,none,none,scale,afl,none	&	3.599712	&	1\\
3	& patch,scale,dict,none,none,scale,afl,none	&	3.599712	&	1\\
4	& patch,scale,dict,none,none,scale,afl,none	&	3.599712	&	1\\
5	& patch,scale,dict,none,none,scale,afl,none	&	3.599712	&	1\\
6	& patch,scale,dict,none,none,scale,afl,none	&	3.599712	&	1\\
7	& patch,scale,dict,none,none,scale,afl,none	&	14.814815	&	2\\
8	& patch,scale,dict,none,none,scale,afl,none	&	14.814815	&	2\\
9	& patch,scale,dict,none,none,scale,afl,none	&	14.814815	&	2\\
10	& rle,delta,none,delta,none					&	294.117645	&	2\\
11	& rle,const,none,delta,none					&	285.714294	&	2\\
12	& rle,patch,afl,none,afl,none,delta,none	&	188.679245	&	2\\
13	& rle,none,delta,none						&	0.499351	&	1\\
14	& rle,delta,rle,none,none,delta,none		&	0.995025	&	1\\
15	& patch,scale,dict,none,none,scale,afl,none	&	3.599712	&	1\\
16	& scale,rle,delta,none,delta,none			&	0.499102	&	1\\
17	& delta,rle,const,none,const,none			&	1.019992	&	1\\
18	& rle,const,none,const,none					&	1.021242	&	1\\
19	& rle,delta,rle,none,none,const,none		&	204.081635	&	2\\
20	& rle,delta,none,delta,none					&	294.117645	&	2\\
21	& rle,patch,afl,none,afl,none,delta,none	&	188.679245	&	2\\
22	& rle,const,none,delta,none					&	285.714294	&	2\\
23	& rle,const,none,delta,none					&	285.714294	&	2\\
24	& rle,const,none,delta,none					&	285.714294	&	2\\
25	& patch,scale,dict,none,none,scale,afl,none	&	3.599712	&	1\\
26	& patch,scale,dict,none,none,scale,afl,none	&	3.599712	&	1\\
\hline
\end{tabular}
\end{table}

\section{Szybkoœæ dzia³ania}
Omówienie szybkoœci dzia³ania


\chapter{Podsumowanie}
Prodsumowuj¹c uda³o siê zaimplementowaæ dzia³aj¹cy prototyp optymalizatora kompresji
szeregów czasowych, który potrafi dostosowaæ siê do zmiennej charakterystyki nap³ywaj¹cych
danych. Kompresor w dobrym tempie kompresuje dane zachowuj¹c wysoki poziom kompresji,
dorównuj¹cy, a dla w³aœciwych szregów czasowych nawet przewy¿szaj¹cy niektóre istniej¹ce
rozwi¹zania. Algorytm wykazuje wy¿szy poziom kompresji dla realistycznych danych ni¿
szeroko stosowane kompresory 7z czy zip. Jednak jest to tylko prototyp i dla realistycznych
rozwi¹zañ w bazach danych GPU uzyskana wydajnoœæ kompresji nie jest wystarczaj¹ca.
Jednak patrz¹c na wydajnoœæ odopowiednio zoptymalizowanych odpowiedników wdro¿onych
kompresji mo¿na uzanaæ, ¿e jest mo¿liwe ulepszenie tego rozwi¹zania by uzyska³o wymagan¹
wydajnoœæ na poziomie kilkudziesiêciu Gb/s.

\section{Konkluzja}
\section{Przysz³e prace}


%-----------Koniec czêœci zasadniczej-----------

\begin{thebibliography}{11}
\small
\bibitem[1]{PPS} Mark Harris, Shubhabrata Sengupta, and John D. Owens. \emph{"Parallel Prefix Sum (Scan) with CUDA"}. In Hubert Nguyen, editor, GPU Gems 3, chapter 39, pages 851–876. Addison Wesley, August 2007
\bibitem[2]{SORT} Nadathur Satish, Mark Harris, and Michael Garland. \emph{"Designing Efficient Sorting Algorithms for Manycore GPUs"}. In Proceedings of the 23rd IEEE International Parallel \& Distributed Processing Symposium, May 2009
\bibitem[3]{PHASH} Alcantara, Dan A., et al. \emph{"Real-time parallel hashing on the GPU."} ACM Transactions on Graphics (TOG) 28.5 (2009): 154
\bibitem[4]{MOSTAK} Mostak, T., 2013. \emph{"An overview of MapD (massively parallel database)."}, Massachusetts Institute of Technology, Cambridge, MA.
\bibitem[5]{CURRY} Cloud RL, Curry ML, Ward HL, Skjellum A, Bangalore P. \emph{"Accelerating lossless data compression with GPUs."} arXiv preprint arXiv:1107.1525. 2011 Jun 21.
\bibitem[6]{RUSSEK} Pietroñ, M., Pawel Russek, and Kazimierz Wiatr. \emph{"Accelerating SELECT WHERE and SELECT JOIN queries on a GPU."} Computer Science 14.2) (2013): 243-252.
\bibitem[7]{DTU} Nicolaisen, Anders Lehrmann Vr?nning. \emph{"Algorithms for Compression on GPUs."} (2013).
\bibitem[8]{MENSMANN} Mensmann, Jörg, Timo Ropinski, and Klaus Hinrichs. \emph{"A GPU-supported lossless compression scheme for rendering time-varying volume data."} 8th IEEE/EG international conference on Volume Graphics, 2–3 May 2010, Norrköping, Sweden. IEEE, 2010.
\bibitem[9]{BURTSCHER} Burtscher M, Ratanaworabhan P. \emph{"FPC: A high-speed compressor for double-precision floating-point data."} Computers, IEEE Transactions on. 2009 Jan;58(1):18-31.
\bibitem[10]{BAKKUM} Bakkum, Peter, and Kevin Skadron. \emph{"Accelerating SQL database operations on a GPU with CUDA."} Proceedings of the 3rd Workshop on General-Purpose Computation on Graphics Processing Units. ACM, 2010.
\bibitem[11]{FERRIERA} Ferreira, Miguel C. \emph{"Compression and query execution within column oriented databases."} Diss. Massachusetts Institute of Technology, 2005.
\bibitem[12]{FINK} Fink, Eugene, and Harith Suman Gandhi. \emph{"Compression of time series by extracting major extrema."} Journal of Experimental \& Theoretical Artificial Intelligence 23.2 (2011): 255-270.
\bibitem[13]{KACZMAR2} Przymus, Piotr, and Krzysztof Kaczmarski. \emph{"Compression Planner for Time Series Database with GPU Support."} Transactions on Large-Scale Data-and Knowledge-Centered Systems XV. Springer Berlin Heidelberg, 2014. 36-63.
\bibitem[14]{OZSOY} Ozsoy, Adnan, Martin Swany, and Anamika Chauhan. \emph{"Pipelined parallel lzss for streaming data compression on GPGPUs."} Parallel and Distributed Systems (ICPADS), 2012 IEEE 18th International Conference on. IEEE, 2012.
\bibitem[15]{FANG} Fang, Wenbin, Bingsheng He, and Qiong Luo. \emph{"Database compression on graphics processors."} Proceedings of the VLDB Endowment 3.1-2 (2010): 670-680.
\bibitem[16]{LEMIRE} Lemire, Daniel, and Leonid Boytsov. \emph{"Decoding billions of integers per second through vectorization."} Software: Practice and Experience 45.1 (2015): 1-29.
\bibitem[17]{PRZYMUS1} Przymus, Piotr, and Krzysztof Kaczmarski. \emph{"Dynamic compression strategy for time series database using GPU."} New Trends in Databases and Information Systems. Springer International Publishing, 2014. 235-244.
\bibitem[18]{MANI} Mani, Ganapathy. \emph{"Data Compression using CUDA programming in GPU."} (2012).
\bibitem[19]{CHASH} Alcantara, Dan A., et al. \emph{"Real-time parallel hashing on the GPU."} ACM Transactions on Graphics (TOG) 28.5 (2009): 154.
\bibitem[20]{ONEIL} O'Neil, Molly A., and Martin Burtscher. \emph{"Floating-point data compression at 75 Gb/s on a GPU."} Proceedings of the Fourth Workshop on General Purpose Processing on Graphics Processing Units. ACM, 2011.
\bibitem[21]{ZU} Zu, Yuan, and Bei Hua. \emph{"GLZSS: LZSS lossless data compression can be faster."} Proceedings of Workshop on General Purpose Processing Using GPUs. ACM, 2014.
\bibitem[22]{GPUFS} Silberstein, Mark, et al. \emph{"GPUfs: Integrating a file system with GPUs."} ACM Transactions on Computer Systems (TOCS) 32.1 (2014): 1.
\bibitem[23]{ACC} Al-Kiswany, Samer, Ammar Gharaibeh, and Matei Ripeanu. \emph{"GPUs as storage system accelerators."} Parallel and Distributed Systems, IEEE Transactions on 24.8 (2013): 1556-1566.
\bibitem[23]{PRZYMUS2} Przymus, Piotr, and Krzysztof Kaczmarski. \emph{"Improving efficiency of data intensive applications on GPU using lightweight compression."} On the Move to Meaningful Internet Systems: OTM 2012 Workshops. Springer Berlin Heidelberg, 2012.
\bibitem[24]{ABADI} Abadi, Daniel, Samuel Madden, and Miguel Ferreira. \emph{"Integrating compression and execution in column-oriented database systems."} Proceedings of the 2006 ACM SIGMOD international conference on Management of data. ACM, 2006.
\bibitem[25]{ANH} Anh, Vo Ngoc, and Alistair Moffat. \emph{"Inverted index compression using word-aligned binary codes."} Information Retrieval 8.1 (2005): 151-166.
\bibitem[26]{EIROLA} Eirola, Axel. \emph{"Lossless data compression on GPGPU architectures."} arXiv preprint arXiv:1109.2348 (2011).
\bibitem[27]{SHYNI} Shyni, K., and Manoj Kumar KV. \emph{"Lossless LZW Data Compression Algorithm on CUDA."} IOSR Journal of Computer Engineering (IOSR-JCE) 13.1 (2013): 122-127.
\bibitem[28]{MAPD} Mostak, Todd. \emph{"An overview of MapD (massively parallel database)."} White paper, Massachusetts Institute of Technology, Cambridge, MA (2013).
\bibitem[29]{BUSCHS} Buchsbaum, Adam L., et al. \emph{"Engineering the compression of massive tables: an experimental approach."} Symposium on Discrete Algorithms: Proceedings of the eleventh annual ACM-SIAM symposium on Discrete algorithms. Vol. 9. No. 11. 2000.
\bibitem[30]{MORISHIMA} Morishima, Shin, and Hiroki Matsutani. \emph{"Performance Evaluations of Document-Oriented Databases Using GPU and Cache Structure."} Trustcom/BigDataSE/ISPA, 2015 IEEE. Vol. 3. IEEE, 2015.
\bibitem[31]{OZSOY3} Ozsoy, Adnan, Martin Swany, and Arun Chauhan. \emph{"Optimizing LZSS compression on GPGPUs."} Future Generation Computer Systems 30 (2014): 170-178.
\bibitem[32]{PATEL} Patel, Ritesh A., et al. \emph{"Parallel lossless data compression on the GPU."} IEEE, 2012.
\bibitem[33]{SIMD} Polychroniou, Orestis, Arun Raghavan, and Kenneth A. Ross. \emph{"Rethinking SIMD vectorization for in-memory databases."} Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data. ACM, 2015.
\bibitem[34]{SHREDDER} Bhatotia, Pramod, Rodrigo Rodrigues, and Akshat Verma. \emph{"Shredder: GPU-accelerated incremental storage and computation."} FAST. 2012.
\bibitem[35]{ZUKOWSKI} Zukowski, Marcin, et al. \emph{"Super-scalar RAM-CPU cache compression."} Data Engineering, 2006. ICDE'06. Proceedings of the 22nd International Conference on. IEEE, 2006.
\bibitem[36]{EICHINGER} Eichinger, Frank, et al. \emph{"A time-series compression technique and its application to the smart grid."} The VLDB Journal 24.2 (2015): 193-218.
\bibitem[37]{KACZMAR1} Przymus, Piotr, and Krzysztof Kaczmarski. \emph{"Time series queries processing with gpu support."} New Trends in Databases and Information Systems. Springer International Publishing, 2014. 53-60.
\bibitem[38]{ZHAO} Zhao, Wayne Xin, et al. \emph{"A General SIMD-based Approach to Accelerating Compression Algorithms."} ACM Transactions on Information Systems (TOIS) 33.3 (2015): 15.
\bibitem[39]{GOLDSTEIN} Goldstein, Jonathan, Raghu Ramakrishnan, and Uri Shaft. \emph{"Compressing relations and indexes."} Data Engineering, 1998. Proceedings., 14th International Conference on. IEEE, 1998.
\bibitem[41]{CUDA_PERF} http://developer.download.nvidia.com/compute/cuda/compute-docs/cuda-performance-report.pdf
\bibitem[42]{PARETO} Marler, R. Timothy, and Jasbir S. Arora. \emph{"Survey of multi-objective optimization methods for engineering."} Structural and multidisciplinary optimization 26.6 (2004): 369-395.
\bibitem[43]{UENG} Ueng, Sain-Zee, et al. \emph{"CUDA-lite: Reducing GPU programming complexity."} Languages and Compilers for Parallel Computing. Springer Berlin Heidelberg, 2008. 1-15.
\bibitem[44]{FPC} Burtscher, Martin, and Paruj Ratanaworabhan. \emph{"pFPC: A parallel compressor for floating-point data."} Data Compression Conference, 2009. DCC'09.. IEEE, 2009.

\end{thebibliography}
\tableofcontents
\clearpage
\pagestyle{empty}
\noindent Warszawa, dnia ...............
\vspace{5cm}
\begin{center}
\LARGE{Oœwiadczenie}
\end{center}
Oœwiadczam, ¿e pracê magistersk¹ pod tytu³em: ,,Tytu³ pracy'', której promotorem jest prof. dr hab. Jan Wybitny, wykona³em/am samodzielnie, co poœwiadczam w³asnorêcznym podpisem.
\vspace{2cm}
\begin{flushright}
...........................................
\end{flushright}

\end{document}
