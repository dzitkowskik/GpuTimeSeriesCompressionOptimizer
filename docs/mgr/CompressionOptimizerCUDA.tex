\documentclass[12pt, twoside, openany]{report}
\usepackage[dvips]{graphicx,color,rotating}
\usepackage[cp1250]{inputenc}
\usepackage{t1enc}
\usepackage{a4wide}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage[MeX]{polski}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{left=25mm,right=25mm,%
bindingoffset=10mm, top=25mm, bottom=25mm}
\usepackage{amssymb, latexsym}
\usepackage{amsthm}
\usepackage{palatino}
\usepackage{array}
\usepackage{pstricks}
\usepackage{multirow}
\usepackage{textcomp}
\theoremstyle{definition}
\newtheorem{theorem}{Twierdzenie}[section]
\newtheorem{remark}{Uwaga}[section]
\newtheorem{definition}{Definicja}[section]
\newtheorem{alg}{Algorytm}[chapter]

\newtheorem{prz}{Przypadek}[section]
\newtheorem{np}{Przyk³ad}[section]
\newtheorem{lemma}[theorem]{Lemat}
\linespread{1.5}
\newcommand*{\norm}[1]{\left\Vert{#1}\right\Vert}
\newcommand*{\abs}[1]{\left\vert{#1}\right\vert}
\newcommand*{\om}{\omega}

\usepackage{float}
\usepackage{hyperref}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{listings}

\author{Karol Dzitkowski}
\title{Optymalizator kompresji szeregów czasowych na GPU}
\begin{document}
\begin{titlepage}
\pagestyle{empty}

\noindent
\begin{Large}
\begin{table}[t]
\centering
\begin{tabular}[t]{lcr}
 \includegraphics[width=70pt,height=70pt]{PW} & POLITECHNIKA WARSZAWSKA & \includegraphics[width=70pt,height=70pt]{MiNI}\\
& WYDZIA£ MATEMATYKI & \\
& I NAUK INFORMACYJNYCH &
\end{tabular}
\end{table}

% \vfill
\begin{center}PRACA DYPLOMOWA MAGISTERSKA\end{center}
\begin{center}INFORMATYKA\end{center}\end{Large}
% \vfill
\begin{center}
\Huge
\textbf{Optymalizator kompresji szeregów czasowych na GPU}
\end{center}
% \vfill\vfill
\vfill
\begin{center}
\Large
Autor:\\
\LARGE
Karol Dzitkowski
\end{center}
\vfill
\begin{center}
\Large
Promotor: dr in¿. Krzysztof Kaczmarski
\end{center}
\vfill
\begin{center}
\large
Warszawa, luty 2016
\end{center}
\newpage
\hfill
\begin{table}[b]
\centering
\begin{tabular}[t]{ccc}
............................................. & \hspace*{100pt} & .............................................\\
podpis promotora & \hspace*{100pt} & podpis autora
\end{tabular}
\end{table}


% \maketitle
\end{titlepage}
\thispagestyle{empty}
\newpage
\pagestyle{headings}
\setcounter{page}{1}
\hyphenation{Syl-ves-tra}
\hyphenation{Syl-ves-ter-a}

\renewcommand{\abstractname}{Abstrakt}

\begin{abstract}
Wiele urz¹dzeñ takich jak czujniki, stacje pomiarowe, czy nawet serwery, produkuj¹ ogromne iloœci danych w postaci szeregów czasowych, które nastêpnie s¹ przetwarzane i sk³adowane do póŸniejszej analizy. Ogromn¹ rolê w tym procesie stanowi przetwarzanie danych na kartach graficznych w celu przyspieszenia obliczeñ. Aby wydajnie korzystaæ z GPGPU przedstawiono szereg rozwi¹zañ, korzystaj¹cych z kart graficznych jako koprocesory w bazach danych lub nawet bazy danych po stronie GPU. We wszystkich rozwi¹zaniach bardzo istotn¹ rolê stanowi kompresja danych. Szeregi czasowe s¹ bardzo szczególnym rodzajem danych, dla których kluczowy jest dobór odpowiedniej kompresji wedle charakterystyki danych szeregu. W tej pracy przedstawiê nowe podejœcie do kompresji szeregów czasowych po stronie GPU, przy u¿yciu planera buduj¹cego na bie¿¹co drzewa kompresji na podstawie statystyk nap³ywaj¹cych danych. Przedstawione rozwi¹zanie kompresuje dane za pomoc¹ lekkich i bezstratnych kompresji w technologii CUDA.
\end{abstract}

\renewcommand{\abstractname}{Abstract}

\begin{abstract}
Many devices such as sensors, measuring stations or even servers produce enormous amounts of data in the form of time series, which are then processed and stored for later analysis. A huge role in this process takes data processing on graphics cards in order to accelerate calculations. To efficiently use the GPGPU a number of solutions has been presented, that use the GPU as a coprocessor in a databases. There were also attempts to create a GPU-side databases. It has been known that data compression plays here the crucial role. Time series are special kind of data, for which choosing the right compression according to the characteristics of the data series is essencial. In this paper I present a new approach to compression of time series on the side of the GPU, using a planner to keep building the compression tree based on statistics of incoming data. The solution compresses data using lightweight and lossless compression in CUDA technology.
\end{abstract}

%-----------Pocz¹tek czêœci zasadniczej-----------

\chapter{Wstêp}
Poni¿sza praca zawiera opis implementacji optymalizatora kompresji szeregów czasowych, bazuj¹cego na dynamicznie generowanych statystykach danych. Pomys³ opiera siê na tworzeniu drzew kompresji (kompresja kaskadowa) oraz zbieraniu statystyk o krawêdziach takich drzew - jak dobrze dana para kompresji sprawdza siê dla nap³ywaj¹cych danych. System bêdzie równie¿ dynamicznie zmienia³ - korygowa³, takie drzewa w zale¿noœci od charakterystyki kolejnych paczek danych.
W za³o¿eniu program ma umo¿liwiæ kompresjê du¿ych iloœci danych przy wykorzystaniu potencja³u obliczeniowego wspó³czesnych kart graficznych.

\section{Opis problemu}
	\begin{figure}[!ht]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/TS}
		\vspace*{-5mm}
		\caption{Szereg czasowy}
		\label{ref:ts}
	\end{figure}

Terabajty danych w postaci szeregów czasowych s¹ przetwarzane i analizowane ka¿dego dnia na ca³ym œwiecie. Zapytania i agregacje na tak wielkich porcjach danych jest czasoch³onne i wymaga du¿ej iloœci zasobów. Aby zmierzyæ siê z tym problemem, powsta³y wyspecjalizowane bazy danych, wspieraj¹ce analizê szeregów czasowych. Wa¿nym czynnikiem w tych rozwi¹zaniach jest kompresja oraz u¿ycie procesorów graficznych w celu przyspieszenia obliczeñ. Aby przetwarzaæ dane na GPU bez koniecznoœci ich ci¹g³ego kopiowania poprzez szynê PCI-E, powstaj¹ bazy danych po stronie GPU (najczêœciej rozproszone), takie jak MapD\footnote{Baza danych GPU - http://www.mapd.com/}\cite{MOSTAK} lub DDJ\footnote{https://github.com/d-d-j -  zaproponowana we wczeœniejszej pracy in¿ynierskiej}.
Innymi rozwi¹zaniami s¹ koprocesory obliczeniowe GPU, wspomagaj¹ce dzia³anie baz takich jak Cassandra, HBase, TepoDB, OpenTSDB czy PostgreSQL. Charakterystyka danych wielu szeregów wskazuje, ¿e przy odpowiedniej obróbce mog¹ byæ kompresowane z bardzo du¿ym wspó³czynnikiem kompresji, szczególnie jeœli by³oby mo¿liwe kompresowanie za pomoc¹ dynamicznie zmieniaj¹cych siê ci¹gów (ró¿nych) algorytmów kompresji i transformacji danych - kodowañ. Dla przyk³adu, jeœli jakiœ fragment szeregu jest sta³y, z nielicznymi wyj¹tkami, warto by³oby usun¹æ wyj¹tki, a resztê skompresowaæ jako jedn¹ liczbê - uzyskuj¹c wspó³czynnik kompresji rzêdu d³ugoœci danych.
\begin{definition}[Wspó³czynnik kompresji]
Stosunek rozmiaru danych wejœciowych $s_{in}$ kompresji $A$, do rozmiaru danych wyjœciowych $s_{out}$, bêdziemy nazywaæ wspó³czynnikiem kompresji i ozn. $C(A) = \frac{s_{in}}{s_{out}}$.
\end{definition}
\subsection{Forma szeregu czasowego}
Postaæ szeregu czasowego prezentuje rysunek \ref{ref:ts}. Dane w tej postaci s¹ próbkami pewnych pomiarów w czasie $t_{i}$, gdzie czas próbkowania nie musi byæ sta³y ($\Delta t \neq const$). Ponadto zak³adamy, ¿e wartoœci pomiêdzy
dwoma pomiarami mo¿na przybli¿yæ stosuj¹c interpolacjê liniow¹, co mo¿e byæ przydatne np. przy dodawaniu dwóch szeregów.
Najwa¿niejsze jednak jest to, ¿e jako pomiary pewnej wielkoœci, dane te najczêœciej zmieniaj¹ siê w charakterystyczny dla nich sposób, z pewnymi odstêpami w postaci b³êdów, które nazywaæ bêdê z ang. \emph{Outliers}.

\section{Lekka kompresja z SIMD}
Bazy danych przechowuj¹ce szeregi czasowe s¹ najczêœciej zorientowane kolumnowo oraz stosuj¹ metody lekkiej kompresji w celu oszczêdnoœci pamiêci. W tych przypadkach stosuje siê metody lekkiej kompresji, takie jak kodowanie s³ownikowe, delta lub sta³ej liczby bitów, zamiast bardziej skomplikowanych i wolniejszych metod, które czêsto zapewni³yby lepszy poziom kompresji. Systemy te ³aduj¹ swoje dane do pamiêci trwa³ej paczkami, które mog¹ byæ kompresowane osobno, przy u¿yciu ró¿nych algorytmów, zmieniaj¹cych siê dynamicznie w czasie. Takie kolumny wartoœci numerycznych tego samego typu wspaniale przetwarza siê przy u¿yciu procesorów typu SIMD, co daje wielokrotne przyspieszenie w stosunku do tradycyjnych architektur. Okazuje siê ¿e wiêkszoœæ algorytmów lekkiej kompresji mo¿e z du¿ym powodzeniem byæ w ten sposób zrównoleglona. Równie¿ dynamiczne generowanie statystyk nap³ywaj¹cych danych mo¿e byæ przyspieszone z u¿yciem SIMD, co otwiera mo¿liwoœæ implementacji wydajnych systemów, dynamicznie optymalizuj¹cych u¿yte kompresje w celu zwiêkszenia wspó³czynnika kompresji danych. 
	\begin{figure}[!ht]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/cascade}
		\vspace*{-5mm}
		\caption{Idea prostej kompresji kaskadowej}
		\label{ref:cascade}
	\end{figure}
Dodatkowo u¿ycie kaskadowej kompresji mo¿e wielokrotnie wzmocniæ poziom kompresji, pod warunkiem stworzenia dobrego planu kompresji, w³aœnie na podstawie wygenerowanych statystyk. Pomys³ takiego schematu pokazany pokazany jest na rysunku \ref{ref:cascade}. Ogromna moc obliczeniowa procesorów graficznych mo¿e pozwoliæ wygenerowaæ odpowiedni plan w rozs¹dnym czasie. Takie u¿ycie jest mo¿liwe np. w bazach danych po stronie GPU, gdzie jest to niezmiernie wa¿ne z powodu œcis³ego limitu pamiêci na kartach i ich wysokiego kosztu.

\section{Zawartoœæ pracy}
W tej pracy przedstawiê planer kompresji (optymalizator) kompresuj¹cy nap³ywaj¹ce paczki danych. Zaprezentujê nowe podejœcie do planera buduj¹cego drzewa kompresji i ucz¹cego siê ich konstrukcji na podstawie statystyk wêz³ów takich drzew generowanych w czasie rzeczywistym\footnote{jak równie¿ statystyk nap³ywaj¹cych danych}. Przedstawiê równie¿ zaimplementowane œrodowisko oraz u¿yte algorytmy lekkiej kompresji. W ramach tej pracy stworzone zosta³y 4 biblioteki, wykorzystuj¹ce technologiê \emph{NVIDIA CUDA}, tworz¹ce framework optymalizatora kompresji oraz program kompresuj¹cy kolumny podanego szeregu czasowego w sposób równoleg³y.
Nastêpny podrozdzia³ zawiera opis wczeœniejszych prac prowadzonych w tych tematach, a tak¿e krótki opis technologii, w tym architektury CUDA. W rozdziale 2 omówiê metody lekkiej kompresji, ze szczególnym uwzglêdnieniem kompresji FL oraz GFC. Rozdzia³ 3 jest w ca³oœci poœwiêcony optymalizatorowi kompresji oraz generowaniu drzew i statystyk. Nastêpnie przedstawiê implementacjê systemu oraz programu konsolowego. Ostatnie rozdzia³y 5 i 6 to wyniki prac i eksperymentów, a tak¿e podsumowanie oraz zakres przysz³ych prac i optymalizacji.

\section{Powi¹zane prace}

\subsection{Szeregi czasowe}
Szeregi czasowe s¹ typem danych dla których istnieje wiele efektywnych sposobów kompresji, zale¿nych od ich charakterystyki. W wielu pracach przedstawiono podejœcia do tego problemu od strony lekkiej kompresji. Najczêstszymi z nich s¹ kodowanie ekstremami \cite{FINK}, sta³ej d³ugoœci bitów \cite{PRZYMUS1}, czyli tzw. NULL Suppression (NS) oraz proste kodowania s³ownikowe np. wszystkich unikalnych wartoœci, które mo¿na zakodowaæ pewn¹ za³o¿on¹ z góry liczb¹ bitów \cite{ABADI}. \\
Dodatkowo do kompresji szeregów stosuje siê metody regresji \cite{MENSMANN}. Autor stosuje Piecewise Regression - regresjê odcinkow¹, polegaj¹c¹ na przybli¿aniu kawa³ków szeregu funkcj¹, np. wielomianem. Ma to swoj¹ wersjê stratn¹ jak i bezstratn¹, gdzie mo¿emy zapisaæ ró¿nicê od zadanej funkcji i wynik zapisaæ na mniejszej liczbie bitów. \\ Szeregi czasowe to nie tylko liczby ca³kowite. Analizuje siê tak¿e wiele sposobów kompresji liczb zmiennoprzecinkowych pojedynczej i podwójnej precyzji. Najczêœciej próbuje siê zamieniæ liczbê u³amkow¹ na ca³kowit¹ stosuj¹c skalowanie \cite{PRZYMUS2}. Istniej¹ te¿ bardziej skomplikowane metody na przyk³ad kompresji liczb double algorytmem FPC \cite{BURTSCHER}, który kompresuje liniow¹ sekwencjê liczb o podwójnej precyzji (IEEE 754), sekwencyjnie przewiduj¹c ka¿d¹ wartoœæ, a nastêpnie wykonuj¹c operacjê XOR z prawdziw¹ wartoœci¹ szeregu, po czym usuwane s¹ wiod¹ce zera.

\subsection{SIMD SSE}
Bior¹c pod uwagê algorytmy lekkiej kompresji dla szeregów, warto zwróciæ uwagê na udane próby optymalizacji z u¿yciem prostego SIMD jakim s¹ operacje wektorowe SSE na procesorach Intel \cite{ZHAO, LEMIRE}. W tych pracach pokazano przek³ad algorytmów kodowania z wyrównaniem do bajtów (Byte-Aligned Coding) oraz do s³ów (Word-Aligned Coding) i zmierzono wydajnoœæ implementacji wektorowej wersji tych kodowañ z u¿yciem SSE. Autorzy zastosowali równie¿ binarne pakowanie (Binary Packing) w formie algorytmu FOR (Frame of Reference) \cite{GOLDSTEIN} dziel¹c dane na bloki o d³ugoœci 128 elementów (zmiennych ca³kowitych o d³ugoœci 32 bitów) i stosuj¹c patchowanie. Taki algorytm okaza³ siê najwydajniejszy. Pokazano, ¿e bez spadku jakoœci kompresji mo¿na uzyskaæ w ten sposób wzrost szybkoœci kompresji od 2 do 4 razy w stosunku to tradycyjnej implementacji.

\subsection{Obliczenia GPU}
Dziêki ogromnej mocy obliczeniowej kart graficznych uzyskano znacz¹cy wzrost wydajnoœci wielu algorytmów daj¹cych siê w mniejszym lub wiêkszym stopniu zrównolegliæ. Przyk³adowymi algorytmami o tej w³aœciwoœci s¹ choæby radix sort\cite{SORT}, hashowanie kuku³cze\cite{PHASH,CHASH}, sumy prefixowe\cite{PPS} i inne zaimplementowane w podstawowych bibliotekach takich jak CUDPP\footnote{CUDA Data Parallel Primitives - http://cudpp.github.io/}
czy Thrust\footnote{Parallel algorithms library - https://developer.nvidia.com/thrust}. \\
Najwa¿niejsze s¹ jednak bardzo zadowalaj¹ce rezultaty zrównoleglania algorytmów u¿ywanych w bazach danych takich jak index search\cite{ANH}, wszelkiego rodzaju agregacje i operacje join, scatter i gather\cite{RUSSEK} oraz obliczanie statystyk danych\cite{KACZMAR1}, jak równie¿ dopasowywanie wyra¿eñ regularnych\cite{MORISHIMA}. Dla przyk³adu, wzrost wydajnoœci oferowany przez algorytmy z biblioteki Thrust, która jest niejako odpowiednikiem Std, jest œrednio 10-krotny\cite{CUDA_PERF} w stosunku do najszybszych wersji CPU. Wiêkszoœæ przytoczonych wy¿ej przyk³adów równie¿ reprezentuje wzrost wydajnoœci o rz¹d wielkoœci. W pracach odnoœnie akceleracji baz danych za pomoc¹ technologii CUDA, autorzy otrzymuj¹ przyspieszenie $20-60$ krotne\cite{BAKKUM}, w przypadku operacji \emph{SELECT WHERE} i \emph{SELECT JOIN} z agregacjami\cite{RUSSEK}. Powy¿sze wyniki zwykle s¹ osi¹gane bez uwzglêdniania czasu kopiowania danych na GPU, co jak obliczono zajmuje to œrednio ok $90\%$ czasu dzia³ania algorytmów\cite{KACZMAR2}.

\subsection{Kompresje}
Opisane wy¿ej algorytmy lekkiej kompresji szeregów czasowych, w wiêkszoœci zosta³y zaimplementowane przez Fang et al.\cite{FANG} oraz Przymus et al.\cite{KACZMAR2} w ich pracach, gdzie autorzy zaznaczaj¹ ogromny wzrost przepustowoœci takich algorytmów oraz ich wysok¹ skutecznoœæ w kompresji szeregów. W przypadku pierwszego jest to nawet to 56 GB/s dekodowania, a dla drugiego od 2 do 40 GB/s kodowania w zale¿noœci od stopnia skomplikowania algorytmu. Wiêkszoœæ przewidzianych metod ma swoje odpowiedniki z patchowaniem, w którym elementy niepasuj¹ce odk³adane s¹ do osobnej tablicy wyj¹tków. Prace te odnosz¹ siê jednak tylko do liczb ca³kowitych, a najczêœciej ca³kowitych bez znaku (naturalnych).\\
Lekk¹ kompresjê liczb zmiennopozycyjnych o podwójnej precyzji przestawi³ w swojej pracy O'Neil et al.\cite{ONEIL}, w której stosuj¹c technologiê CUDA i dziel¹c dane na odpowiednie bloki, zastosowano wariacjê algorytmu FOR i osi¹gniêto bardzo dobre wyniki rzêdu 75 Gb/s kodowania oraz a¿ 90 Gb/s dekodowania (daje to podobne rezultaty jak implementacja algorytmu FL dla liczb naturanlych\cite{PRZYMUS1}). Algorytm nazwano GFC, a jego uogólnienie dla liczb o pojedynczej precyzji przedstawiê dok³adnie w kolejnym rozdziale. \\
Wzrost wydajnoœci osi¹gniêto równie¿ na tle bardziej skomplikowanych metod (daj¹cych czêsto lepsze wspó³czynniki kompresji) jak kodowanie Huffmana\cite{CURRY}, gdzie równoleg³a implementacja na GPU uzyska³a \emph{2-5} krotne przyspieszenie, natomiast przepustowoœæ takiej kompresji to dla porównania 300 do 500 MB/s. Próby zoptymalizowania algorytmów takich jak LZSS w pracach Ozsoy et al.\cite{OZSOY}, skoñczy³y siê lekkim (max 2.2x) wzrostem wydajnoœci (w stosunku do wielordzeniowych implementacji CPU), przy uzyskanej przepustowoœci 1700 Mb/s w konfiguracji z dwoma kartami GPU\cite{OZSOY3}. Równie¿ inni autorzy maj¹ nadziejê na optymalizacjê z u¿yciem kodowañ s³ownikowych, takich jak LZW, pobijaj¹c wyniki CPU po przepisaniu ich do architektury SIMD\cite{SHYNI}. Mo¿na dodatkowo spotkaæ wariacje algorytmu LZSS przepisanego na CUDA, takie jak CANLZSS\cite{DTU}, która wed³ug autora przewy¿sza wydajnoœci¹ ponad 60 razy seryjn¹ implementacjê zwyk³ego LZSS. Kolejna optymalizacja GLZSS, w której zreorganizowano s³ownik to postaci tablicy haszy, oraz przyspieszono porównywanie podci¹gów\footnote{równie¿ zrównoleglaj¹c je na GPU}, osi¹gaj¹c dwukrotne przyspieszenie wzglêdem poprzednich prac\cite{ZU}. \\
Porównuj¹c szybkoœæ dzia³ania oraz wspó³czynniki kompresji uzyskane przez autorów, mo¿na dojœæ do wniosku, ¿e zastosowanie metod lekkich kompresji dla szeregów czasowych, w miejscach gdzie szczególne znaczenie ma szybka dekompresja, jest uzasadnione.

\subsection{Planery kompresji}
Okazuje siê, ¿e aby wielokrotnie zwiêkszyæ wspó³czynnik kompresji szeregu czasowego, warto go przetransformowaæ przed kompresj¹ b¹dŸ nawet skompresowaæ wielokrotnie ró¿nymi algorytmami. W tym celu powsta³y planery kompresji, które dzia³aj¹ na zasadzie kodowania kaskadowego, czyli ci¹gu nastêpuj¹cych po sobie kodowañ tworz¹cych drzewo. Dziêki zastosowaniu procesorów graficznych osi¹gniêto bardzo dobre wyniki zarówno pod wzglêdem wspó³czynnika kompresji, jak i szybkoœci dzia³ania. Dla przyk³adu przepustowoœæ kodowania 45 GB/s oraz dekodowania 56 GB/s zosta³a osi¹gniêta przez Fang et al.\cite{FANG}. W tym przypadku pos³uguj¹c siê heurystykami wykorzystuj¹cymi statystyki danych wejœciowych, spoœród ogromnej iloœci dostêpnych schematów kodowania, wyznaczano najlepiej pasuj¹ce\footnote{np. dla danych posortowanych powinny zaczynaæ siê od RLE itd.}. Nastêpnie wybierano spoœród nich plan spe³niaj¹cy zdefiniowane normy, np. plan o najwiêkszym wspó³czynniku kompresji. Statystyki na których oparty by³ algorytm pozyskiwano z informacji o kolumnie w bazie danych. Zanotowano du¿o lepsz¹ kompresjê ni¿ w przypadku tradycyjnego kodowania pojedyncz¹ metod¹ dla realistycznych danych. \\
Kolejnym, podobnym podejœciem do planera jest praca Przymusa et al.\cite{PRZYMUS2}, w której plan z³o¿ony jest z trzech warstw metod nastêpuj¹cych po sobie: transformacji, kodowania bazowego i pomocniczego. Cech¹ charakterystyczn¹ tego rozwi¹zania jest dynamiczny generator statystyk, który uaktualnia statystyki w momencie tworzenia planu, wykorzystuj¹c w³aœciwoœci poszczególnych metod takiej kompresji\footnote{szczególnie w przypadku minimalnej iloœci bitów potrzebnych do zapisania ka¿dej liczby}. Dodatkowo praca ta implementuje znajdowanie optimum ze wzglêdu na dwie sprzeczne zmienne (bi-objective optimizer): szybkoœæ dzia³ania i jakoœæ kompresji, stosuj¹c optymalnoœæ Pareto\cite{PARETO}. Generowanie statystyk dla takiego planera na GPU zapewnia do 70 razy lepsz¹ wydajnoœæ w stosunku do analogicznej implementacji na CPU\cite{KACZMAR2}.

\section{Technologie}
Procesory graficzne sta³y siê znacz¹cymi i potê¿nymi koprocesorami obliczeñ dla wielu aplikacji i systemów takich jak bazy danych, badania naukowe czy wyszukiwarki www. Nowoczesne GPU posiadaj¹ moc obliczeniow¹ o rz¹d wiêksz¹ ni¿ zwykle, wielordzeniowe procesory CPU, takie jak AMD FX 8XXX czy Intel Core i7. Dla przyk³adu flagowa konstrukcja firmy NVIDIA - GeForce GTX Titan X osi¹ga moc 6600 GFLOPS (miliardów operacji zmiennoprzecinkowych na sekundê), przy $336 GB/s$ przepustowoœci pamiêci, podczas gdy najszybsze procesory takie jak Intel Core i7-5960x osi¹gaj¹ nieca³e 180 GFLOPS, przy przepustowoœci $68 GB/s$. Kartom graficznym dorównuj¹ tylko inne jednostki typu SIMD, na przyk³ad karty obliczeniowe Xeon Phi. Pomimo tak osza³amiaj¹cych wyników, programowanie na jednostkach SIMD jest o wiele trudniejsze,
jak równie¿ ograniczone przepustowoœci¹ szyny PCI-E, która wynosi w porywach $8 GB/s$, co dodatkowo przemawia za u¿yciem kompresji przy przetwarzaniu szeregów czasowych, choæby w celu przyspieszenia kopiowania danych z i na kartê graficzn¹.

\subsection{CUDA}
Jedn¹ z wielu zalet architektury kart graficznych jest to, ¿e sk³adaj¹ siê z kilku multiprocesorów (SMs - Streaming Multiprocessors) architektury SIMD. Jest to w³aœciwie architektura typu SIMT, gdzie multiprocesor wykonuje w¹tki w grupach o licznoœci 32 zwanymi \emph{warps}. Architektura ta jest zbli¿ona do SIMD z t¹ ró¿nic¹, ¿e to nie organizacja wektora danych kontroluje jednostki obliczeniowe, a organizacja instrukcji pojedyñczego w¹tku. Umo¿liwia on zatem pisanie równolegle wykonywanego kodu dla niezale¿nych i skalowalnych w¹tków, jak i dla tych koordynowanych danymi.
	\begin{figure}[!ht]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.50]{img/CUDA_arch}
		\vspace*{-3mm}
		\caption{Architektura NVIDIA CUDA}
		\label{ref:cuda_arch}
	\end{figure}

Wszystkie w¹tki wykonuj¹ ten sam kod funkcji, któr¹ nazywa siê mianem kernela. Ponadto CUDA tworzy abstrakcjê bloków w¹tków, które zorganizowane s¹ w siatkê (GRID) i wspó³dziel¹ zasoby multiprocesora. Wa¿na jest równie¿ hierarchia pamiêci, w której czêœæ przydzielana jest w¹tkom w postaci pamiêci lokalnej i rejestrów, oraz pamiêci wspó³dzielonej przez w¹tki z tego samego bloku (Shared Memory) - te pamiêci musz¹ byæ znane w trakcie kompilacji kernela. Najwolniejsza jest pamiêæ globalna (Device Memory), wspólna dla wszystkich w¹tków, wszystkich bloków, na wszystkich multiprocesorach. Dok³adny opis tej architektury mo¿na znaleŸæ bezpoœrednio na stronie producenta.
	\begin{figure}[!ht]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.50]{img/CUDA_grid}
		\vspace*{-6mm}
		\caption{Abstrakcja bloków i siatki w CUDA}
		\label{ref:cuda_grid}
	\end{figure}

\chapter{Algorytmy lekkiej kompresji}

Przedstawiê kodowania u¿yte w implementacji planera kompresji oraz ich modyfikacje, a nastêpnie opiszê szczegó³owo dwa najwa¿niejsze, które zwykle koñcz¹ œcie¿ki kompresji w generowanych planach. S¹ to kodowania bazuj¹ce na pomyœle usuwania zbêdnych zer wiod¹cych, dla liczb naturalnych - AFL oraz u³amkowych - GFC. Trzeba zauwa¿yæ, ¿e operacja patchowania jest tutaj zaimplementowana odmiennie ni¿ w innych publikacjach, jako osobny rodzaj kodowania, mog¹cy przybieraæ wiele form, natomiast algorytmy nie maj¹ swoich wersji z patchowaniem.\\

\section{Global memory coalescing}
Tablice zaalokowane w pamiêci urz¹dzenia GPU Nvidia s¹ wyrównane do bloków o wielkoœci 256 bajtów przez sterownik urz¹dzenia. Urz¹dzenie mo¿e dostaæ siê do pamiêci przez 32, 64 lub 128 bajtowe transakcje ,które s¹ wyrównane do ich wielkoœci. Odczytuj¹c lub zapisuj¹c do pamiêci globalnej, wa¿ne jest zatem aby w¹tki wymaga³y dostêpu zawsze do kolejnych rekordów tablicy, najlepiej wszystkie nale¿¹ce do tego samego \emph{warp}. Dla osi¹gniêcia takiego rezultatu mo¿na zastosowaæ poni¿szy algorytm obliczania indeksów wejœciowych dla danego w¹tku CUDA. \\
Oznaczmy jako:
\begin{itemize}
	\item $\Sigma$ -- iloœæ przetwarzanych elementów
	\item $\omega$ -- iloœæ w¹tków w grupie
	\item $\kappa$ -- iloœæ elementów w bloku danych
	\item $\lambda$ -- iloœæ elementów przetwarzanych przez pojedynczy w¹tek
	\item $B_{size}$ -- wielkoœæ bloków w¹tków -- (CUDA block size)
	\item $B_{count}$ -- iloœæ bloków -- (CUDA block count)
	\item $w_{g}$ -- iloœæ grup w bloku
	\item $W_{lane}(t) = t_{idx} (mod\ \omega)$ -- indeks w¹tku t w grupie -- (warp lane)
\end{itemize}
\noindent
Za³ó¿my ¿e chcemy przetworzyæ 1MB danych tj. $1024*1024$ elementy, u¿ywaj¹c bloków z 4 grupami po 32 w¹tki ka¿dy, czyli 4 warpy. Ponadto chcemy aby bloki danych mia³y 32 rekordy, a ka¿dy w¹tek przetwarza³ 16 elementów: $\Sigma = 1024*1024$, $\omega = 32$,  $\kappa = 32$, $\lambda = 16$, $w_{g}$ = 4. \\
Bardzo ³atwo mo¿na obliczyæ ile wynosi rozmiar pojedynczego bloku $B_{size}$, oraz iloœæ wszystkich bloków, potrzebnych do przetworzenia wszystkich elementów wektora wejœciowego $B_{count}$:
$$B_{size} = \omega * w_{g} $$,
$$ B_{count} = \frac{\Sigma + B_{size}*\lambda - 1}{B_{size}*\lambda} $$

Przyjmuj¹c pocz¹tkowy indeks bloków danych dla w¹tku $t$ o indeksie $t_{idx}(t)$ z bloku $b_{idx}(t)$ za $\Psi(t) = (t_{idx}(t) - W_{lane}(t)) * \lambda / 32$, indeks bloku danych dla danego w¹tku mo¿na obliczyæ za pomoc¹ wzoru:
$$ d_{b}(t) = b_{idx}(t) * w_{g} * \lambda + \Psi(t) $$
co dla naszego przyk³adu obrazuje rysunek \ref{ref:cuda_data_blocks}.
\begin{figure}[!ht]
	\centering
	\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/cuda_data_blocks}
	\caption{Przejœcie z u³o¿enia w¹tków w bloku na bloki danych}
	\label{ref:cuda_data_blocks}
\end{figure}

Ka¿dej grupie w bloku CUDA odpowiada tyle samo bloków danych, przy czym bloki danych s¹ wielkoœci $\kappa$ elementów i ich numery s¹ potrzebne do obliczenia pocz¹tkowego indeksu wejœciowego dla w¹tku, który definiujemy jako $$ \mu_{0}(t) = d_{b}(t)*\kappa + W_{lane}(t) $$
Kolejne indeksy wyliczane s¹ jako przesuniêcia o $\omega$, czyli
$ \mu_{k}(t) = \mu_{0}(t) + k * \omega $, dla $ k \in [1,\kappa-1] $.
Tworzy to podzia³ danych wejœciowych, który zgodnie z przyk³adem obrazuje rysunek \ref{ref:cuda_data_blocks2}.

\begin{figure}[!ht]
	\centering
	\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/cuda_data_blocks2}
	\caption{Indeksy danych wejœciowych}
	\label{ref:cuda_data_blocks2}
\end{figure}

Dziêki takiemu u³o¿eniu kolejne w¹tki z tego samego warp, wykonuj¹ odczyt kolejnych rekordów z tablicy Ÿród³owej, poniewa¿ w¹tek 0 odczytuje rekord 0, w¹tek 1 rekord 1, a¿ wreszcie w¹tek $\omega$ rekord $\omega$. Nastêpnie po przesuniêciu o $\omega$ w¹tki ponownie odczytuj¹ dane, które s¹ ze sob¹ s¹siaduj¹ce. Dziêki temu odczyt mo¿e byæ po³¹czony (Global Memory Coalescing\cite{UENG}). £¹czny odczyt mo¿e byæ wielokrotnie szybszy ni¿ odczyty z nie kolejnych indeksów, co jest kluczowe przy budowie bardzo wydajnych algorytmów przetwarzaj¹cych dane na GPU.
W przypadku CUDA grupa powinna mieæ licznoœæ 32, co odpowiada iloœci w¹tków w jednym \emph{warp}.

\section{Podstawowe algorytmy transformacji szeregów}
\label{sec:trans_alg}
\begin{description}
\item[Delta] -- Zapisuje zmiany pomiêdzy kolejnymi danymi w szeregu, rejestruj¹c pierwsz¹ wartoœæ w metadanych. Bardzo dobrze sprawdza siê na danych posortowanych b¹dŸ o zmianach liniowych o sta³ej wartoœci. Algorytm ten zosta³ zaimplementowany czêœciowo z u¿yciem biblioteki Thrust i funkcji \emph{inclusive\_scan} - do dekodowania.
\item[Scale] -- Bardzo prosta transformacja, odmienna od wielu implementacji o tej samej nazwie, polegaj¹ca na odjêciu lub dodaniu (dla liczb ujemnych) najmniejszej dodatniej wartoœci szeregu. Bardzo dobrze sprawdza siê dla du¿ych wartoœci szeregu o ma³ej wariancji. Dla przyk³adu, maj¹c wartoœci: $${1234000, ..., 1234500, ..., 1234999}$$ dane zostan¹ zapisane jako ${0, 1, ..., 999}$ i bêd¹ mog³y byæ zredukowane do du¿o mniejszej liczby bitów.
\item[FloatToInt] -- Wersja algorytmu, któr¹ czêsto w literaturze nazywa siê mianem \emph{Scale}. Znaj¹c maksymaln¹ precyzjê danych zmiennopozycyjnych, mo¿liwe jest ich zapisanie w postaci liczb ca³kowitych, mno¿¹c przez odpowiedni¹ potêgê liczby 10. Oznacza to, ¿e maj¹c wektor cen w z³otówkach, mo¿na przemno¿yæ cenê 99.99 przez 100 otrzymuj¹c 9999 i zmieniæ reprezentacjê liczb na ca³kowite.
W wyniku takiego dzia³ania reprezentacja liczb ca³kowitych mo¿e ulec lepszej kompresji.
\item[Patch] -- Bardzo wa¿nym zadaniem w kompresji szeregów czasowych jest usuwanie wartoœci odstaj¹cych tzw. \emph{outliers}. Kodowanie to dzieli wektor danych na dwa wektory wzglêdem zdefiniowanego operatora, mówi¹cego np. ¿e jako wartoœci odstaj¹ce nale¿y uznaæ wszystkie wartoœci przekraczaj¹ce $90\%$ wartoœci maksymalnej. W ten sposób mo¿e byæ zdefiniowanych wiele ró¿nych wersji ,,patchowania'', dla przyk³adu, dziel¹c wartoœci na ujemne i dodatnie.

	\begin{figure}[!ht]
		\centering
		\includegraphics{img/Patch}
		\caption{Przyk³ad u¿ycia patchowania z operatorem - "wiêkszy od zera"}
		\label{ref:patch}
	\end{figure}

W przeciwieñstwie do innych prac algorytm ten nie zapisuje wyj¹tków wraz z ich pozycjami, umo¿liwiaj¹c lepsze ich skompresowanie w dalszych krokach. Zamiast tego przechowuje w metadanych zapisany bitowo stempel przynale¿noœci poszczególnych elementów wektora do pierwszej lub drugiej tablicy wynikowej. Rozmiar takich metadanych wynosi $(N+32)$ bitów, gdzie $N$ to liczba kompresowanych elementów.
\end{description}

\section{Algorytmy kompresji szeregów}
\begin{description}
\item[RLE] -- kodowanie d³ugoœci serii (Run-Length-Encoding) to sposób kompresji polegaj¹cy na zapisie ci¹gów takich samych wartoœci, jako wartoœæ i d³ugoœæ tego ci¹gu. W tym przypadku obie te wartoœci trafiaj¹ do 2 ró¿nych tablic, które nastêpnie mog¹ byæ kompresowane osobno. Szczególnie dobrze sprawdza siê w przypadku posortowanych danych, lub czêsto siê powtarzaj¹cych. Dla przyk³adu wektor ${5,5,5,5,1,1,1,1,17,17,17,17}$ zostanie skompresowany do ${5,1,17}$ oraz ${4,4,4}$. Data technika kompresji jest op³acalna jeœli œrednia d³ugoœæ ci¹gów przekracza 2 ($D_{sr} > 2$). \\ Dana metoda zosta³a zaimplementowana z u¿yciem biblioteki Thrust, stosuj¹c miêdzy innymi metodê \emph{reduce\_by\_key}.
\item[Dict] -- Kolejn¹ grup¹ kompresji s¹ kodowania bazuj¹ce na pomyœle s³ownikowym ($Dict_{K}$). Wykorzystuj¹ one informacjê o licznoœci poszczególnych wartoœci w wektorze. Kompresja s³ownikowa wykorzystuje $K$ najczêœciej wystêpuj¹cych wartoœci i zapisuje ich tablicê w metadanych. Nastêpnie wartoœci z wektora danych s¹ kodowane indeksami w tej tablicy, przy u¿yciu jak najmniejszej liczby bitów $bit_{cnt} = log_{2}(K)$. Reszta niepasuj¹cych wartoœci zapisywana jest do osobnej tablicy, co dzia³a podobnie jak w kodowaniu \emph{Patch}.
\item[Unique, Const] -- Zaimplementowane s¹ tak¿e lekko zoptymalizowane wersje kodowania $Dict_{K}$ dla $K=1$ - \emph{Const}, oraz $K=N_{u}$ - \emph{Unique}, gdzie $N_{u}$ jest liczb¹ unikalnych wartoœci w ca³ym kompresowanym wektorze. Dla przyk³adu, jeœli wszystkie wartoœci s¹ równe, z nielicznymi wyj¹tkami, zostanie wybrane kodowanie \emph{Const}, które zapisze najczêstsz¹ wartoœæ w metadanych i stworzy tablicê wyj¹tków, uzyskuj¹c bardzo wysoki stopieñ kompresji.
\end{description}

\subsection{Kodowanie AFL}
Ten rodzaj kodowania (Aligned Fixed-Length Encoding) nazywany jest kodowaniem o sta³ej d³ugoœci z wyrównaniem. Ogólny pomys³ algorytmu jest bardzo prosty i bazuje na algorytmie NS (null suppression), czyli usuwaniu wiod¹cych zer z liczb i zapisywanie ich na mniejszej iloœci bitów. W tym przypadku iloœæ bitów na których zapisujemy liczby jest znana z góry przed rozpoczêciem kodowania i nie ulega zmianie. Dla uproszczenia przyjmijmy, ¿e kompresujemy liczby naturalne o d³ugoœci 32 bitów, np. \emph{unsigned int}. Wyrównanie polega na grupowaniu wykonawczych w¹tków w grupy o pewnej licznoœci. W naszym przypadku bêdzie to liczba 32, czyli liczba w¹tków nale¿¹cych do jednego \emph{warpa}, z uwagi na wykorzystanie tzw. \emph{³¹cznego dostêpu do pamiêci globalnej CUDA}. Wtedy liczba kompresowanych elementów musi byæ wielokrotnoœci¹ d³ugoœci kodowanego s³owa pomno¿onej przez 32, czyli 1024. Kodowanie przebiega nastêpuj¹co:
\begin{enumerate}
\item Obliczana jest najmniejsza liczba bitów potrzebna do zakodowania wszystkich s³ów w wektorze, nazwijmy go $W$ i oznaczmy liczbê bitów jako $\sigma$:
$$ \sigma = log_{2}(max(W)) + 1 $$
\item Nastêpnie wektor elementów jest dope³niany, aby jego d³ugoœæ by³a wielokrotnoœci¹ 1024, a liczba dope³nionych elementów wraz z potrzebn¹ do zakodowania ka¿dej wartoœci liczb¹ bitów $\sigma$ zapisywana jest do metadanych.
\item Dla ka¿dego w¹tku $t$ CUDA ozn. \emph{$t=thread(b_{idx},t_{idx})$}, co oznacza w¹tek o indeksie $t_{idx}$ z bloku $b_{idx}$, wyznaczany jest pocz¹tkowy indeks danych wejœciowych i wyjœciowych dla tego w¹tku, zgodnie z algorytmem przedstawionym w poprzedniej sekcji.
Wielkoœæ bloków w¹tków ustalmy na $ B_{size} = 32 * 8 $ co sprawi, ¿e ka¿dy blok bêdzie siê sk³ada³ z 8 warpów, a grupy bêd¹ mia³y licznoœæ 32 ($\omega = 32$, $w_{g} = 8$). Ponadto, chcemy aby bloki danych by³y wielkoœci 32 elementów ($\kappa = 32$).
Maj¹c dane wejœciowe o indeksach $ {\mu_{0}, \mu_{1}, ..., \mu_{\kappa-1}} $ w¹tek zapisuje $\sigma$ dolnych bitów ka¿dej z liczb spod tych indeksów, do rekordów tablicy wynikowej. Wielkoœci bloków s¹ tak dobrane, aby ka¿dy w¹tek kodowa³ $\kappa$ liczb u¿ywaj¹c $\sigma$ bitów i otrzymuj¹c w ten sposób $\sigma$ liczb o wielkoœci $\kappa$. Za³ó¿my, ¿e $\kappa = 8$ oraz $\sigma = 3$, wtedy \ref{ref:afl4} obrazuje u³o¿enie danych wejœciowych o wielkoœci 8 bitów, skompresowanych do wielkoœci 3 bitów w wektorze wynikowym, przyjmuj¹c 16 iloœæ w¹tków w grupie ($\omega = 16$). Jak widaæ skompresowane dane idealnie mieszcz¹ siê w 3 rekordach tablicy wynikowej.

\begin{figure}[!ht]
	\centering
	\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/AFL4}
	\caption{AFL - zapis w tablicy wyjœciowej}
	\label{ref:afl4}
\end{figure}

Pocz¹tkowy indeks tablicy wynikowej pod który w¹tek ma zapisaæ skompresowane dane, wyliczany jest jako $ \nu_{0}(t) = d_{b}(t) * \sigma + W_{lane}(t) $. Do rekordu zapisywanych jest mo¿liwie najwiêcej bitów (tak jak pokazuje \ref{ref:afl4}), po czym jeœli brak³o miejsca dalsze bity przenoszone s¹ do nastêpnego rekordu, którego indeks wyliczany jest jako $ \nu_{k}(t) = \nu_{0}(t) + k * \omega $, gdzie $ k \in [1,\sigma-1] $. Tutaj równie¿ w¹tki pos³uguj¹ siê ³¹cznym dostêpem do pamiêci.
\item Po skompresowaniu, dane powinny mieæ dok³adnie $\sigma * \Sigma$ bitów d³ugoœci, nie licz¹c metadanych, które mo¿na zapisaæ w dwóch bajtach.

\end{enumerate}

Tak zaimplementowany algorytm okazuje siê byæ wielokrotnie szybszy od tradycyjnej implementacji \emph{Fixed-Length encoding} na CUDA, który jest równowa¿ny tej kompresji z $\omega = 1$.

\subsection{Kodowanie GFC}
\emph{GFC} to zaproponowana przez Burtscher et al.\cite{ONEIL} modyfikacja algorytmu \emph{pFPC} kompresji liczb zmiennoprzecinkowych o podwójnej precyzji, który jest równoleg³¹ wersj¹ algorytmu \emph{FPC} zaimplementowan¹ na procesory graficzne. Zamiast operacji XOR na prawdziwej i przewidzianej wartoœci kompresowanej liczby, metoda ta u¿ywa zwyk³ego odejmowania i dodatkowo zapamiêtuje znak, a kompresuje wartoœæ absolutn¹ tej ró¿nicy. Algorytm ten równie¿ stosuje wyrównanie, u¿ywaj¹c ³¹czny dostêp do pamiêci, za to w przeciwieñstwie do algorytmu \emph{AFL} nie wymaga aby iloœæ kompresowanych liczb przez pojedynczy w¹tek by³a podzielna przez 32. Mo¿e byæ to na przyk³ad 15. Blok danych bêdzie mia³ ponownie 32 wartoœci, poniewa¿ ka¿dy \emph{warp} musi przetworzyæ 32 wartoœci, aby uzyskaæ $\sigma$ liczb wynikowych. W tym algorytmie liczba $\sigma$ jest wyznaczana na bie¿¹co dla ka¿dej liczby osobno i wyra¿ona jest w bajtach. Opiszê tutaj wersjê algorytmu dla liczb o pojedynczej precyzji (32-bit) typu np. float. Zatem $\sigma$ mo¿e przybieraæ wartoœci 1, 2, 3 lub 4 i mo¿na zapisaæ j¹ na 2 bajtach. Iloœæ bajtów na których zostanie zapisana liczba x mo¿e byæ przedstawiona w uproszczeniu jako: $ \sigma(x) = log_{2}(x)/8 + 1 $. Poni¿ej zamieszczam prosty pseudokod algorytmu wykonywanego przez ka¿dy w¹tek w kernelu CUDA:
\begin{algorithm}[H]
 \caption{Pseudokod algorytmu kompresji GFC dla w¹tku t}
 \tcc{WEJŒCIE: $data$ - wektor do skompresowania}
 \tcc{WYJŒCIE: $compr$ - skompr. dane, $offsets$ - rozm. paczek}
 \nl $last$ = 0, $i$ = 0\;
 \While{$i < \lambda$}{
    \nl $diff$ = $data[\mu_{i}(t)]$ - $last$\;
    \nl $sign$ = bit znaku liczby $diff$\;
    \nl $diff = abs(diff)$\;
    \nl $minByte = \sigma(diff)$\;
    \nl $size$ = wykonaj sumê prefixow¹ na minByte w warpie\;
    \nl $save(compr, diff, minByte)$ \tcp*{zapisz $minByte$ bajtów liczby $diff$ do tablicy wynikowej}
    \nl $saveMeta(compr, minByte, sign)$ \tcp*{zapisz minByte oraz sign do tablicy wynikowej}
    \nl $off = off + size + 16$\;
    \nl $beg = beg + 32$\;
    \nl $last = data[beg-1]$\;
 }
 \If{$warp_{idx} == 31$}{
    \nl $offsets[warp] = off$\;
 }
 \label{ref:alg_gfc}
\end{algorithm}
\newpage
\noindent
Poszczególne \emph{warp-y} pracuj¹ oddzielnie, kompresuj¹c dane do osobnych paczek. Dane z ca³ego \emph{warp} pakowane s¹ w jedno miejsce, pocz¹wszy od wyliczonego wczeœniej przesuniêcia. W ka¿dej iteracji, \emph{warp} pakuje 32 liczby tworz¹c z nich podpaczkê, poprzedzon¹ ma³ym nag³ówkiem zawieraj¹cym informacje o znakach i liczbie bitów na których jest zapisana ka¿da liczba. Rozmiar tych informacji to 4 bity, wiêc dane w pesymistycznym wypadku mog¹ rozrosn¹æ siê o $l_{w}/2$ bajtów. Podpaczki zapisywane s¹ jedna za drug¹. Poniewa¿ rozmiar skompresowanej paczki nie jest znany w momencie uruchomienia algorytmu, potrzebna jest osobna tablica wynikowa, w której przechowywane s¹ wynikowe wielkoœci paczek. Ponadto trzeba zaalokowaæ tablicê wynikow¹ o wielkoœci
$ c_{s} = (l_{W} + 1)*\frac{9}{2} $ bajtów miejsca.

\begin{figure}[!ht]
	\centering
	\hspace*{-0.5cm}\includegraphics[scale=0.75]{img/gfc}
	\caption{wynik dzia³ania algorytmu \emph{GFC} - tablica wyjœciowa}
	\label{ref:gfc}
\end{figure}

Pomimo podobnego podzia³u na bloki danych, powy¿szy rodzaj kompresji znacz¹co ró¿ni siê od metody \emph{AFL}. Iloœæ stworzonych paczek danych przez ten algorytm wynosi $ p_{n} = w_{g} * B_{n} $. Paczki skompresowane przez poszczególne \emph{warp-y} nie przylegaj¹ do siebie, co widaæ na rysunku \ref{ref:gfc}, przez to minusem tej metody jest to, ¿e po kompresji nale¿y przekopiowaæ wszystkie $p_{n}$ paczek, o ró¿nych rozmiarach do tablicy wynikowej. Kopiowanie to jest odpowiednio szybkie dla ma³ej iloœci paczek o wiêkszych rozmiarach. Wtedy zachodzi zale¿noœæ, ¿e kiedy $p_{n}$ roœnie, wydajnoœæ kopiowania maleje, natomiast wydajnoœæ samego algorytmu wzrasta. Jeœli zmniejszymy $p_{n}$ automatycznie musimy zwiêkszyæ $\lambda$, bo $B_{n}$ zale¿y odwrotnie proporcjonalnie od $\lambda$, a im wiêksze $\lambda$, tym wolniejszy jest sam algorytm (pojedyncze w¹tki wykonuj¹ wiêcej pracy).
Warto sprawdziæ zatem, czy napisanie dedykowanego algorytmu kopiowania (jako kernel CUDA), mo¿e przyspieszyæ takie kopiowania danych na GPU, wzglêdem tradycyjnych wywo³añ \emph{cudaMemcpy} w pêtli. Próby zrównoleglenia tych kopiowañ na ró¿nych \emph{stream-ach} na mojej karcie graficznej (GeForce GT 640) skoñczy³y siê gorsz¹ wydajnoœci¹ ni¿ seria kopiowañ na \emph{stream 0}.

\chapter{Optymalizator kompresji}

W tym rodziale opiszê algorytm nazwany roboczo \emph{Online Stat compression Planner}, który bêdzie uczy³ siê budowaæ jak najlepsze drzewo kompresji na podstawie nap³ywaj¹cych danych, jednoczeœnie je kompresuj¹c. Zatem wydajnoœæ - compression ratio, powinno z czasem rosn¹æ, a¿ znajdzie siê na optymalnym poziomie. Ponadto algorytm ten przeszukuj¹c przestrzeñ ciekawych drzew kompresji i testuj¹c je na ma³ym fragmencie danych, bêdzie mia³ szansê znaleŸæ optymalne drzewo ju¿ na pocz¹tku swojego dzia³ania. Jednak w momencie zmiany charakterystyki danych, algorytm powinien zareagowaæ mutuj¹c drzewo, zmieniaj¹c jego wêz³y, aby dostosowaæ go do nowych danych. Na uwagê zas³uguje fakt, ¿e wszystkie dane na których operuj¹ optymalizator oraz drzewo, zawsze znajduj¹ siê na GPU, w celu minimalizacji liczby kopiowañ przez szynê PCI-E. Dodatkowo w oparciu o \emph{Shared Pointer} z biblioteki \emph{Boost} zaimplementowano inteligentne wskaŸniki na wektory danych w globalnej pamiêci GPU. Takie wskaŸniki przechowuj¹ce tablicê bajtów bêdê dalej nazywa³ SCBP\footnote{SCBP - inteligentny wskaŸnik na tablicê bajtów w globalnej pamiêci GPU (Shared Cuda Byte Pointer)}.
\begin{definition}[Paczka danych]
Optymalizator kompresuj¹c dane $D = {D_{1},D_{2},...,D_{N}}$ otrzymuje je w czêœciach $D_{i}$ o zdefiniowanym maksymalnym rozmiarze, nazywanych paczkami.
\end{definition}

\section{Kodowanie}
Wszystkie algorytmy kompresji zosta³y zaimplementowane jako klasy dziedzicz¹ce po
abstrakcyjnej klasie kodowania (\emph{Encoding}), implementuj¹c metody kompresji i
dekompresji dla wszystkich typów wspieranych przez system (optymalizator).
Dla nas najwa¿niejsze s¹ dwie metody:
\begin{description}[noitemsep,nolistsep]
\item[Encode] -- przyjmuje dane do kompresji jako SCBP oraz typ danych do kompresji.
Metoda ta kompresuje dane i zwraca wektor wskaŸników SCBP d³ugoœci 2 lub 3, z których pierwszy jest zawsze metadanymi.
\item[Decode] -- przyjmuje w zasadzie to co zwraca \emph{Encode} oraz typ danych,
a zwraca zdekodowane dane w postaci SCBP.
\end{description}
Obiekt ka¿dego kodowania mo¿e byæ stworzony za pomoc¹ fabryki, podaj¹c jego typ oraz typ danych jakie ma kompresowaæ.
Aby kodowania, a raczej ich wynik by³ mo¿liwy do zserializowania i w nastêpstwie pozwala³ odtworzyæ schemat u¿yty do kompresji, przed metadanymi wyniku dodawany jest header w postaci: \emph{[Typ Kodowania (16 bit), Typ danych (16 bit),
D³ugoœæ metadanych (32 bit)]}, nazwijmy go EH\footnote{EH - header metadanych wyniku kodowania}.
Ponadto kodowanie umo¿liwia sprawdzenie jaki jest jego typ wynikowy oraz ile skompresowanych czêœci zwraca, np. metody \emph{PATCH} lub \emph{DICT} zwracaj¹ po 2 wyniki.

\section{Drzewo kompresji}
    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.55]{img/tree}
        \caption{Schemat drzewa kompresji}
        \label{ref:tree}
    \end{figure}
Drzewo kompresji jest implementacj¹ idei kompresji kaskadowej. Wêz³owi drzewa odpowiada kompresja
danego typu. Wêze³ ma tyle dzieci ile wyników zwraca kodowanie które reprezentuje.
Dodatkowy typ kodowania zosta³ dodany aby oznaczyæ liœcie takiego drzewa. Przyk³adowe drzewo
zosta³o przedstawione na rysunku \ref{ref:tree}. Drzewo mo¿e byæ tak¿e zapisane jako ci¹g typów kodowañ
(który dalej bêdê nazywa³ \emph{TreePath}, na przyk³ad pokazane drzewo mo¿na przedstawiæ jako:
\newline
\small{\textit{PATCH, RLE, AFL, NONE, SCALE, GFC, NONE, FLOAT\_TO\_INT, CONST, AFL, NONE}}
\newline
Schemat ten jest o tyle wa¿ny, ¿e w ten sposób bêd¹ u³o¿one fragmenty skompresowanych danych przez algorytm kompresji drzewem.

\subsection{Algorytm kompresji drzewem}
    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.55]{img/tree_compress}
        \caption{Schemat przebiegu algorytmu kompresji drzewem}
        \label{ref:tree_compress}
    \end{figure}
Algorytm kompresji drzewem jest rekurencyjny pocz¹wszy od korzenia drzewa i za wejœcie
dostaje tylko dane do skompresowania w postaci SCBP. Ogólna idea polega na kompresowaniu
danych odpowiednim koderem reprezentowanym przez wierzcho³ek drzewa i przekazywaniu wyników
dzieciom tego wêz³a. Dzia³anie kompresji opisuje algorytm \ref{alg:tree_compress}.

\begin{algorithm}[H]
\label{alg:tree_compress}
 \caption{Pseudokod algorytmu kompresji drzewem}
 \SetKwFunction{algoN}{$Node \mapsto Compress$}
 \SetKwFunction{algoT}{$Tree \mapsto Compress$}
 \SetKwProg{myalg}{Metoda}{}{}
 \KwIn{DATA -- dane do skompresowania (GPU)}
 \KwOut{RES -- skompresowane dane (GPU), wynik w postaci wektora SCBP}
 \myalg{\algoN{}}{
    \nl $X \gets$ wêze³ na którym wywo³ano metodê\;
    \nl $K \gets$ pobierz koder typu reprezentowanego przez wêze³ $X$ z fabryki\;
    \nl $COMPR \gets$ zakoduj $DATA$ u¿ywaj¹c kodera $K$\;
    \nl $EH \gets$ stwórz odpowiedni nag³ówek kodowania\;
    \nl do³¹cz $EH$ na pocz¹tku wektora $COMPR$\;
    \uIf{$X$ jest liœciem}{
        \nl dopisz $COMPR$ do $RES$\;
    }
    \Else{
        \ForEach{$D$ dziecka $X$}{
            \nl $CHILD\_RES \gets$ wywo³aj metodê Compress na $D$\;
            \nl dopisz $CHILD\_RES$ na koñcu wektora $RES$\;
        }
    }
    \nl uaktualnij compression ratio uzyskane przez aktualne poddrzewo\;
    \nl \Return{$RES$}\;
 }
 \setcounter{AlgoLine}{0}
 \myalg{\algoT{}}{
    \nl $ROOT \gets$ pobierz korzeñ drzewa\;
    \nl $VEC \gets$ wykonaj metodê $Compress(DATA)$ na $ROOT$\;
    \If{ustawiony wskaŸnik na statystyki}{
        \nl zaktualizuj statystyki; \tcp*{opisane w 2 fazie optymalizatora}
    }
    \nl $RES \gets$ po³¹cz wektor wyników $VEC$ w jeden ci¹g pamiêci\;
    \nl \Return{$RES$}\;
 }
\end{algorithm}

Po skompresowaniu danych za pomoc¹ korzenia drzewa uzyskujemy wektor kawa³ków skompresowanych danych
oraz nag³ówków. Ostatni¹ czynnoœci¹ w algorytmie jest po³¹czenie tych danych w jeden ci¹g wynikowy
(pojedyncza tablica zaalokowana na GPU). Na rysunku \ref{ref:tree_compress} widaæ prosty przebieg dzia³ania
algorytmu. Jako \emph{E\#} oznaczono nag³ówki doczepiane z ró¿nych kodowañ.
Jak widaæ, nag³ówki odzwierciedlaj¹ strukturê drzewa i s¹ to¿same z \emph{TreePath},
pomijaj¹c kawa³ki skompresowanych danych (\emph{A, B, C}). Dziêki temu mo¿na odtworzyæ drzewo do dekompresji.

\subsection{Algorytm dekompresji drzewem}
Algorytm dekompresji drzewem jest bardziej skomplikowany ni¿ kompresja i sk³ada siê z
dwóch faz: rekonstrukcji struktury drzewa i w³aœciwej dekompresji drzewem. Ogólny schemat
ca³oœci algorytmu pokazany jest na rysunku \ref{ref:tree_decompress}.

\subsubsection{Rekonstrukcja drzewa}
Kolejny algorytm rekurencyjny (patrz algorytm \ref{alg:rec_tree}), który na wejœciu dostaje SCBP ze skompresowanymi danymi oraz
offset - referencja do parametru okreœlaj¹cego po³o¿enie ju¿ odczytanego fragmentu danych, tj.
od jakiego bajtu nale¿y czytaæ dalsze dane wejœciowe. Idea algorytmu polega na odczytywaniu
kolejnych nag³ówków \emph{EH} i budowaniu na ich podstawie drzewa, odpowiadaj¹cego drzewu u¿ytemu
do kompresji.

\begin{algorithm}[H]
\label{alg:rec_tree}
 \scriptsize
 \caption{Pseudokod algorytmu rekonstrukcji drzewa}
 \SetKwFunction{algo}{$Tree \mapsto DecompressNodes$}
 \SetKwProg{myalg}{Metoda}{}{}
 \KwIn{DATA -- skompresowane dane (GPU), OFFSET -- przesuniêcie (REF)}
 \KwOut{NODE -- zrekonstruowany wêze³ drzewa}
 \myalg{\algo{}}{
    \nl $EH \gets$ odczytaj nag³ówek z wejœcia\;
    \nl $OFFSET += SIZEOF(EH)$\;
    \nl $NODE \gets$ stwórz wêze³ typu wskazywanego przez $EH$\;
    \nl $MET\_SIZE \gets$ pobierz rozmiar metadanych z $EH$\;
    \nl $MET \gets$ odczytaj metadane o rozmiarze $MET\_SIZE$\;
    \nl $OFFSET += MET\_SIZE$\;
    \nl ustaw metadane w $NODE$ na $MET$\;
    \uIf{$NODE$ ma typ \emph{NONE}, czyli jest liœciem}{
        \nl $SIZE \gets$ odczytaj z $MET$ rozmiar skompresowanych danych\;
        \nl $DATA \gets$ odczytaj z wejœcia $SIZE$ bajtów\;
        \nl ustaw dane w wêŸle $NODE$ na $DATA$\;
        \nl $OFFSET += SIZE$\;
    }
    \Else{
        \nl $K \gets$ pobierz koder o typie wskazywanym przez $EH$\;
        \nl $N \gets$ pobierz iloœæ wyników zwracanych przez koder $K$\;
        \For{i=0 to N}{
            \nl $CHILD\_NODE \gets DecompressNodes(DATA, OFFSET)$\;
            \nl dodaj $CHILD\_NODE$ jako dziecko $NODE$\;
        }
    }
    \nl \Return{$NODE$}\;
 }
\end{algorithm}
\normalsize

\newpage
\subsubsection{Dekompresja}
Po odtworzeniu drzewa na korzeniu wywo³ywana jest metoda \emph{Decompress}, która nie
przyjmuje ¿adnych parametrów, za to zwraca zdekodowane dane w postaci SCBP. Pokazuje
to algorytm ~\ref{alg:tree_decompress}.

\begin{algorithm}[H]
\label{alg:tree_decompress}
 \scriptsize
 \caption{Pseudokod algorytmu dekompresji drzewem}
 \SetKwFunction{algo}{$Node \mapsto Decompress$}
 \SetKwProg{myalg}{Metoda}{}{}
 \KwIn{}
 \KwOut{RES -- zdekodowane dane (GPU)}
 \myalg{\algo{}}{
    \nl $X \gets$ wêze³ na którym wywo³ano metodê\;
    \nl $K \gets$ pobierz koder typu reprezentowanego przez wêze³ $X$ z fabryki\;
    \nl $MET \gets$ pobierz metadane zapisane w wêŸle $X$\;
    \nl $W \gets$ stwórz wektor wskaŸników SCBP i dodaj do niego $MET$\;
    \uIf{$X$ jest liœciem}{
        \nl $DATA \gets$ pobierz dane zapisane w wêŸle $X$\;
        \nl dodaj $DATA$ na koñcu wektora $W$\;
    }
    \Else{
        \ForEach{$D$ dziecko $X$}{
            \nl $CHILD\_RES \gets$ wykonaj metodê $Decompress()$ na $X$\;
            \nl dodaj $CHILD\_RES$ na koñcu wektora $W$\;
        }
    }
    \nl $RES \gets$ u¿yj kodera $K$ do zdekodowania wektora $W$\;
    \nl \Return{$RES$}\;
 }
\end{algorithm}
\normalsize

Podsumowuj¹c, jest to implementacja kaskadowej kompresji (rekurencyjnej z u¿yciem drzew jako reprezentacji).
Dodatkowo drzewa te posiadaj¹ wskaŸnik na statystyki drzewa i mog¹ je uaktualniaæ, co bêdzie szerzej
opisane w czêœci poœwiêconej 2 fazie algorytmu optymalizatora.
    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.55]{img/tree_decompress}
        \caption{Schemat przebiegu algorytmu dekompresji drzewem}
        \label{ref:tree_decompress}
    \end{figure}

\section{Statystyki}

Warunkiem podejmowania dobrych decyzji przez optymalizator jest znajomoœæ charakterystyki danych na których operuje. G³ówne zastosowanie statystyk w tym systemie, opiera siê na przesiewaniu wszystkich mo¿liwych drzew do tych najistotniejszych, które mog¹ uzyskaæ dobry wspó³czynnik kompresji. Ponadto, niektóre statystyki wykorzystywane s¹ przez same kodowania, aby odpowiednio dzia³aæ. W tym systemie zaimplementowano statystyki takie jak:
\begin{enumerate}
\item \emph{IsFloatingPoint} -- czy dane maj¹ typ zmiennoprzecinkowy czy ca³kowity
\item \emph{Sorted} -- czy dane s¹ posortowane (obojêtnie czy rosn¹co czy malej¹co)
\item \emph{Min} i \emph{Max} -- wartoœæ minimalna i maksymalna w zbiorze danych
\item \emph{Precision} -- maksymalna dok³adnoœæ (precyzja) danych, czyli iloœæ miejsc po przecinku
\item \emph{MinBitLength} -- minimalna liczba bitów na których mo¿na zakodowaæ ka¿d¹ liczbê ze zbioru
\item \emph{Size} -- rozmiar danych
\item \emph{RleMetric(N)} -- statystyka dla kodowania RLE opisana dok³adnie w nastêpnej podsekcji
\item \emph{Dictionary Counter} -- histogram wszystkich unikalnych wartoœci ze zbioru
\item \emph{Mean} -- œrednia arytmetyczna liczb w zbiorze
\end{enumerate}

W systemie w bardzo ³atwy sposób mo¿na implementowaæ dodatkowe statystyki i udostêpniaæ je do optymalizatora w celu implementacji dodatkowych regu³.

\subsection{Metryka RLE}
\begin{definition}
Metryk¹ RLE bêdziemy nazywaæ œredni¹ z d³ugoœci maksymalnych ci¹gów równych liczb, nie d³u¿szych ni¿ N, w danych D i ozn. $RLE_{M}(D, N)$, gdzie $N \geq 2$. Oznaczmy jako $l_{i}^{N}$ d³ugoœæ ci¹gu równych liczb, pocz¹wszy od indeksu $i$, nie d³u¿szego ni¿ $N$, oraz d³ugoœæ danych $D$ jako $k$. Wtedy $$RLE_{M}(D, N) = \frac{\sum_{i=0}^{k} l_{i}^{N}}{k} $$
\end{definition}
Dla przyk³adu, jeœli weŸmiemy $N=2$ oraz dane D: $1112234444555555$, wtedy odczytane ci¹gi równych liczb nie d³u¿sze ni¿ 2 wynosz¹: $2212112221222221$, z czego œrednia jest równa $\frac{27}{16} \approx 1.7$. Natomiast podstawiaj¹c $N=4$: $3212114321444321$, œrednia wyniesie $\frac{38}{16} \approx 2.4$. Daje to wyobra¿enie o œredniej d³ugoœci ci¹gów równych liczb w danych, a ponadto jest bardzo wydajne obliczeniowo. Wyliczanie takiej statystyki jest trywialnie równoleg³e, poniewa¿ mo¿na w ka¿dym w¹tku wyliczaæ ci¹g pocz¹wszy od innego indeksu, niezale¿nie. Pseudokod wyliczania ci¹gu dla pojedynczego w¹tku CUDA pokazuje algorytm \ref{alg:rle_metric}. W ostatnim kroku wystarczy obliczyæ œredni¹, korzystaj¹c na przyk³ad z gotowej funkcji z biblioteki \emph{Thrust}. W tej pracy przyjmujê $N = 2$, poniewa¿ mo¿na udowodniæ, ¿e:
\begin{lemma}
Jeœli $RLE_{M}(D, 2) > 1.5$, to wykorzystanie kodowania RLE zmniejszy rozmiar danych $D$. 
\begin{proof}
Kodowanie ci¹gu równych liczb odbywa siê za pomoc¹ pary wartoœci, wiêc aby rozmiar danych siê zmniejszy³, ci¹gi œrednio musz¹ mieæ d³ugoœæ wiêksz¹ ni¿ 2. Przyjmuj¹c $n_{1}, n_{2}, ..., n_{m}$ jako d³ugoœci ci¹gów, oraz $n_{sr}$ jako œredni¹ d³ugoœæ tych ci¹gów, $\frac{\sum_{i=1}^{m} n_{i}}{m} = n_{sr} > 2$ implikuje wspó³czynnik kompresji wiêkszy od $1.0$.
$$ \sum_{i=1}^{m} n_{i} = k \implies \frac{k}{m} > 2 $$
Zatem warunkiem koniecznym i dostatecznym jest, aby $ m < \frac{k}{2} $. Mo¿na zauwa¿yæ, ¿e ci¹g o d³ugoœci $n_{i}$ zostanie przez algorytm zapisany jako ci¹g $n_{i}-1$ dwójek, oraz jedynkê, zatem wzór na metrykê mo¿na zapisaæ w zale¿noœci od $n_{i}$, jako:
$$ RLE_{M}(D,2) = \frac{\sum_{i=1}^{m} (2*n_{i}-1)}{k} = \frac{2(n_{1}+...+n_{m})-m}{k}$$
po przekszta³ceniu:
$$ RLE_{M}(D,2) = 2 - \frac{m}{k} \implies (2 - RLE_{M}(D,2)) \cdot k = m < \frac{k}{2} $$
A z tego ju¿ wprost wynika, ¿e $ RLE_{M}(D,2) > 1.5 $

\end{proof}
\end{lemma}

W implementacji algorytmu, aby unikn¹æ sprawdzania warunku koñca tablicy, warto jest zrezygnowaæ z obliczania $N-1$
ostatnich wartoœci, które maj¹ znikomy wp³yw na wynik, szczególnie dla du¿ego rozmiaru danych.

\begin{algorithm}[H]
\label{alg:rle_metric}
 \small
 \caption{Obliczanie metryki RLE}
 \KwIn{DATA -- wektor danych wejœciowych\;
 N -- argument metryki RLE (maks. d³ugoœæ sprawdzanego ci¹gu)\;
 IDX -- globalny indeks w¹tku (unikalny)
 }
 \KwOut{LENGTHS -- d³ugoœci ci¹gów równych liczb}
 \tcc{Wykonaj równolegle dla ka¿dego w¹tku CUDA}
 \SetKwFunction{algo}{GetRunLenN}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
 	\nl \If{$IDX >= length(DATA)-N$}{ \nl \Return{} }
 	\nl $num \gets 1, out \gets 1, last \gets 1$\;
 	\nl \For{$i=1$ to $N$}{
 		\nl $out \gets DATA[IDX] == DATA[IDX+i]$\;
 		\nl $num += out$ \& $last$\;
 		\nl $last \gets out$\;
 	}
 	\nl $LENGTHS[IDX] \gets num$\;
 }
\end{algorithm}
\normalsize

\subsection{Precyzja}
Kolejn¹ wa¿n¹ statystyk¹ dla liczb zmiennoprzecinkowych jest precyzja, która odnosi siê do tego, czy warto zastosowaæ zmianê wartoœci na typ ca³kowitoliczbowy, stosuj¹c przemno¿enie\footnote{patrz kodowanie \emph{FLOAT\_TO\_INT} str. ~\pageref{sec:trans_alg}} przez odpowiedni¹ potêgê liczby 10. Analogicznie do metryki RLE, algorytm wyliczania precyzji jest trywialnie równoleg³y, a obliczanie precyzji pokazuje algorytm \ref{alg:precision}.

\begin{algorithm}[H]
\label{alg:precision}
 \small
 \caption{Obliczanie precyzji}
 \KwIn{VALUE -- wartoœæ wymierna;
 MAX\_PREC -- maksymalna precyzja
 }
 \KwOut{PREC -- precyzja}
 \SetKwFunction{algo}{GetPrecision}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
	\nl $E \gets 1$\;
	\nl $MP \gets 10^{MAX\_PREC}$\;
	\nl \While{$(\frac{round(VALUE \cdot E)}{E} \neq VALUE)\ \&\&\ (E < MP)$}{
		\nl $E \gets E \cdot 10$\;
	}
	\nl \Return{$\frac{log_{f}(E)}{log{f}(10)}$}\;
 }
\end{algorithm}
\normalsize
Pomiary w rzeczywistoœci maj¹ konkretn¹ dok³adnoœæ i czêsto z góry wiadomo jaka jest precyzja poszczególnych
kolumn szeregu czasowego. Te informacje, jeœli dostêpne, mog¹ byæ przekazane jako parametr w nag³ówku szeregu i ustawiane jako domyœlne zamiast wyliczania jej na bie¿¹co za pomoc¹ powy¿szego algorytmu.

\section{Optymalizator}
Algorytm optymalizatora kompresji maksymalizuje wspó³czynnik kompresji, jednoczeœnie staraj¹c siê wybraæ jak najmniejsze i najni¿sze drzewo kompresji. G³ównym pomys³em jest tworzenie statystyk krawêdzi drzewa kompresji o kszta³cie pe³nego drzewa binarnego (z tego wzglêdu kodowania mog¹ zwracaæ co najwy¿ej 2 wyniki). Nic nie stoi jednak na przeszkodzie, aby algorytm ten uogólniæ na kodowania zwracaj¹ce dowolnie du¿¹ iloœæ wyników. 

\begin{definition}[Optymalne drzewo]
Drzewo kompresji bêdziemy nazywaæ optymalnym, jeœli dla aktualnie przetwarzanych danych, wykazuje najwy¿szy wspó³czynnik kompresji, wœród wszystkich znanych i zbadanych drzew. Drzewo wybrane jako optymalne to drzewo,
które wierzymy, ¿e jest optymalne wedle posiadanych informacji.
\end{definition}
\noindent
Algorytm sk³ada siê z 3 faz, a jego zarys wygl¹da nastêpuj¹co:
\begin{enumerate}
\item Dla ma³ego fragmentu danych generujemy kandyduj¹ce drzewa kompresji (patrz def. \ref{def:candidate}), zapisuj¹c statystyki krawêdzi w drzewie binarnym, po czym wybieramy drzewo o najlepszym wspó³czynniku kompresji z niewielk¹ poprawk¹ od wysokoœci drzewa.
\item Kompresujemy odpowiednio du¿¹ paczkê danych u¿ywaj¹c drzewa ustawionego jako optymalne i odpowiednio aktualizujemy statystyki krawêdzi podczas kompresji.
\item Jeœli wspó³czynnik kompresji dla drzewa ustawionego jako optymalne pogorszy³ siê, zmieniamy drzewo wymieniaj¹c odpowiednie poddrzewo na lepsze, wed³ug statystyk krawêdzi.
\end{enumerate}

\subsection{Faza 1 - generowanie}
Ten fragment opisuje rekurencyjny algorytm generowania kandyduj¹cych drzew na postawie statystyk. Faza ta dzia³a na ma³ej czêœci danych wejœciowych rzêdu $1\%$ rozmiaru paczki, poniewa¿ mo¿e byæ relatywnie czasoch³onna wzglêdem ca³oœci algorytmu.
\begin{definition}[Drzewo kandyduj¹ce]
\label{def:candidate}
Drzewo, którego ka¿dy wêze³ zosta³ wybrany jako kontynuacja wêz³a poprzedniego, wedle okreœlonych regu³ (heurystyki).
\end{definition}
\noindent
Regu³y tworzone s¹ na podstawie statystyk danych, które dany wêze³ ma dostaæ do kompresji, typu poprzedzaj¹cej go kompresji oraz typu danych. Znany jest tak¿e aktualny poziom drzewa na którym ma siê znaleŸæ nowy wêze³. Metoda zwracaj¹ca kontynuacje zosta³a nazwana roboczo \emph{GetContinuations} i zwraca listê typów kodowañ, wybranych przez regu³y\footnote{w ogólnoœci, jest to heurystyka okreœlaj¹ca zbiór drzew kandyduj¹cych dla konkretnych danych}. 
Kilka przyk³adów mo¿liwych regu³:
\begin{itemize}
\item Jeœli poprzednikiem kodowania nie by³o \emph{FLOAT\_TO\_INT}, dane maj¹ nisk¹ precyzjê i niewielk¹ wartoœæ maksymaln¹, a ponadto typ danych to \emph{double}, to dodaj do listy kontynuacji typ kodowania \emph{FLOAT\_TO\_INT}, poniewa¿ jest zasadne.
\item Jeœli poprzednim kodowaniem by³o \emph{GFC} albo \emph{AFL}, to nie kompresuj ju¿ wiêcej i jako jedyn¹ mo¿liw¹ kontynuacjê zwróæ NONE. Jeœli nie, a typ danych to \emph{float} lub \emph{double} to dodaj \emph{GFC} do listy mo¿liwych kontynuacji, w p.p. dodaj \emph{AFL}.
\end{itemize}

Algorytm kompresuje dane w trakcie generowania drzew oraz jednoczeœnie oblicza i uaktualnia statystyki krawêdzi w drzewie binarnym (o tym w fazie 2). Tê fazê optymalizatora implementuje metoda \emph{FullStatisticsUpdate}, której pseudokod pokazany jest jako algorytm \ref{alg:faza1}.

\begin{algorithm}[H]
 \label{alg:faza1}
 \scriptsize
 \caption{Faza 1 algorytmu optymalizatora}
 \KwIn{DATA -- ma³a paczka danych\;
 ET -- typ kompresji, DT -- typ danych\;
 LEVEL -- aktualny poziom drzewa
 }
 \KwOut{RES -- lista interesuj¹cych drzew z ich wynikami}
 \SetKwFunction{algo}{FullStatisticsUpdate}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
	\nl $STAT \gets$ policz statystyki dla $DATA$\;
	\nl $RES \gets$ pusty wektor drzew\;
	\nl $CONT \gets$ wywo³aj $GetContinuations(ET, DT, STAT, LEVEL)$ \tcp{pobierz mo¿liwe kontynuacje}
	\ForEach{$C$ from $CONT$}{
		\nl $T \gets$ stwórz drzewo o jednym wêŸle reprezentuj¹cym kodowanie $C$ z typem danych $DT$\;
		\nl $COMPR \gets$ zakoduj dane $DATA$ u¿ywaj¹c $T$\;
		\nl $DT \gets$ typ danych zwracany przez kodowanie $C$\;
		\nl zaktualizuj w $T$ uzyskany wspó³czynnik kompresji\;
		\eIf{liczba wyników zwracana przez $C$ jest równa 1}{
			\nl $PART1 \gets$ wywo³aj $FullStatisticsUpdate(COMPR[1], C, DT, LEVEL+1)$\;
			\nl $PART1 \gets$ wywo³aj $CrossTrees(T, PART1, length(DATA), length(COMPR[0])$\;
		}(\tcp*[f]{jest równa 2}){
			\nl $PART1 \gets$ wywo³aj $FullStatisticsUpdate(COMPR[1], C, DT, LEVEL+1)$\;
			\nl $PART2 \gets$ wywo³aj $FullStatisticsUpdate(COMPR[2], C, DT, LEVEL+1)$\;
			\nl $PART1 \gets$ wywo³aj $CrossTrees(T, PART1, PART2, length(DATA), length(COMPR[0])$\;
		}
		\If{$PART1$ jest pusty}{
			\nl dodaj $T$ do $PART1$\;
		}
		\Else{
			\nl dopisz $PART1$ na koñcu wektora $RES$\;
		}
	}
	\nl \Return{$RES$}\;
 }
\end{algorithm}
\normalsize
\noindent
Metody \emph{CrossTrees} tworz¹ wszystkie mo¿liwe kombinacje, w których $T$ jest wierzcho³kiem, a drzewa z kolejnych dwóch argumentów (wektory drzew), jego poddrzewami. Dodatkowo uaktualniany jest wspó³czynnik kompresji po³¹czonych drzew. Przyk³adem dzia³ania tej metody jest rysunek \ref{ref:phase1} oraz poni¿szy schemat:
$$ PART1 = \{{T_{1}^A, T_{2}^A, ..., T_{N}^A}\}, PART2 = \{{T_{1}^B, T_{2}^B, ..., T_{M}^B}\} $$
$$ CrossTrees(T, PART1, PART2) = \{{T|T_{1}^A|T_{1}^B, T|T_{1}^A|T_{2}^B, ..., T|T_{2}^A|T_{1}^B, ..., T|T_{N}^A|T_{M}^B}\} $$
,gdzie napis $A|B|C$ oznacza drzewo o wierzcho³ku $A$ oraz poddrzewach $B$ i $C$, bêd¹cych jego dzieæmi. \\
    \begin{figure}[!ht]
        \centering
        \hspace*{-0.25cm}\includegraphics[scale=0.6]{img/phase1}
        \caption{Przyk³ad dzia³ania metody CrossTrees}
        \label{ref:phase1}
    \end{figure}

W skrócie, wyliczamy statystyki danych i na ich podstawie przewidujemy mo¿liwe wêz³y potomne, konstruuj¹c drzewo kandyduj¹ce, a nastêpnie kompresujemy dane kodowaniem wêz³a i rekurencyjnie wyznaczamy kolejne drzewa kandyduj¹ce. Nastêpnie ³¹czymy wyniki we wszystkie mo¿liwe kombinacje, ale zachowuj¹c hierarchiê i do³¹czamy do mo¿liwych rozwi¹zañ. Dodatkowo, wiemy jak dobrze ka¿de skonstruowane drzewo zachowuje siê dla danych wejœciowych. Finalnie drzewo o najlepszym wyniku (wspó³czynnik kompresji oraz poprawka za wysokoœæ drzewa) jest optymalne i automatycznie jest wybierane jako drzewo optymalne dla póŸniejszych faz algorytmu.

\subsection{Faza 2 - kompresja}
W tej fazie pe³na paczka danych jest kompresowana przez drzewo wybrane jako optymalne, ale
co wa¿niejsze uaktualniane s¹ statystyki krawêdzi drzewa binarnego. Opiszê jak wygl¹daj¹ te
statystyki i jak s¹ uaktualniane. Wa¿ne jest równie¿, ¿e drzewo wybrane jako optymalne pamiêta ostatni¹ kopiê statystyk, która jest tworzona w momencie ustawienia nowego drzewa jako optymalne.
    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.75]{img/bin_tree}
        \caption{Przyk³ad numerowania krawêdzi w a) drzewie binarnym b) drzewie kompresji}
        \label{ref:bintree}
    \end{figure}
\noindent
Krawêdzie w drzewie kompresji odpowiadaj¹ parom kodowañ na pewnym miejscu w odpowiadaj¹cym mu pe³nym drzewie binarnym, co pokazuje rysunek \ref{ref:bintree}. Z za³o¿enia, chcemy analizowaæ pary kodowañ, poniewa¿ ka¿dy wczeœniejszy etap kompresji wp³ywa na nastêpny i niejako przygotowuje dla niego dane.
Czêsto okazuje siê, ¿e \emph{AFL} dzia³a dla jakiœ danych bardzo s³abo, ale poprzedzone
kodowaniem \emph{DELTA} lub \emph{PATCH} osi¹ga bardzo dobre wyniki, zaœ poprzedzone kodowaniem \emph{DICT} ma
wynik jeszcze s³abszy. W takiej sytuacji oczekuje siê, ¿e dwie wczeœniejsze konfiguracje bêd¹ mia³y lepsz¹, wiêksz¹ co do wartoœci statystykê, na danym miejscu w drzewie binarnym, ni¿ opcja z kodowaniem \emph{DICT}. 

Ka¿dej parze nastêpuj¹cych po sobie kodowañ da siê przypisaæ krawêdŸ w pe³nym drzewie binarnym o tej samej, lub
wiêkszej wysokoœci. Wynika to z tego, ¿e ka¿de kodowanie mo¿e mieæ co najwy¿ej dwójkê nastêpców (dzieci).
Ponadto jeœli krawêdŸ ma indeks $i$, to ³atwo policzyæ indeksy krawêdzi odchodz¹cych od niej jako $2 \cdot (i+1)$ oraz $2 \cdot (i+1)+1$. Program konstruuje tablicê statystyk (patrz rys. \ref{ref:stats}), w której pod indeksem $\lambda$ bêd¹ przechowywane statystyki
par kompresji na miejscu krawêdzi $\lambda$ w drzewie binarnym.

    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=1]{img/stats}
        \caption{Tablica statystyk krawêdzi}
        \label{ref:stats}
    \end{figure}

\begin{definition}[Wspó³czynnik krawêdzi drzewa kompresji]
Wspó³czynnikiem krawêdzi $e$ stworzonej z pary kodowañ $(A,B)$ w drzewie kompresji ozn. $C_{e} = \frac{C(A) + C(B)}{2}$, nazywamy œredni¹ arytmetyczn¹ wspó³czynników kompresji osi¹gniêtych przez poddrzewo definiowane przez wêze³ $A$ i poddrzewo definiowane przez $B$.
\end{definition}

Dla danej pary kodowañ na wybranym miejscu w drzewie, statystyka jest liczona jako œrednia arytmetyczna, ze
starej wartoœci statystyki (inicjowana wartoœci¹ 1.0) oraz uzyskanego wspó³czynnika krawêdzi drzewa kompresji:
$$ \alpha' = \frac{\alpha + C_{e}}{2} $$
Dla przyk³adu, jeœli krawêdŸ $1$ z par¹ kompresji $(A,B)$ uzyska³a $C_{e} = 2$ a potem $3$, to statystyka dla tej pary na tej krawêdzi bêdzie wynosi³a $\alpha' = \frac{\frac{1+2}{2}+3}{2} = 2,25$. Taka statystyka sprawia, ¿e nigdy nie bêdzie wiêksza ni¿ najlepszy wspó³czynnik kompresji uzyskany przez t¹ parê oraz, ¿e statystyka ta d¹¿y do tego wspó³czynnika (w granicy), jeœli jest sta³y. 
\begin{proof}
Za³ó¿my, ¿e ${\alpha_{1},\alpha_{2},\alpha_{3},...,\alpha_{n}}$ s¹ kolejnymi wspó³czynnikami krawêdzi drzewa, wtedy statystyka $\alpha'$ w granicy bêdzie wynosi³a:
$$ 
\lim_{n \to \infty} \cfrac{\cfrac{\cfrac{\cfrac{1+\alpha_{1}}{2} + \alpha_{2}}{...} + ...}{2} + \alpha_{n}}{2} 
= \frac{1}{2^n}+\frac{\alpha_{1}}{2^n}+\frac{\alpha_{2}}{2^{n-1}}+...+\frac{\alpha_{n-1}}{2^2}+\frac{\alpha_n}{2^1}
= {*}
$$
Bior¹c $\alpha = const$, z granicy sumy ci¹gu geometrycznego wynika, ¿e suma ta zbiega do $\alpha^{-}$.
$$ {*} = \lim_{n \to \infty} \frac{1}{2^n} + \alpha \cdot \displaystyle\sum_{i=1}^{n} \frac{1}{2^i} = \alpha^{-}$$
\end{proof}
Statystyki krawêdzi uaktualniane s¹ w ten sposób podczas trwania ka¿dej kompresji i w momencie jej ukoñczenia powinny byæ aktualne.

\subsection{Faza 3 - poprawa}
Po dokonaniu kompresji ca³ej paczce danych (> 1M elementów), jesteœmy w stanie du¿o lepiej stwierdziæ, jak dobrze dane drzewo kompresji siê sprawuje. Jeœli jakoœæ ta wzros³a lub pozosta³a bez zmian, znaczy to ¿e nic nie trzeba zmieniaæ i wybrane drzewo kompresji jest optymalne. W przeciwnym przypadku nale¿y drzewo poprawiæ, stosuj¹c now¹ wiedzê, uzyskan¹ w formie statystyk krawêdzi z nowych danych.
Aby to osi¹gn¹æ algorytm sprawdza statystyki krawêdzi i wybiera krawêdŸ o najmniejszym indeksie dla której statystyka siê pogorszy³a (drzewo wybrane jako optymalne trzyma kopiê statystyk oraz wspó³czynnika kompresji z momentu wybrania go na optymalne). Mo¿na te¿ w tym momencie wybieraæ krawêdŸ dla której statystyka pogorszy³a siê
najbardziej np. procentowo. Wybran¹ krawêdŸ kasujemy (usuwamy j¹ z drzewa razem z poddrzewem). Na miejscu usuniêtej krawêdzi, zach³annie, wstawiamy parê kompresji o najwiêkszym wspó³czynniku $\alpha$ dla tej krawêdzi. Podobnie
wstawiamy jej dzieci, a¿ do limitu wysokoœci drzewa. Proces ten dok³adniej opisuj¹ algorytmy \ref{alg:faza3_correct} i \ref{alg:faza3_replace}, z prostym przyk³adem w formie rysunku \ref{ref:mutate}. 

    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.75]{img/mutate}
        \vspace*{-3mm}
        \caption{Przyk³ad mutacji drzewa dla kompresji 3 kolejnych paczek danych}
        \label{ref:mutate}
    \end{figure}
\noindent
Wymieniaj¹c krawêdŸ, algorytm w zasadzie wymienia poddrzewo w grafie, zaczynaj¹c od pocz¹tku lub koñca krawêdzi (oszczêdzaj¹c pocz¹tek). Na rysunku \ref{ref:mutate} widzimy oba przypadki. Na przyk³ad, w pierwszej \emph{mutacji} tylko
jedna odnoga \emph{DICT} zosta³a zmieniona, podczas gdy w przejœciu drugim wymianie podlega ca³a krawêdŸ \emph{AFL-NONE}. \\

\begin{algorithm}[H]
 \label{alg:faza3_replace}
 \scriptsize
 \caption{Faza 3 - poprawianie drzewa (Replace)}
 \KwIn{NODE -- wymieniany wêze³ drzewa, STATS -- statystyki krawêdzi\;
 $EDGE_{NO}$ -- numer wymienionej krawêdzi, $MAX_{H}$ -- maksymalna wysokoœæ drzewa\;
 }
 \SetKwFunction{algo}{Replace}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
	\nl \lIf{$EDGE_{NO} > 2^{MAX_{H}}-3$}{\Return}
	\nl $K \gets$ kodowanie wêz³a $NODE$
	\nl $RES_{CNT} \gets$ pobierz iloœæ wyników zwracanych przez $K$\;
	\For{$i=0$ to $RES_{CNT}$}{
		\nl $BEST, BEST_{VAL} \gets$ pobierz ze $STATS$ parê zaczynaj¹c¹ siê na $K$ o najwiêkszej statystyce na pozycji $EDGE_{NO}+i$ w drzewie binarnym oraz jej wartoœæ\;
		\If{$BEST_{VAL} > 1.0$}{
			\nl $CHLD \gets$ wêze³ reprezentuj¹cy kodowanie BEST.TO\;
			\nl dodaj $CHLD$ jako dziecko $NODE$\;
			\nl wywo³aj $Replace(CHLD, STATS, 2*(EDGE_{NO}+i)+2$\;
		}
		\Else{
			\nl dodaj do $NODE$ dziecko z kodowaniem \emph{NONE}\;
		}
	}
	\Return
 }
\end{algorithm}
\normalsize
\newpage

\begin{algorithm}[H]
 \label{alg:faza3_correct}
 \scriptsize
 \caption{Faza 3 - poprawianie drzewa (TryCorrectTree)}
 \KwIn{OPT -- drzewo wybrane jako optymalne, $STAT_{new}$ -- aktualne statystyki\;}
 \SetKwFunction{algo}{TryCorrectTree}
 \SetKwProg{myalg}{Funkcja}{}{}
 \tcc{X.TO i X.FROM, X.NO to wêze³ koñcowy, pocz¹tkowy oraz numer krawêdzi X}
 \myalg{\algo{}}{
	\nl $CR_{new} \gets$ pobierz aktualny wspó³czynnik kompresji drzewa $OPT$\;
	\nl $CR_{old} \gets$ pobierz historyczny wspó³czynnik kompresji $OPT$\;
	\If{$CR_{new} \geq CR_{old}$}{
		\nl \Return{false}\;
	}
	\nl $STAT_{OLD} \gets$ pobierz historyczne statystyki z $OPT$\;
	\nl $EDGES \gets$ pobierz krawêdzie drzewa $OPT$\;
	\ForEach{$E$ from $EDGES$}{
		\nl $VAL_{OLD} \gets$ wartoœæ statystyki krawêdzi $E$ z $STAT_{OLD}$\;
		\nl $BEST \gets$ pobierz wartoœæ najlepszej statystyki na miejscu $E$ z $STAT_{NEW}$\;
		\If{$BEST > VAL_{OLD}$}{
			\nl $NEW, VAL_{NEW} \gets$ pobierz ze statystyk $STAT_{NEW}$ parê na miejscu $E$ zaczynaj¹c¹ siê t¹ sam¹ kompresj¹, o najwiêkszej statystyce oraz jej wartoœæ\;
			\If{$VAL_{NEW} > VAL_{OLD}$}{
				\nl wymieñ E.TO na NEW.TO, kasuj¹c ca³e poddrzewo od E.TO\;
				\nl wykonaj $Replace(NEW.TO, STAT_{NEW}, 2*(E.NO + 1))$\;
			}
			\Else{
				\nl $NEW \gets$ pobierz ze statystyk $STAT_{NEW}$ parê na miejscu $E$ o najwiêkszej statystyce\;
				\nl wymieñ E.FROM na NEW.FROM, kasuj¹c ca³e poddrzewo od E.FROM\;
				\eIf{E.NO jest parzyste}{
					\nl $NO \gets E.NO-1$\;
				}{
					\nl $NO \gets E.NO$\;
				}
				\nl wykonaj $Replace(NEW.FROM, STAT_{NEW}, NO)$\;
			}
			\nl wyjdŸ z pêtli\;
		}
	}
	\nl \Return{true}\;
 }
\end{algorithm}
\normalsize

Podsumowuj¹c, program mutuje drzewo kompresji dopóki wspó³czynnik kompresji nie zacznie siê poprawiaæ. Pojedyncza
mutacja mo¿e zmieniæ jeden wêze³, ale mo¿e tak¿e wymieniæ ca³e drzewo, co dzieje siê bardzo czêsto. Wymiany s¹
dokonywane tylko wtedy, gdy wed³ug statystyk nast¹pi poprawa kompresji. W ten sposób nawet jeœli charakterystyka
danych siê zmieni, algorytm powinien dostosowaæ drzewo do nowych warunków.

\subsection{Algorytm optymalizatora kompresji}

\begin{algorithm}[H]
 \scriptsize
 \caption{Optymalizacja kompresji}
 \KwIn{DATA -- dane do skompresowania, DT -- typ danych\;}
 \KwOut{RES -- skompresowane dane}
 \SetKwFunction{algo}{CompressData}
 \SetKwProg{myalg}{Funkcja}{}{}
 \myalg{\algo{}}{
	\If(\tcc*[f]{heurystyka}){warto przejrzeæ ponownie interesuj¹ce drzewa}{
		\nl $SAMPLE \gets$ pobierz kawa³ek danych z $DATA$\;
		\nl $TREES \gets$ wywo³aj $FullStatisticsUpdate(SAMPLE, NONE, DT, 0)$\;
		\nl $BEST \gets$ pobierz drzewo z najlepszym wynikiem\;
		\nl ustaw $BEST$ jako optymalne drzewo
	}
	\nl $RES \gets$ wykonaj kompresjê optymalnym drzewem\;
	\nl $UPDATE \gets$ wywo³aj $TryCorrectTree$ na optymalnym drzewie\;
	\If{$UPDATE$ is $true$}{
		\nl ustaw ponownie optymalne drzewo\;
	}
	\nl \Return{RES}
 }
 \label{alg:compress}
\end{algorithm}
\normalsize

Przebieg dzia³ania kompresji z u¿yciem optymalizatora pokazuje algorytm \ref{alg:compress}.
Co pewien czas próbujemy przejrzeæ wszystkie interesuj¹ce drzewa uaktualniaj¹c statystyki i wybieraj¹c
inne optymalne drzewo. Staramy siê je poprawiaæ i jeœli siê uda³o, to ponownie zapisujemy je jako
optymalne, tworz¹c now¹ kopiê statystyk (historycznych).

\subsection{Usprawnienie}
Iloœæ drzew do sprawdzenia w fazie 1 mo¿e lawinowo rosn¹c wzglêdem iloœci ró¿nych kompresji zaimplementowanych w systemie, w zale¿noœci od zastosowanych regu³. Warto zaimplementowaæ zbiory regu³ produkuj¹cych mniej i wiêcej
takich drzew, aby lepiej przeszukiwaæ przestrzeñ rozwi¹zañ\footnote{patrz tabela \ref{tab:trees}}. 
Jednak przeszukiwanie du¿ej iloœci drzew jest pomimo
zastosowania GPU, zbyt czasoch³onne jak na planowane zastosowania. 
Mo¿liwym rozwi¹zaniem (jeszcze nie zaimplementowanym ale planowanym), jest niezale¿ne i równoleg³e wykonywanie fazy 1 dla ró¿nych zbiorów regu³, równolegle do faz 2 i 3, w sposób pokazany na rysunku \ref{ref:threads}. Na tym rysunku numery 1,2,3 stanowi¹ numer fazy, a
A,B,C zbiory regu³ w których A s¹ najbardziej restrykcyjne i produkuj¹ ma³o drzew, zaœ C bardzo du¿o.

    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.5]{img/threads}
        \caption{Zrównoleglenie fazy 1 w optymalizatorze}
        \label{ref:threads}
    \end{figure}
\noindent
W ten sposób oba w¹tki mog¹ pracowaæ nawet na 2 oddzielnych urz¹dzeniach, wielokrotnie zwiêkszaj¹c nie tylko
wydajnoœæ ale i wspó³czynnik kompresji z racji przeszukania wiêkszej iloœci opcji. Algorytm powinien
tak¿e lepiej dostosowywaæ siê do zmian danych. Taka równoleg³oœæ jest mo¿liwa, poniewa¿ tablica statystyk krawêdzi
zosta³a zaimplementowana w taki sposób, aby umo¿liwiæ równoleg³y dostêp bez obaw o niespójnoœæ danych.

\chapter{System kompresji}

Projekt sk³ada siê z 4 bibliotek, których zale¿noœci wewnêtrzne pokazane s¹ na rysunku \ref{ref:libs}. Dwie z nich, \emph{CORE} oraz \emph{ENC}, wykorzystuj¹ technologiê CUDA i musz¹ byæ kompilowane za pomoc¹ \emph{nvcc}. Wszystkie korzystaj¹ z biblioteki \emph{Boost} oraz bibliotek do testowania i benchmarków (\emph{GTEST}, \emph{Google Benchmark}).
Poni¿ej znajduje siê tak¿e opis poszczególnych czêœci projektu.

\section{Biblioteki}
	\begin{figure}[!ht]
		\centering
		\hspace*{-0.5cm}\includegraphics[scale=0.55]{img/Libs}
		\caption{Biblioteki}
		\label{ref:libs}
	\end{figure}

\subsection{TS - TIME SERIES}
Biblioteka definiuj¹ca strukturê szeregu czasowego, udostêpniaj¹ca metody do odczytu i zapisu szeregów z plików binarnych oraz tekstowych o kolumnach rozdzielonych separatorem, na przyk³ad \emph{CSV}. Ponadto umo¿liwia definicjê szeregu czasowego poprzez plik nag³ówkowy o strukturze wierszy: ([nazwa kolumny],[typ kolumny],[precyzja]), w której ka¿dy wiersz definiuje osobn¹ kolumnê. Przyk³adowa treœæ pliku nag³ówkowego zosta³a umieszczona na listingu~\ref{lst:tsheader}.
\begin{lstlisting}[caption=Przyk³adowy plik opisu szeregu czasowego,label={lst:tsheader}]
		timestamp,time,0
		CORE VOLTAGE,float,6
		CPU TEMP,float,6
		GPU TEMP,float,6
\end{lstlisting}

\subsection{CORE}
Tutaj zaimplementowane s¹ wszystkie podstawowe elementy takie jak logowanie, konfiguracja, inteligentny wskaŸnik na pamiêæ CUDA (zaimplementowany w oparciu o \emph{Shared Pointer} z biblioteki \emph{Boost}), operacje na wektorach danych po stronie GPU takie jak histogramy, wyliczanie statystyk itp., a tak¿e bazowe klasy testów i benchmarków wraz z generatorem danych. Zawiera tak¿e ,,scheduler'' równoleg³ych zadañ kompresji.

\subsection{ENC - ENCODINGS}
Encodings to biblioteka mieszcz¹ce wszystkie zaimplementowane w ramach tego projektu algorytmy kodowania i transformacji zaimplementowane na CUDA, potrafi¹ce kodowaæ i dekodowaæ dane wszystkich typów obs³ugiwanych przez ten system (\emph{char, short, int, unsigned int, long, float, double}).

\subsection{OPT - OPTIMIZER}
W³aœciwa biblioteka dla tego projektu mieszcz¹ca optymalizator kompresji, a tak¿e definicjê i implementacjê drzewa kompresji, jak równie¿ drzewa optymalnego (drzewa aktualnie u¿ywanego przez kompresor, które umo¿liwia pewne mutowanie tego drzewa, co zostanie opisane w nastêpnym rozdziale).

\section{Program}
Przyk³adowy program wynikowy, który u¿ywaj¹c optymalizatora kompresji, wielow¹tkowo i równolegle kompresuje wiele kolumn szeregu czasowego, podanego jako plik wejœciowy. Plik wejœciowy jest zaczytywany paczkami i w tym samym czasie czêœci ju¿ skompresowane mog¹ byæ zapisywane do podanego pliku wyjœciowego. Dok³adny opis tego algorytmu znajduje siê poni¿ej (Patrz \emph{Równoleg³y kompresor}). Argumenty programu:
\begin{itemize}
\item \emph{--compress} lub \emph{-c}: opcja kompresji (nast¹pi kompresja pliku wejœciowego)
\item \emph{--decompress} lub \emph{-d}: opcja dekompresji (nast¹pi dekompresja pliku wejœciowego)
\item \emph{--header} lub \emph{-h} \emph{[<œcie¿ka>]}: podanie œcie¿ki do pliku zawieraj¹cego opis szeregu jak wy¿ej \ref{lst:tsheader}.
\item \emph{--input} lub \emph{-i} \emph{[<œcie¿ka>]}: podanie œcie¿ki do pliku wejœciowego
\item \emph{--output} lub \emph{-o} \emph{[<œcie¿ka>]}: podanie œcie¿ki do pliku wyjœciowego
\item \emph{--generate} lub \emph{-g}: -- wygeneruj przyk³adowe pliki danych
\item \emph{--padding} lub \emph{-p} \emph{[<ró¿nica>]}: w przypadku gdy wiersze szeregu w pliku binarnym s¹ wyrównane do jakieœ wielkoœci, podajemy w ten sposób ró¿nicê wzglêdem ich rzeczywistej wielkoœci, np. jeœli dane zajmuj¹ 12 bajtów, a s¹ wyrównane do 16, powinniœmy uruchomiæ program z opcj¹ \emph{-p 4}.
\end{itemize}

\section{Równoleg³a kompresja kolumn danych}
Szeregi czasowe zwykle sk³adaj¹ siê z wielu kolumn, które maj¹ ró¿ne charakterystyki, wiêc mog¹ byæ
kompresowane niezale¿nie i równolegle. Oprócz mo¿liwoœci wykorzystania do tego celu wielu urz¹dzeñ GPU
jednoczeœnie, mo¿na wykorzystaæ \emph{CUDA streams} aby wykonywaæ jednoczeœnie wiele \emph{kerneli} oraz kopiowañ danych na tej samej karcie. 
W nowych wersjach CUDA ($>7.0$) ka¿dy w¹tek CPU mo¿e otrzymaæ osobny i niezale¿ny \emph{stream} ,,domyœlny'' 0, nie
powoduj¹cy niejawnej synchronizacji. Aby tak siê sta³o, nale¿y skompilowaæ program z flag¹
--default-stream per-thread lub zdefiniowaæ CUDA\_API\_PER\_THREAD\_DEFAULT\_STREAM na pocz¹tku programu.
Dziêki tej opcji, wykonanie wielu \emph{kerneli} oraz kopiowañ pamiêci bêdzie mog³o byæ zrównoleglone, pomimo
wywo³ania na domyœlnym \emph{stream} 0. Zdecydowanie upraszcza to implementacjê rozwi¹zania od strony zarz¹dzania
wykonaniem funkcji na \emph{stream'ach CUDA}.

    \begin{figure}[!ht]
        \centering
        \hspace*{-0.25cm}\includegraphics[scale=0.6]{img/parallel}
        \caption{Wykonanie zadañ kompresji przez w¹tki}
        \label{ref:parallel}
    \end{figure}

\subsection{Opis dzia³ania algorytmu}
W programie równoleg³a kompresja opiera siê na puli w¹tków zaimplementowanej jako \emph{Task Scheduler}
w bibliotece \emph{CORE}, w oparciu o bibliotekê \emph{BOOST}. Sama kompresja i dekompresja polega na
uruchamianiu zadañ kompresji lub dekompresji kawa³ków danych z u¿yciem instancji optymalizatora, unikalnego dla danej kolumny. W zale¿noœci od konfiguracji zadania mog¹ wykorzystywaæ jeden lub wiele dostêpnych GPU.

\subsubsection{Kompresja}
Równoleg³a kompresja kolumn jest opisana przez pseudokod w algorytmie \ref{alg:parallel}.

\begin{algorithm}[H]
 \scriptsize
 \caption{Ca³oœæ kompresji optymalizatorem}
 \KwIn{$FILE_{IN}$ -- plik wejœciowy, $FILE_{OUT}$ -- plik wyjœciowy\;}
 \SetKwFunction{algo}{$ParallelCompressor \rightarrow Compress$}
 \SetKwProg{myalg}{Metoda}{}{}
 \myalg{\algo{}}{
 	\nl $ID \gets 1$\;
	\Repeat{koniec pliku $FILE_{IN}$}{
		\nl $TS \gets$ odczytaj paczkê danych z pliku $FILE_{IN}$\;
		\If{niezainizjalizowany}{
			\tcc{inicjalizuje kompresor tworzy optymalizator dla ka¿dej kolumny wejœciowych danych oraz tworzy pulê w¹tków}
			\nl wywo³aj $init()$
		}
		\nl $COL_{N} \gets$ pobierz iloœæ kolumn z $TS$\;
		\For{$i=0$ to $N$}{
			\nl $TASK \gets$ stwórz zadanie kompresji z optymalizatorem dla kolumny $i$ oraz danymi $TS[i]$ (i-ta kolumna szeregu TS) o numerze $ID$\;
			\nl dodaj $TASK$ do schedulera oraz powiêksz $ID$ o 1\;
		}
		\nl zaczekaj na wykonanie wszystkich zadañ\;
	}
 }
 \label{alg:parallel}
\end{algorithm}
\normalsize
\noindent

W tym przypadku wa¿ne jest jak dzia³a samo zadanie kompresji, przy czym kluczowym elementem
jest synchronizacja zapisu do pliku wynikowego, który to przedstawia rysunek \ref{ref:parallel}.
Zadanie to przebiega nastêpuj¹co:
\begin{enumerate}
\item Otrzymane dane kopiowane s¹ do pamiêci globalnej GPU
\item Dane s¹ kompresowane przy u¿yciu podanego optymalizatora
\item Dane s¹ zapisywane z powrotem do pamiêci RAM
\item Nastêpnie przy u¿yciu metod synchronizacji w¹tki zapisuj¹ dane do pliku wyjœciowego.
	\begin{itemize}
	\item w¹tek czeka a¿ wszystkie w¹tki o mniejszych numerach zakoñcz¹ pracê
	\item w¹tek zapisuje dane poprzedzaj¹c je ich rozmiarem
	\end{itemize}
\item Oznacz zadanie jako ukoñczone
\item Jeœli jakikolwiek z powy¿szych pkt. siê nie powiedzie oznacz zadanie jako zakoñczone pora¿k¹
\end{enumerate}

\subsubsection{Dekompresja}
Dekompresja przebiega na tyle prosto, ¿e ograniczê siê do krótkiego opisu bez pseudokodu i obrazków.
\begin{enumerate}
\item Kawa³ek po kawa³ku, zgodnie z zapisanymi rozmiarami czytamy skompresowane dane kolumn.
\item Dla ka¿dego kawa³ka tworzone jest zadanie dekompresuj¹ce (posiadaj¹ce wskaŸnik na wspóln¹ instancjê szeregu czasowego), które:
	\begin{enumerate}
	\item Kopiuje dane do pamiêci globalnej GPU
	\item Dekompresuje je
	\item Dopisuje na koñcu kolumny, któr¹ obs³uguje w szeregu czasowym
	\end{enumerate}
\item Po zdekodowaniu liczby kawa³ków równej liczbie kolumn czekamy a¿ w¹tki zakoñcz¹ pracê i zapisujemy szereg na wyjœciem.
\item Czyœcimy szereg czasowy aby nie zapisywaæ kolejny raz tych samych danych
\item Jeœli to nie koniec danych do dekompresji, wracamy do punktu pierwszego
\end{enumerate}

\subsection{Random Access}
Kompresja danych za pomoc¹ zaimplementowanych kodowañ, z u¿yciem drzew i równoleg³ej kompresji kolumn,
umo¿liwia dostêp do poszczególnych rekordów skompresowanych danych, bez rozpakowywania ca³oœci. Mo¿e siê
to jednak wi¹zaæ z rozpakowaniem czêœci lub ca³ej paczki danych, zatem umo¿liwia losowy dostêp do danych
w ograniczonym zakresie. 

    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=1.25]{img/access}
        \caption{Schemat dostêpu do wartoœci o indeksie $i$ w paczce}
        \label{ref:access}
    \end{figure}

Poniewa¿ ka¿da paczka danych mo¿e byæ dekompresowana oddzielnie, znajomoœæ przedzia³ów
indeksów danych wystêpuj¹cych w ka¿dej paczce umo¿liwi³aby losowy dostêp do danych, dekompresuj¹c pojedyncz¹ paczkê.
Takie indeksy wraz z adresami paczek mog³yby byæ przechowywane na przyk³ad w postaci B+drzew.
Aby nie dekompresowaæ ca³ej paczki, niezbêdna by³aby, implementacja alternatywnych algorytmów dekodowania, które
czyta³yby jedn¹ lub wiele wartoœci skompresowanych danych, w celu odtworzenia wartoœci spod indeksu $i$ w paczce, np.
kodowanie \emph{DELTA} musia³oby czytaæ wartoœci z indeksami ${0,1,...,i}$, zaœ \emph{AFL} tylko $i$. 
Z drugiej strony, drzewiasta struktura kodowañ, wymusza koniecznoœæ wyliczania indeksu danej wartoœci
na ka¿dym etapie dekompresji w drzewie, co mog³oby spowodowaæ du¿y spadek wydajnoœci.
Jest to jednak temat na kolejn¹ pracê naukow¹ i nie jest czêœci¹ powy¿szej pracy.

\chapter{Wyniki}
W tym rozdziale opiszê uzyskane wyniki pod wzglêdem wspó³czynników kompresji dla ró¿nych danych, jak równie¿ wygenerowane schematy kompresji. PóŸniej porównam wydajnoœæ ca³oœci jak i poszczególnych elementów systemu, z istniej¹cymi rozwi¹zaniami.

\section{Platforma testowa}
Wszystkie testy wykonano na komputerze stacjonarnym pod systemem \emph{Ubuntu 14.04.3 LTS},
z zainstalowanymi sterownikami \emph{NVIDIA 352.68} oraz \emph{CUDA 7.5}. Parametry komputera:
\begin{itemize}
\item Procesor: AMD FX(tm)-8350 Eight-Core Processor
\item Karta graficzna: 2 x GeForce GT 640
\item Pamiêæ RAM: 16 GB (1600 Mhz)
\item Dysk: SSD 40 GB
\item P³yta g³ówna: 970A-UD3 - Gigabyte
\end{itemize}

\section{Dane}
\subsection{Rzeczywiste}
Dane rzeczywiste pochodz¹ z dwóch Ÿróde³. Pierwsze pozyskano z pomiarów dzia³aj¹cego komputera MAC,
wykonane za pomoc¹ prostego programu OsxSystemDataLogger\footnote{https://github.com/dzitkowskik/osx-system-data-logger}, które zawieraj¹ pola takie jak czas, napiêcie na procesorze oraz temperaturê procesora i GPU. Dane te dalej bêdê nazywa³ \emph{INFO}. Drugie pochodz¹ z \emph{New York Stock Exchange} i s¹ danymi historycznymi wszystkich zdarzeñ w czasie rzeczywistym w formie \emph{NYSE OpenBook}\footnote{http://www.nyxdata.com/Data-Products/NYSE-OpenBook} zawieraj¹cymi ponad 20 kolumn, a w tym czas, wolumen, cenê, stronê, symbol i inne. Dane te dalej bêdê nazywa³ \emph{NYSE}.
\subsection{Wygenerowane}
\subsubsection{Czas}
\label{sec:time}
Liczby ca³kowite o d³ugoœci $64bit$ monotonicznie rosn¹ce od zadanej wartoœci startowej, o losow¹ wielkoœæ z zadanego przedzia³u, z pewnym prawdopodobieñstwem. Dla prawdopodobieñstwa 0 czas siê nie zmienia, natomiast dla prawdopodobieñstwa 1, nie bêdzie dwóch tych samych liczb w wygenerowanym ci¹gu.
\begin{lstlisting}[caption=Time pattern,label={lst:time},basicstyle=\small]
	//                              ------------
	//                        ------
	//          --------------
	//       ---
	// ------                                   min
\end{lstlisting}

\subsubsection{Pattern A}
Liczby dowolnego typu i wielkoœci, z przedzia³u od zadanego minimum($v_{min}$) do maksimum($v_{max}$).
Wartoœæ generowanych punktów zmienia siê co $len$ kroków oraz przed ka¿d¹ zmian¹ generowany jest
pojedynczy punkt o wartoœci $v_{max}$.

\begin{lstlisting}[caption=Pattern A,label={lst:patternA},basicstyle=\small]
	// *       *       *       *      *      * max
	//                  -------
	//          -------         ------
	//  -------                        ------  min
	//  <-len->
\end{lstlisting}

\subsubsection{Pattern B}
Dane B sk³adaj¹ siê z dwóch czêœci po³o¿onych na przemian co $len$ kroków, z których pierwsza
sk³ada siê z naprzemian po³o¿onych wartoœci bliskich $v_{max}$ i $v_{min}$. Druga czêœæ sk³ada
siê z wartoœci malej¹cych od $v_{max}$ do $v_{min}$ co ustalon¹ wartoœæ, a nastêpnie
rosn¹ca z powrotem.
\begin{lstlisting}[caption=Pattern B,label={lst:patternB},basicstyle=\small]
//   pattern 1     |       pattern 2       |     pattern 1
// * * * * * * * *  *                       * * * * * * * * max-rand(0,5)
//  # # # # # # #     *                   *  # # # # # # #  max-rand(0,5)
//                      *               *
//                        *           *
//                          *       *
//  * * * * * * * *           *   *          * * * * * * * min+rand(0,5)
//   # # # # # # #              *             # # # # # #  min+rand(0,5)
//  <------len-----> <---------len---------> <-----len---->
\end{lstlisting}

\section{Ustawienia siatki CUDA (grid)}
\begin{definition}[Kernel Policy]
Polityka kernela definiuje w jaki sposób tworzyæ siatkê w¹tków podzielonych na bloki w CUDA 
dla podanego rozmiaru danych oraz którego \emph{stream} nale¿y u¿yæ.
\end{definition}
 
    \begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.75]{img/policy}
        \vspace*{-3mm}
        \caption{Schemat wywo³ywania kernela}
        \label{ref:policy}
    \end{figure} 
 
Pomimo zaimplementowania wygodnego do testów systemu odpalania kerneli za pomoc¹ \emph{Kernel Policy},
nie starczy³o czasu na przetestowanie optymalnych ustawieñ polityki dla ka¿dego algorytmu. Dlatego te¿, podczas
testów wszystkie autorskie kernele, by³y odpalane z u¿yciem domyœlnej polityki tworz¹cej bloki o rozmiarze $1024$ w¹tków, co mo¿e negatywnie rzutowaæ na wydajnoœæ systemu.

\section{Badanie wspó³czynnika kompresji}

Wyniki tego pomiaru otrzymano kompresuj¹c pliki \emph{CSV} z danymi rzeczywistymi
omówionymi wczeœniej za pomoc¹ zaimplementowanego równoleg³ego kompresora oraz
kompresorów \emph{7z, zip, bz2} dostêpnych w systemie \emph{Linux Ubuntu}. Dane \emph{GEN1}
powsta³y z wygenerowanych kolumn Czasu oraz \emph{Pattern A i B}, opisanych wy¿ej, dla danych ca³kowitych
oraz zmiennoprzecinkowych pojedynczej precyzji, natomiast \emph{BROW}, to dzienne wartoœci udzia³u w rynku przegl¹darek\footnote{http://www.economicswebinstitute.org/data/browsermarket01.xls}.
\begin{table}[!ht]
\centering
\caption{Wspó³czynnik kompresji dla plików CSV z danymi w porównaniu ze standardowymi kompresorami}
\label{tab:ratios}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\multirow{2}{*}{} & \multicolumn{2}{c|}{optymalizator} &	\multicolumn{2}{c|}{bz2} & \multicolumn{2}{c|}{zip} & \multicolumn{2}{c|}{7z} \\ 

& ratio & czas & ratio & czas & ratio & czas & ratio & czas \\ 
\hline
INFO				&27.26 &2.84s			&20.29 &3.88s  			&22.60 &0.66s		&30.31 &5.64s \\
NYSE				&8.99  &37.40s			&6.60  &1m 19.62s		&5.64  &32.45s		&7.42  &6m 23.58s  \\
GEN1				&17.43 &4.86s			&8.33  &5.34s			&7.95  &2.92s		&10.91 &36.05s \\
BROW				&5.12  &1.43s			&4.51  &0.02s			&4.15  &0.02s		&5.40  &0.05s \\
\hline
\end{tabular}
\end{table}

Z pomiarów (patrz tabela \ref{tab:ratios}) wynika, ¿e dla wiêkszoœci danych optymalizator zachowuje siê lepiej ni¿
dostêpne w systemie kompresje, które poza tym s¹ o wiele wolniejsze dla du¿ych danych, 
co widaæ dla danych \emph{NYSE} o rozmiarze \emph{720MB}. 
W dwóch przypadkach jednak \emph{7z} okaza³ siê nieco lepszy, natomiast obie kompresje maj¹ porównywalne wyniki.
W pomiarach kompresje korzystaj¹ ze wszystkich 8 rdzeni, a kompresor \emph{gzip} okaza³ siê najszybszy, daj¹c
porównywalny wynik do optymalizatora. Algorytm korzystaj¹cy z \emph{CUDA} traci niestety du¿¹ czêœæ czasu na
inicjalizacjê oraz transfer danych przez szynê \emph{PCI-E}. Wyniki te uzyskano dla przyk³adowego programu,
u¿ywaj¹cego równoleg³ego kompresora opisanego wczeœniej. Czas liczony jest ³¹cznie z czytaniem danych
z dysku, co zajmuje wiêkszoœæ czasu.

\section{Wygenerowane schematy}
Kolejny test polega³ na przeœledzeniu dzia³ania optymalizatora dla du¿ej iloœci
danych w wariancie \emph{Pattern B}. Patrz¹c na dane mo¿emy domyœlaæ siê jak powinna wygl¹daæ
dobra kompresja dla obu czêœci. W pierwszym przypadku, algorytm powinien podzieliæ dane
na górne i dolne operacj¹ \emph{PATCH}, nastêpnie transformowaæ obie czêœci operacjami \emph{SCALE} i \emph{DELTA}, a na koniec skompresowaæ kodowaniem \emph{AFL} lub \emph{GFC}. W drugim spodziewamy
siê kombinacji \emph{DELTA} z \emph{RLE} lub \emph{CONST}. Przebieg dzia³ania algorytmu dla tych danych,
pokazuje tabela \ref{tab:patternBworkflow}.

\begin{table}[]
\centering
\caption{Dzia³anie optymalizatora dla kolejnych paczek danych Pattern B}
\label{tab:patternBworkflow}
\begin{tabular}{|l|l|l|l|l|}
\hline
Lp. &schemat kompresji								&ratio &pattern &zmiana \\
\hline
1	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
2	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
3	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
4	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
5	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
6	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
7	&scale,patch,afl,none,scale,afl,none 			&2.32829	&2&tak\\
8	&scale,dict,afl,none,scale,afl,none				&2.32829	&2&tak\\
9	&scale,patch,afl,none,scale,afl,none 			&2.32829	&2&tak\\
10	&delta,rle,delta,none,delta,none 				&250.000	&2&tak\\
11	&delta,scale,rle,none,none	 					&263.158	&2&nie\\
12	&delta,scale,rle,none,none	 					&263.158	&2&nie\\
13	&delta,scale,rle,none,none	 					&1.00000	&1&tak\\
14	&delta,rle,delta,afl,none,delta,afl,none 		&1.00000	&1&tak\\
15	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
16	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
17	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
18	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
19	&scale,patch,afl,none,scale,afl,none 			&2.32829	&2&tak\\
20	&delta,rle,delta,none,delta,none 				&250.000	&2&tak\\
21	&delta,rle,constData,none,delta,none 			&243.902	&2&tak\\
22	&delta,rle,patch,afl,none,afl,none,delta,none 	&169.492	&2&tak\\
23	&delta,rle,delta,afl,none,delta,none 			&227.273	&2&nie\\
24	&delta,rle,delta,afl,none,delta,none 			&227.273	&2&tak\\
25	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
26	&scale,patch,afl,none,scale,afl,none 			&7.71010	&1&nie\\
\hline
\end{tabular}
\end{table}

Ca³kowity poziom kompresji wyniós³ lekko ponad $4$, co bior¹c pod uwagê pojedyncze statyczne scenariusze, jest dobrym wynikiem. Dla porównania skompresowanie ca³ych danych za pomoc¹ sugerowanych na pocz¹tku scenariuszy wynosz¹ odpowiednio $2.4$ oraz $1.3$ co przedstawia listing \ref{lst:patternBresults}.
\begin{lstlisting}[caption=Pattern B - wyniki przyk³adowych schematów,label={lst:patternBresults},basicstyle=\small]
patch,delta,scale,afl,none,delta,scale,afl,none:  
compression ratio = 2.43919

delta,rle,afl,none,afl,none: 
compression ratio = 1.3374
\end{lstlisting}

Tabela \ref{tab:patternBworkflow} pokazuje jak algorytm dostosowuje siê do zmieniaj¹cej siê charakterystyki danych oraz
jak mutuje schematy aby mieæ szansê otrzymania lepszego rozwi¹zania, np. zmiana pomiêdzy iteracj¹
$10$ a $11$. Warto zauwa¿yæ, ¿e na koñcu po powrocie do dawnej charakterystyki algorytm stosuje
ponownie ten sam schemat co na pocz¹tku, który by³ optymalny. \\
Dla danych \emph{Pattern A} algorytm stosuje jedn¹ strategiê i jej nie zmienia, poniewa¿ charakterystyka szeregu jest sta³a. Strategia ta osi¹ga wspó³czynnik kompresji $46.8384$ i wygl¹da nastêpuj¹co: \\
$rle,patch,rle,none,none,rle,none,none,patch,delta,afl,none,rle,none,none$ \\
Analogiczne zachowanie otrzymujemy dla wygenerowanych punktów czasu\footnote{patrz dane czasu - listing \ref{lst:time}}, gdzie algorytm u¿ywa kodowania \emph{RLE} oraz \emph{AFL}, stosuj¹c równie¿ skalowanie oraz deltê. W ten sposób dla czasu osi¹gany wspó³czynnik kompresji jest rzêdu $100$.

\subsection{Pojedyncze schematy}
Wykonano porównanie wspó³czynnika kompresji, osi¹ganego dla danych o zmiennej (okresowo) charakterystyce, przez optymalizator, w stosunku do optymalnego drzewa kompresji dla pierwszej
paczki danych. Pomiary przeprowadzono dla optymalizatora
wykonuj¹cego fazê 1 algorytmu raz na dziesiêæ paczek danych. 

\begin{table}[ht!]
\centering
\small
\caption{Porównanie optymalizatora do pojedynczych schematów}
\label{tab:opt_vs_single}
\begin{tabular}{|l|l|l|l|l|}
\hline
Dane & COpt & CSch & Schemat & Zysk \\
\hline
B              & 1.80 & 0.54 & scale,patch,afl,n,scale,afl,n & 3.33 \\
A+B            & 4.71 & 0.67 & dict,scale,dict,n,n,rle,const,n,delta,afl,n & 7.03 \\
Time+A         & 9.75 & 0.39 & patch,rle,const,n,delta,afl,n,const,n & 25.00 \\ 
A+B+MaxPrec    & 2.00 & 0.40 & rle,patch,const,n,const,n,patch,n,const,n & 5.00 \\
Time+Cons+Rand & 1.37 & 0.60 & rle,scale,afl,n,delta,dict,afl,n,n & 2.28 \\
\hline
\end{tabular}
\end{table}
\normalsize

Wyniki testu przedstawia tabela \ref{tab:opt_vs_single}, w której:
\begin{itemize}
\item Dane - kombinacja paczek danych o ró¿nych charakterystykach co 5 paczek,
\item COpt - wsp. kompresji osi¹gniêty przez optymalizator
\item CSch - wsp. kompresji osi¹gniêty przez optymalne drzewo dla 1 paczki w kompresji ca³oœci danych
\item Zysk - stosunek COpt do CSch, czyli wzrost wspó³czynnika kompresji przy u¿yciu optymalizatora
\end{itemize}

Œredni wzrost wspó³czynnika kompresji przy zastosowaniu optymalizatora zamiast pojedynczego
drzewa kompresji wynosi $8.53$. Rozmiar danych zosta³ zmniejszony œrednio oko³o $4$ krotnie, co œwiadczy o tym, ¿e algorytm dobrze radzi sobie z danymi o zmiennej charakterystyce.

\newpage
\section{B³êdne odczyty}
W wiêkszoœci danych pomiarowych trafiaj¹ siê b³êdne odczyty lub zaburzenia, które nie pasuj¹ do ogólnej charakterystyki
danych. Zbadano wp³yw takich wartoœci, zwanych z angielskiego \emph{outliers}, na jakoœæ kompresji danych (patrz rys. \ref{ref:cr_vs_out}). Badane
dane s¹ wygenerowanymi punktami czasu, z du¿¹ powtarzalnoœci¹ (jak w \emph{Pattern A}), z pewnym procentowym udzia³em
wartoœci niepasuj¹cych w losowych miejscach. 

    \begin{figure}[!ht]
        \centering
        \hspace*{-0.25cm}\includegraphics[scale=0.3]{img/cr_vs_out}
        \vspace*{-3mm}
        \caption{wsp. kompresji vs \% outliers}
        \label{ref:cr_vs_out}
    \end{figure}
W rezultacie przy braku outlier'ów optymalizator u¿ywa³ kodowania \emph{RLE}, natomiast po przekroczeniu paru procent
b³êdnych odczytów, zmieni³ drzewo kompresji na:
$patch,delta,rle,none,none,scale,afl,none$ w celu oddzielenia wartoœci niepasuj¹cych od w³aœciwego szeregu i skompresowania ich za pomoc¹ \emph{AFL}. Wraz ze wzrostem liczby outlier'ów poziom kompresji spada liniowo, lekko
siê sp³aszczaj¹c by ostatecznie ustaliæ siê na poziomie $C \approx 5$, u¿ywaj¹c g³ównie \emph{AFL} i \emph{CONST}.


\section{Wydajnoœæ}
Wydajnoœæ kaskadowej kompresji jest limitowana przede wszystkim przez szybkoœæ najwolniejszej kompresji u¿ytej w planie.
Niestety, nie wszystkie u¿yte kompresje zosta³y zaimplementowane optymalnie, co ma znacz¹cy wp³yw na osi¹gi ca³oœci. 
Bêdzie to jednak tematem innej pracy i zgodnie z wieloma publikacjami, mo¿liwa jest wydajniejsza implementacja
u¿ytych algorytmów \cite{CURRY,KACZMAR2,FANG,ONEIL}. Ponadto, wydajnoœæ ta w du¿ej mierze zale¿y od u¿ytej karty, która w tym przypadku jest relatywnie niska w porównaniu do drogich kart z wy¿szej pó³ki. Dla porównania wydajnoœæ analogicznej implementacji algorytmu \emph{GFC} uzyskana przez autorów wynosi³a oko³o $10GB/s$, natomiast na mojej karcie tylko nieca³e $2GB/s$. Przepustowoœæ poszczególnych kodowañ i dekodowañ umieszczona jest na rysunku \ref{ref:enc_perf}.
    \begin{figure}[!ht]
        \centering
        \hspace*{-0.25cm}\includegraphics[scale=0.35]{img/enc_perf}
        \caption{Wydajnoœæ kodowañ}
        \label{ref:enc_perf}
    \end{figure}
Mo¿na przypuszczaæ, ¿e znacz¹cy wp³yw na spadek wydajnoœci kompresji ma u¿ycie w drzewie kodowañ bazuj¹cych na s³owniku lub precyzji i te metody powinny byæ optymalizowane w pierwszej kolejnoœci. Z drugiej strony, u¿ycie 
transformacji nie powinno wp³ywaæ na wydajnoœæ drzewa, poniewa¿ s¹ one znacznie wydajniejsze od reszty kodowañ.
Wydajnoœæ wybranych drzew kompresji w zale¿noœci od wielkoœci paczki danych kompresowanych przez pojedyncze drzewo, pokazano na rysunku \ref{ref:tcp}. Jak mo¿na siê domyœleæ, czym wiêksze i bardziej skomplikowane drzewo tym wolniejszy algorytm, dlatego te¿ warto wybieraæ ni¿sze drzewo, jeœli nie spowoduje to znacznego spadku jakoœci.
Z uwagi na architekturê GPU, op³aca siê za jednym zamachem przetwarzaæ jak najwiêcej danych,
pojedynczym drzewem, zatem powinno siê dzieliæ przychodz¹ce dane na paczki o wielkoœci wiêkszej ni¿ milion elementów.
	\begin{figure}[!ht]
        \centering
        \hspace*{-0.25cm}\includegraphics[scale=0.35]{img/tcp}
        \caption{Wydajnoœæ kompresji drzewami}
        \label{ref:tcp}
    \end{figure}
Ponadto, bardzo znacz¹cy wp³yw na wydajnoœæ algorytmu ma wykonanie fazy 1, której wydajnoœæ plasuje siê na poziomie
jedynie $5 MB/s$, poniewa¿ sprawdza du¿¹ iloœæ drzew\footnote{patrz tabela \ref{tab:trees}}. Mo¿e siê to wydawaæ niewiele, jednak faza ta wykonywana jest na bardzo ma³ej liczbie elementów lub równolegle do w³aœciwej kompresji. Jeœli faza ta wykonywana jest rzadko, przestaje wp³ywaæ na w³aœciw¹ wydajnoœæ kompresji.

\begin{table}[!ht]
\centering
\caption{Iloœæ drzew kompresji generowana dla 2 ró¿nych heurystyk: A - szerokiej, z luŸnymi regu³ami i generuj¹c¹ du¿¹ iloœæ drzew oraz B - w¹sk¹, mocno ograniczon¹ i generuj¹c¹ ma³¹ iloœæ drzew}
\begin{tabular}{|l|l|l|l|l|}
\hline
\multirow{2}{*}{Data} & \multicolumn{2}{c|}{Heurystyka A} &	\multicolumn{2}{c|}{Heurystyka B}\\ 
& Iloœæ kand. drzew & ratio & Iloœæ kand. drzew & ratio \\ 
\hline
NYSE time  		&97404	&176.991		&3787	&88.691	\\
Float Prec 3		&2686	&4.03918		&1040	&1.645	\\
Random Int 		&1104	&2.28206		&110		&1.000	\\
Int consecutive	&38427	&625			&2963	&625.000\\
Int Pattern A	&87973	&236.686		&494		&196.078\\
Float Pattern A 	&87370	&220.994		&1413	&196.078\\
Int Pattern B 	&1346	&7.857		&203		&2.383	\\
Float Pattern B   &3654	&4.2328		&1837	&3.336 \\
\hline
\end{tabular}
\label{tab:trees}
\end{table}

W przewa¿aj¹cej liczbie kodowañ prêdkoœæ dekompresji jest znacz¹co wiêksza ni¿ prêdkoœæ kompresji\footnote{patrz rysunek \ref{ref:enc_perf}}. Przy dekodowaniu z danych optymalizatorem, nie ma potrzeby wyliczania ¿adnych statystyk ani sprawdzania wielu drzew. Wydajnoœæ dekompresji powinna byæ zatem du¿o wy¿sza, co potwierdzaj¹ testy pokazane na listingu \ref{lst:optim_results}.  

\begin{lstlisting}[caption=Benchmark optymalizatora,label={lst:optim_results},basicstyle=\small]
Pattern A (type INT):
Pack size = 32M
Scheme = rle[266],patch[13],const[22],none[1],const[23],none,
patch[9],delta[9],afl[9],none,const[23],none
Ratio = 266.407
Compression throughput = 431.267 MB/s
Decompression throughput = 1.28074 GB/s

Pattern B (type INT):
Pack size = 32M
Scheme = scale[7],patch[7],afl[10],none,scale[10],afl[10],none
Ratio = 7.99996
Compression throughput = 554.785MB/s
Decompression throughput = 853.789MB/s

Time (type LONG):
Pack size = 16M
Scheme = delta[33],patch[33],rle[1014],none,none,scale[63],afl[63],none
Ratio = 33.77
Compression throughput = 257.235MB/s
Decompression throughput = 1.12897GB/s
\end{lstlisting}
\noindent
Wartoœci w nawiasach odpowiadaj¹ uciêtym do jednoœci wartoœciom wspó³czynnika kompresji uzyskanego 
w poszczególnych wêz³ach drzewa. Kompresowane dane w powy¿szym teœcie by³y podzielone na 25 paczek
po ,,\emph{Pack size}'' elementów, a faza 1 wykonana zosta³a 2 do 3 razy w trakcie trwania testu.
Bior¹c pod uwagê fakt, ¿e wydajnoœæ danych drzew jest porównywalna do szybkoœci optymalizatora,
który je wywnioskowa³, mo¿na stwierdziæ, ¿e algorytm poprawiania i zgadywania drzew, nie spowalnia znacz¹co 
samego procesu kompresji drzewem.

\subsection{Generowanie statystyk}
Podczas pierwszej fazy algorytmu, jak równie¿ w czasie trwania niektórych kodowañ, wyliczane s¹ statystyki
aktualnych danych. Wyliczanie metryki \emph{RLE} zamiast prawdziwej, maksymalnej lub œredniej d³ugoœci ci¹gów,
poskutkowa³o bardzo wydajn¹ implementacj¹ na GPU. Wyliczanie precyzji nie zosta³o niestety odpowiednio
zoptymalizowane pod k¹tem obliczeñ na \emph{CUDA} i jego wydajnoœæ ogranicza sumaryczn¹ przepustowoœæ obliczania
statystyk do oko³o \emph{500 MB/s}.
	\begin{figure}[!ht]
        \centering
        \hspace*{-0.5cm}\includegraphics[scale=0.4]{img/stats_perf}
        \caption{Wydajnoœæ wybranych statystyk}
        \label{ref:stats_perf}
    \end{figure}
Ponadto w testach na danych typu ca³kowitego \emph{Pattern A}, maksymalna przepustowoœæ implementacji 
histogramu oraz statystyki \emph{Dictionary Counter} wynios³y odpowiednio \emph{5.63227 GB/s} oraz
\emph{790.123 MB/s}.

\chapter{Podsumowanie}
Podsumowuj¹c, uda³o siê zaimplementowaæ dzia³aj¹cy prototyp optymalizatora kompresji
szeregów czasowych, który potrafi dostosowaæ siê do zmiennej charakterystyki nap³ywaj¹cych
danych. Kompresor w dobrym tempie koduje dane zachowuj¹c wysoki poziom kompresji,
dorównuj¹cy, a dla w³aœciwych szeregów czasowych nawet przewy¿szaj¹cy, niektóre istniej¹ce
rozwi¹zania. Algorytm wykazuje wy¿szy poziom kompresji dla realistycznych danych, ni¿
szeroko stosowane kompresory 7z czy zip. Jednak jest to tylko prototyp i dla
rozwi¹zañ w bazach danych GPU uzyskana wydajnoœæ kompresji nie jest wystarczaj¹ca.
Z drugiej strony, patrz¹c na wydajnoœæ odpowiednio zoptymalizowanych odpowiedników wdro¿onych
kompresji mo¿na uznaæ, ¿e mo¿liwe jest ulepszenie tego rozwi¹zania w taki sposób, by uzyska³o wymagan¹
wydajnoœæ na poziomie kilkudziesiêciu Gb/s.

\section{Konkluzja}
U¿ywaj¹c kaskadowej kompresji specyficznej dla konkretnego szeregu czasowego mo¿na osi¹gn¹æ
du¿o lepsze rezultaty ni¿ stosuj¹c metody s³ownikowe, które czêsto wykazuj¹ nisk¹ wydajnoœæ.
Uzyskano ponad oœmiokrotny wzrost jakoœci kompresji\footnote{patrz tabela \ref{tab:opt_vs_single}} dla danych o zmiennej charakterystyce wzglêdem kompresji pojedynczym schematem. Wskazane zosta³y s³abe punkty dotychczasowej implementacji,
których wyeliminowanie powinno prowadziæ do wyrównania wydajnoœci z istniej¹cymi rozwi¹zaniami
kaskadowej kompresji na GPU. Co wiêcej mo¿na uznaæ, ¿e zaproponowane rozwi¹zanie ma szansê z 
powodzeniem zostaæ wdro¿one jako kompresor w bazie danych po stronie GPU, który na bie¿¹co
bêdzie kompresowa³ i dekompresowa³ nap³ywaj¹ce dane.

\section{Przysz³e prace}
Projekt nadal wymaga w³o¿enia du¿ego nak³adu pracy w celu optymalizacji wydajnoœci, a tak¿e implementacji wielu algorytmów kodowania przydatnych do kompresji szeregów. Dalsze prace bêd¹
prowadzone na temat implementacji kompresji za pomoc¹ regresji czêœciowej na GPU. Warto bêdzie
u¿yæ wersji niektórych algorytmów z wbudowanym \emph{patchowaniem} w celu przyspieszenia
obliczeñ. Wa¿nym elementem, który bêdzie w przysz³oœci równie¿ zaimplementowany jest niezale¿ne
wykonanie fazy 1 algorytmu optymalizatora, która zajmuje wiêkszoœæ czasu wykonania. Dodatkowo
jest planowane udostêpnienie rozwi¹zania w formie \emph{Open Source}, wraz z przyk³adami oraz gotowym 
œrodowiskiem uruchomieniowym w formie dockera\footnote{An open platform for distributed applications for developers and sysadmins: https://www.docker.com/}. Ostatecznie projekt móg³by byæ wykorzystany w bazie danych szeregów czasowych,
po stronie GPU.


%-----------Koniec czêœci zasadniczej-----------

\begin{thebibliography}{11}
\small
\bibitem[1]{PPS} Mark Harris, Shubhabrata Sengupta, and John D. Owens. \emph{"Parallel Prefix Sum (Scan) with CUDA"}. In Hubert Nguyen, editor, GPU Gems 3, chapter 39, pages 851–876. Addison Wesley, August 2007
\bibitem[2]{SORT} Nadathur Satish, Mark Harris, and Michael Garland. \emph{"Designing Efficient Sorting Algorithms for Manycore GPUs"}. In Proceedings of the 23rd IEEE International Parallel \& Distributed Processing Symposium, May 2009
\bibitem[3]{PHASH} Alcantara, Dan A., et al. \emph{"Real-time parallel hashing on the GPU."} ACM Transactions on Graphics (TOG) 28.5 (2009): 154
\bibitem[4]{MOSTAK} Mostak, T., 2013. \emph{"An overview of MapD (massively parallel database)."}, Massachusetts Institute of Technology, Cambridge, MA.
\bibitem[5]{CURRY} Cloud RL, Curry ML, Ward HL, Skjellum A, Bangalore P. \emph{"Accelerating lossless data compression with GPUs."} arXiv preprint arXiv:1107.1525. 2011 Jun 21.
\bibitem[6]{RUSSEK} Pietroñ, M., Pawel Russek, and Kazimierz Wiatr. \emph{"Accelerating SELECT WHERE and SELECT JOIN queries on a GPU."} Computer Science 14.2) (2013): 243-252.
\bibitem[7]{DTU} Nicolaisen, Anders Lehrmann Vr?nning. \emph{"Algorithms for Compression on GPUs."} (2013).
\bibitem[8]{MENSMANN} Mensmann, Jörg, Timo Ropinski, and Klaus Hinrichs. \emph{"A GPU-supported lossless compression scheme for rendering time-varying volume data."} 8th IEEE/EG international conference on Volume Graphics, 2–3 May 2010, Norrköping, Sweden. IEEE, 2010.
\bibitem[9]{BURTSCHER} Burtscher M, Ratanaworabhan P. \emph{"FPC: A high-speed compressor for double-precision floating-point data."} Computers, IEEE Transactions on. 2009 Jan;58(1):18-31.
\bibitem[10]{BAKKUM} Bakkum, Peter, and Kevin Skadron. \emph{"Accelerating SQL database operations on a GPU with CUDA."} Proceedings of the 3rd Workshop on General-Purpose Computation on Graphics Processing Units. ACM, 2010.
\bibitem[11]{FERRIERA} Ferreira, Miguel C. \emph{"Compression and query execution within column oriented databases."} Diss. Massachusetts Institute of Technology, 2005.
\bibitem[12]{FINK} Fink, Eugene, and Harith Suman Gandhi. \emph{"Compression of time series by extracting major extrema."} Journal of Experimental \& Theoretical Artificial Intelligence 23.2 (2011): 255-270.
\bibitem[13]{KACZMAR2} Przymus, Piotr, and Krzysztof Kaczmarski. \emph{"Compression Planner for Time Series Database with GPU Support."} Transactions on Large-Scale Data-and Knowledge-Centered Systems XV. Springer Berlin Heidelberg, 2014. 36-63.
\bibitem[14]{OZSOY} Ozsoy, Adnan, Martin Swany, and Anamika Chauhan. \emph{"Pipelined parallel lzss for streaming data compression on GPGPUs."} Parallel and Distributed Systems (ICPADS), 2012 IEEE 18th International Conference on. IEEE, 2012.
\bibitem[15]{FANG} Fang, Wenbin, Bingsheng He, and Qiong Luo. \emph{"Database compression on graphics processors."} Proceedings of the VLDB Endowment 3.1-2 (2010): 670-680.
\bibitem[16]{LEMIRE} Lemire, Daniel, and Leonid Boytsov. \emph{"Decoding billions of integers per second through vectorization."} Software: Practice and Experience 45.1 (2015): 1-29.
\bibitem[17]{PRZYMUS1} Przymus, Piotr, and Krzysztof Kaczmarski. \emph{"Dynamic compression strategy for time series database using GPU."} New Trends in Databases and Information Systems. Springer International Publishing, 2014. 235-244.
\bibitem[18]{MANI} Mani, Ganapathy. \emph{"Data Compression using CUDA programming in GPU."} (2012).
\bibitem[19]{CHASH} Alcantara, Dan A., et al. \emph{"Real-time parallel hashing on the GPU."} ACM Transactions on Graphics (TOG) 28.5 (2009): 154.
\bibitem[20]{ONEIL} O'Neil, Molly A., and Martin Burtscher. \emph{"Floating-point data compression at 75 Gb/s on a GPU."} Proceedings of the Fourth Workshop on General Purpose Processing on Graphics Processing Units. ACM, 2011.
\bibitem[21]{ZU} Zu, Yuan, and Bei Hua. \emph{"GLZSS: LZSS lossless data compression can be faster."} Proceedings of Workshop on General Purpose Processing Using GPUs. ACM, 2014.
\bibitem[22]{GPUFS} Silberstein, Mark, et al. \emph{"GPUfs: Integrating a file system with GPUs."} ACM Transactions on Computer Systems (TOCS) 32.1 (2014): 1.
\bibitem[23]{ACC} Al-Kiswany, Samer, Ammar Gharaibeh, and Matei Ripeanu. \emph{"GPUs as storage system accelerators."} Parallel and Distributed Systems, IEEE Transactions on 24.8 (2013): 1556-1566.
\bibitem[23]{PRZYMUS2} Przymus, Piotr, and Krzysztof Kaczmarski. \emph{"Improving efficiency of data intensive applications on GPU using lightweight compression."} On the Move to Meaningful Internet Systems: OTM 2012 Workshops. Springer Berlin Heidelberg, 2012.
\bibitem[24]{ABADI} Abadi, Daniel, Samuel Madden, and Miguel Ferreira. \emph{"Integrating compression and execution in column-oriented database systems."} Proceedings of the 2006 ACM SIGMOD international conference on Management of data. ACM, 2006.
\bibitem[25]{ANH} Anh, Vo Ngoc, and Alistair Moffat. \emph{"Inverted index compression using word-aligned binary codes."} Information Retrieval 8.1 (2005): 151-166.
\bibitem[26]{EIROLA} Eirola, Axel. \emph{"Lossless data compression on GPGPU architectures."} arXiv preprint arXiv:1109.2348 (2011).
\bibitem[27]{SHYNI} Shyni, K., and Manoj Kumar KV. \emph{"Lossless LZW Data Compression Algorithm on CUDA."} IOSR Journal of Computer Engineering (IOSR-JCE) 13.1 (2013): 122-127.
\bibitem[28]{MAPD} Mostak, Todd. \emph{"An overview of MapD (massively parallel database)."} White paper, Massachusetts Institute of Technology, Cambridge, MA (2013).
\bibitem[29]{BUSCHS} Buchsbaum, Adam L., et al. \emph{"Engineering the compression of massive tables: an experimental approach."} Symposium on Discrete Algorithms: Proceedings of the eleventh annual ACM-SIAM symposium on Discrete algorithms. Vol. 9. No. 11. 2000.
\bibitem[30]{MORISHIMA} Morishima, Shin, and Hiroki Matsutani. \emph{"Performance Evaluations of Document-Oriented Databases Using GPU and Cache Structure."} Trustcom/BigDataSE/ISPA, 2015 IEEE. Vol. 3. IEEE, 2015.
\bibitem[31]{OZSOY3} Ozsoy, Adnan, Martin Swany, and Arun Chauhan. \emph{"Optimizing LZSS compression on GPGPUs."} Future Generation Computer Systems 30 (2014): 170-178.
\bibitem[32]{PATEL} Patel, Ritesh A., et al. \emph{"Parallel lossless data compression on the GPU."} IEEE, 2012.
\bibitem[33]{SIMD} Polychroniou, Orestis, Arun Raghavan, and Kenneth A. Ross. \emph{"Rethinking SIMD vectorization for in-memory databases."} Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data. ACM, 2015.
\bibitem[34]{SHREDDER} Bhatotia, Pramod, Rodrigo Rodrigues, and Akshat Verma. \emph{"Shredder: GPU-accelerated incremental storage and computation."} FAST. 2012.
\bibitem[35]{ZUKOWSKI} Zukowski, Marcin, et al. \emph{"Super-scalar RAM-CPU cache compression."} Data Engineering, 2006. ICDE'06. Proceedings of the 22nd International Conference on. IEEE, 2006.
\bibitem[36]{EICHINGER} Eichinger, Frank, et al. \emph{"A time-series compression technique and its application to the smart grid."} The VLDB Journal 24.2 (2015): 193-218.
\bibitem[37]{KACZMAR1} Przymus, Piotr, and Krzysztof Kaczmarski. \emph{"Time series queries processing with gpu support."} New Trends in Databases and Information Systems. Springer International Publishing, 2014. 53-60.
\bibitem[38]{ZHAO} Zhao, Wayne Xin, et al. \emph{"A General SIMD-based Approach to Accelerating Compression Algorithms."} ACM Transactions on Information Systems (TOIS) 33.3 (2015): 15.
\bibitem[39]{GOLDSTEIN} Goldstein, Jonathan, Raghu Ramakrishnan, and Uri Shaft. \emph{"Compressing relations and indexes."} Data Engineering, 1998. Proceedings., 14th International Conference on. IEEE, 1998.
\bibitem[41]{CUDA_PERF} http://developer.download.nvidia.com/compute/cuda/compute-docs/cuda-performance-report.pdf
\bibitem[42]{PARETO} Marler, R. Timothy, and Jasbir S. Arora. \emph{"Survey of multi-objective optimization methods for engineering."} Structural and multidisciplinary optimization 26.6 (2004): 369-395.
\bibitem[43]{UENG} Ueng, Sain-Zee, et al. \emph{"CUDA-lite: Reducing GPU programming complexity."} Languages and Compilers for Parallel Computing. Springer Berlin Heidelberg, 2008. 1-15.
\bibitem[44]{FPC} Burtscher, Martin, and Paruj Ratanaworabhan. \emph{"pFPC: A parallel compressor for floating-point data."} Data Compression Conference, 2009. DCC'09.. IEEE, 2009.

\end{thebibliography}
\tableofcontents
\clearpage
\pagestyle{empty}
\noindent Warszawa, dnia ...............
\vspace{5cm}
\begin{center}
\LARGE{Oœwiadczenie}
\end{center}
Oœwiadczam, ¿e pracê magistersk¹ pod tytu³em: ,,Tytu³ pracy'', której promotorem jest prof. dr hab. Jan Wybitny, wykona³em/am samodzielnie, co poœwiadczam w³asnorêcznym podpisem.
\vspace{2cm}
\begin{flushright}
...........................................
\end{flushright}

\end{document}
